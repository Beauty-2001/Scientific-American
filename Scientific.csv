date,title,articles,url
"May 11, 2023- Starre Vartan",Astronomy Tool Can Now Detect COVID in Breath,"Astronomers and physicists have long used a laser-based sensor called an “optical frequency comb” to study the material makeup of the cosmos and to make timekeeping more accurate. But the COVID pandemic has pushed this versatile tool from the world of space and physics into health care.

Optical frequency combs are lasers that simultaneously shoot pulses of light at multiple frequencies. Because these superfast pulses are precisely spaced along the light spectrum—from infrared through the visible colors to ultraviolet—they form a series of peaks on a graph of the frequencies that look like the teeth of a comb. This “comb” can be used in a variety of ways. For instance, different types of molecules absorb different colors of light; by detecting which colors of light are absorbed near specific frequencies, the comb can identify specific molecules in an air sample. In a recent study, scientists proved this tool can detect COVID from Breathalyzer-type tests in which subjects simply blow into a tube—potentially paving the way for fast, noninvasive diagnostic tests for a multitude of diseases.

Every time humans exhale, we expel more than 1,000 kinds of trace molecules called volatile organic compounds, or VOCs. “Changes in VOC profiles can be linked to specific health conditions,” says Cristina Davis, associate vice chancellor for interdisciplinary research and strategic initiatives at the University of California, Davis. Scholars have known for millennia that certain breath odors are associated with clinical diseases or disorders. References in ancient Greek and Chinese medical literature indicate that doctors used the nose as a diagnostic tool, Davis says. More recently, dogs have been trained to identify some diseases in humans—and laser comb detectors also need training, says physicist Jun Ye, co-author of the new study. “We are training our frequency comb nose using machine learning, and once it’s trained, it becomes an electronic dog—with much greater sensitivity,” Ye says.

ADVERTISEMENT

This powerful artificial nose has the advantage of being able to sniff out disease in a way that’s quick and noninvasive, says the study’s lead author, Qizhong Liang, a graduate student at the University of Colorado Boulder. For maximum accuracy, Liang adds, positive results from the new technology’s COVID tests should be followed up with a more reliable PCR test. But for quick screening at airports, concert venues or hospitals, it could beat other methods, such as body temperature scans, that are used to assess potential COVID infection without requiring an invasive nose swab.

Frequency combs can do more than identify molecules. They were originally developed in the 1990s to make more accurate optical atomic clocks, for which the inventors won the 2005 Nobel Prize in Physics. The combs can measure the natural oscillation of atoms so precisely that they have become an indispensable component of atomic clocks, which keep time incredibly well by counting these oscillations. In astronomy, researchers use optical frequency combs to measure the frequencies of light coming from distant stars; disruptions can indicate a star has an exoplanet. In atmospheric science, they have been used to study greenhouse gases. And in 2008 Ye and his colleagues at JILA (a joint institute of the National Institute of Standards and Technology and the University of Colorado Boulder) first proved that the technology could be used as a breath test for disease biomarkers. They set this finding aside, but global events suddenly gave them a very good reason to revive the work in April 2020. “Using breath as a diagnostic tool has been around for a while,” Davis says, “but I think it took a pandemic for research interest to really to really be moved forward.”

Shortly after the COVID pandemic began, Ye got a call from his colleagues at the National Academies of Sciences, Engineering, and Medicine and the Air Force Office of Scientific Research. They wanted to know whether his early frequency comb “Breathalyzer” research might help develop a noninvasive COVID test.

Ye and his team started by updating their 2008 technology. The researchers extended the laser comb’s frequency range from the near-infrared region of the spectrum into the mid-infrared part—where molecules absorb light two to three times more strongly. That signal boost allowed the researchers to improve the tool’s detection sensitivity by 1,000-fold, letting them identify molecules at extremely low concentrations on the scale of hundreds of parts per trillion.

Next, Ye’s team collected breath samples from 170 University of Colorado Boulder students and staff from May 2021 to January 2022. Each participant received conventional PCR nasal swab COVID tests, and about half were positive. The researchers then used the frequency comb to analyze light-absorption patterns among molecules in the participants’ breath. Applying machine learning to the frequency comb data, combined with the already-known PCR data on who was positive or negative, they found six “discriminating molecules” that indicated COVID infection. The work was described in a paper published in April in the Journal of Breath Research.

ADVERTISEMENT

Liang says AI was key to the project’s success because of the vast amount of information the frequency comb gathers when analyzing breath. “Machine learning can analyze all of this data simultaneously and can automatically figure out the best way of utilizing all of that discriminating information to make a prediction model,” he says.

Frequency combs aren’t the only way to test human breath for COVID or other diseases. Other methods include gas chromatography/mass spectrometry systems such as the InspectIR test, which received emergency use authorization from the U.S. Food and Drug Administration in April 2022. In such chemistry-based techniques, the gas molecules to be analyzed are separated by an inert gas, broken down into fragments and then measured. Davis calls these types of tests the “gold standard,” but they require time, specialized training and bulky equipment that limits their use to the lab. Davis has been working on a smaller, portable type of test, an ion mobility spectrometer, which identifies substances based on the mobility of their molecules in an electric field. Other options use chemicals that bind to VOCs to isolate and test them. “There are more than 15 companies working on a variety of these kinds of tests,” Davis says.

The frequency comb technology is different, Liang says, because it uses laser spectroscopy and therefore “detects the molecules in breath in a nondestructive way.” By this he means the comb does not cause a sample to degrade or create any unwanted by-products, as breath tests that rely on chemical reactions can. Frequency comb technology also has the potential to be really, really fast: it could potentially eventually provide results in seconds, compared with minutes in other breath tests.

Sign up for Scientific American’s free newsletters.

Sign Up

That said, you probably won’t see laser combs the next time you catch a flight. “Breath tests, in general, have not reached prime time yet,” says Wilbur Lam, a COVID test expert, pediatrician and biomedical engineer at Emory University and the Georgia Institute of Technology. With the frequency comb method, he says, “you get an optical signal, and whether that optical signal is truly indicative of a COVID infection really has to be proven. Right now, they’re showing some correlation. But how does it correlate with other types of conditions that could affect the breath?”

If frequency comb “Breathalyzers” do prove themselves in further research, they could make a huge difference in many clinical settings beyond rapid testing for COVID. Study co-author Kristen Bjorkman, director of interdisciplinary research at the BioFrontiers Institute, suggests this technology might one day be used to detect chronic obstructive pulmonary disease, kidney failure, lung and pancreatic cancers and even Alzheimer’s disease. Multiple early studies have provided preliminary evidence that the contents of exhaled breaths can be used for these diagnoses.

ADVERTISEMENT

Breathalyzer-style tests could also be ideal for diagnosing children, and Ye says some pediatricians have already approached him about a frequency comb test for asthma in kids. When a child shows up sick at the emergency room, Ye explains, a lot of invasive tests are required to determine if the symptoms are caused by a bacterial or viral illness or asthma. He says one Denver-based pediatrician told him, “‘Imagine you can do a breath analysis on children, which is totally noninvasive. Kids won’t cry if they have to just donate a breath.’”",https://www.scientificamerican.com/article/astronomy-tool-can-now-detect-covid-in-breath/
"May 11, 2023- George Musser",How AI Knows Things No One Told It,"No one yet knows how ChatGPT and its artificial intelligence cousins will transform the world, and one reason is that no one really knows what goes on inside them. Some of these systems’ abilities go far beyond what they were trained to do—and even their inventors are baffled as to why. A growing number of tests suggest these AI systems develop internal models of the real world, much as our own brain does, though the machines’ technique is different.

“Everything we want to do with them in order to make them better or safer or anything like that seems to me like a ridiculous thing to ask ourselves to do if we don’t understand how they work,” says Ellie Pavlick of Brown University, one of the researchers working to fill that explanatory void.

At one level, she and her colleagues understand GPT (short for generative pretrained transformer) and other large language models, or LLMs, perfectly well. The models rely on a machine-learning system called a neural network. Such networks have a structure modeled loosely after the connected neurons of the human brain. The code for these programs is relatively simple and fills just a few screens. It sets up an autocorrection algorithm, which chooses the most likely word to complete a passage based on laborious statistical analysis of hundreds of gigabytes of Internet text. Additional training ensures the system will present its results in the form of dialogue. In this sense, all it does is regurgitate what it learned—it is a “stochastic parrot,” in the words of Emily Bender, a linguist at the University of Washington. But LLMs have also managed to ace the bar exam, explain the Higgs boson in iambic pentameter, and make an attempt to break up their users’ marriage. Few had expected a fairly straightforward autocorrection algorithm to acquire such broad abilities.

ADVERTISEMENT

That GPT and other AI systems perform tasks they were not trained to do, giving them “emergent abilities,” has surprised even researchers who have been generally skeptical about the hype over LLMs. “I don’t know how they’re doing it or if they could do it more generally the way humans do—but they’ve challenged my views,” says Melanie Mitchell, an AI researcher at the Santa Fe Institute.

“It is certainly much more than a stochastic parrot, and it certainly builds some representation of the world—although I do not think that it is quite like how humans build an internal world model,” says Yoshua Bengio, an AI researcher at the University of Montreal.

At a conference at New York University in March, philosopher Raphaël Millière of Columbia University offered yet another jaw-dropping example of what LLMs can do. The models had already demonstrated the ability to write computer code, which is impressive but not too surprising because there is so much code out there on the Internet to mimic. Millière went a step further and showed that GPT can execute code, too, however. The philosopher typed in a program to calculate the 83rd number in the Fibonacci sequence. “It’s multistep reasoning of a very high degree,” he says. And the bot nailed it. When Millière asked directly for the 83rd Fibonacci number, however, GPT got it wrong: this suggests the system wasn’t just parroting the Internet. Rather it was performing its own calculations to reach the correct answer.

Although an LLM runs on a computer, it is not itself a computer. It lacks essential computational elements, such as working memory. In a tacit acknowledgement that GPT on its own should not be able to run code, its inventor, the tech company OpenAI, has since introduced a specialized plug-in—a tool ChatGPT can use when answering a query—that allows it to do so. But that plug-in was not used in Millière’s demonstration. Instead he hypothesizes that the machine improvised a memory by harnessing its mechanisms for interpreting words according to their context—a situation similar to how nature repurposes existing capacities for new functions.

This impromptu ability demonstrates that LLMs develop an internal complexity that goes well beyond a shallow statistical analysis. Researchers are finding that these systems seem to achieve genuine understanding of what they have learned. In one study presented last week at the International Conference on Learning Representations (ICLR), doctoral student Kenneth Li of Harvard University and his AI researcher colleagues—Aspen K. Hopkins of the Massachusetts Institute of Technology, David Bau of Northeastern University, and Fernanda Viégas, Hanspeter Pfister and Martin Wattenberg, all at Harvard—spun up their own smaller copy of the GPT neural network so they could study its inner workings. They trained it on millions of matches of the board game Othello by feeding in long sequences of moves in text form. Their model became a nearly perfect player.

ADVERTISEMENT

To study how the neural network encoded information, they adopted a technique that Bengio and Guillaume Alain, also at the University of Montreal, devised in 2016. They created a miniature “probe” network to analyze the main network layer by layer. Li compares this approach to neuroscience methods. “This is similar to when we put an electrical probe into the human brain,” he says. In the case of the AI, the probe showed that its “neural activity” matched the representation of an Othello game board, albeit in a convoluted form. To confirm this, the researchers ran the probe in reverse to implant information into the network—for instance, flipping one of the game’s black marker pieces to a white one. “Basically, we hack into the brain of these language models,” Li says. The network adjusted its moves accordingly. The researchers concluded that it was playing Othello roughly like a human: by keeping a game board in its “mind’s eye” and using this model to evaluate moves. Li says he thinks the system learns this skill because it is the most parsimonious description of its training data. “If you are given a whole lot of game scripts, trying to figure out the rule behind it is the best way to compress,” he adds.

This ability to infer the structure of the outside world is not limited to simple game-playing moves; it also shows up in dialogue. Belinda Li (no relation to Kenneth Li), Maxwell Nye and Jacob Andreas, all at M.I.T., studied networks that played a text-based adventure game. They fed in sentences such as “The key is in the treasure chest,” followed by “You take the key.” Using a probe, they found that the networks encoded within themselves variables corresponding to “chest” and “you,” each with the property of possessing a key or not, and updated these variables sentence by sentence. The system had no independent way of knowing what a box or key is, yet it picked up the concepts it needed for this task. “There is some representation of the state hidden inside of the model,” Belinda Li says.

Researchers marvel at how much LLMs are able to learn from text. For example, Pavlick and her then Ph.D. student Roma Patel found that these networks absorb color descriptions from Internet text and construct internal representations of color. When they see the word “red,” they process it not just as an abstract symbol but as a concept that has certain relationship to maroon, crimson, fuchsia, rust, and so on. Demonstrating this was somewhat tricky. Instead of inserting a probe into a network, the researchers studied its response to a series of text prompts. To check whether it was merely echoing color relationships from online references, they tried misdirecting the system by telling it that red is in fact green—like the old philosophical thought experiment in which one person’s red is another person’s green. Rather than parroting back an incorrect answer, the system’s color evaluations changed appropriately in order to maintain the correct relations.

Sign up for Scientific American’s free newsletters.

Sign Up

Picking up on the idea that in order to perform its autocorrection function, the system seeks the underlying logic of its training data, machine learning researcher Sébastien Bubeck of Microsoft Research suggests that the wider the range of the data, the more general the rules the system will discover. “Maybe we’re seeing such a huge jump because we have reached a diversity of data, which is large enough that the only underlying principle to all of it is that intelligent beings produced them,” he says. “And so the only way to explain all of this data is [for the model] to become intelligent.”

In addition to extracting the underlying meaning of language, LLMs are able to learn on the fly. In the AI field, the term “learning” is usually reserved for the computationally intensive process in which developers expose the neural network to gigabytes of data and tweak its internal connections. By the time you type a query into ChatGPT, the network should be fixed; unlike humans, it should not continue to learn. So it came as a surprise that LLMs do, in fact, learn from their users’ prompts—an ability known as “in-context learning.” “It’s a different sort of learning that wasn’t really understood to exist before,” says Ben Goertzel, founder of the AI company SingularityNET.

ADVERTISEMENT

One example of how an LLM learns comes from the way humans interact with chatbots such as ChatGPT. You can give the system examples of how you want it to respond, and it will obey. Its outputs are determined by the last several thousand words it has seen. What it does, given those words, is prescribed by its fixed internal connections—but the word sequence nonetheless offers some adaptability. Entire websites are devoted to “jailbreak” prompts that overcome the system’s “guardrails”—restrictions that stop the system from telling users how to make a pipe bomb, for example—typically by directing the model to pretend to be a system without guardrails. Some people use jailbreaking for sketchy purposes, yet others deploy it to elicit more creative answers. “It will answer scientific questions, I would say, better” than if you just ask it directly, without the special jailbreak prompt, says William Hahn, co-director of the Machine Perception and Cognitive Robotics Laboratory at Florida Atlantic University. “It’s better at scholarship.”

Another type of in-context learning happens via “chain of thought” prompting, which means asking the network to spell out each step of its reasoning—a tactic that makes it do better at logic or arithmetic problems requiring multiple steps. (But one thing that made Millière’s example so surprising is that the network found the Fibonacci number without any such coaching.)

In 2022 a team at Google Research and the Swiss Federal Institute of Technology in Zurich—Johannes von Oswald, Eyvind Niklasson, Ettore Randazzo, João Sacramento, Alexander Mordvintsev, Andrey Zhmoginov and Max Vladymyrov—showed that in-context learning follows the same basic computational procedure as standard learning, known as gradient descent. This procedure was not programmed; the system discovered it without help. “It would need to be a learned skill,” says Blaise Agüera y Arcas, a vice president at Google Research. In fact, he thinks LLMs may have other latent abilities that no one has discovered yet. “Every time we test for a new ability that we can quantify, we find it,” he says.

Although LLMs have enough blind spots not to qualify as artificial general intelligence, or AGI—the term for a machine that attains the resourcefulness of animal brains—these emergent abilities suggest to some researchers that tech companies are closer to AGI than even optimists had guessed. “They’re indirect evidence that we are probably not that far off from AGI,” Goertzel said in March at a conference on deep learning at Florida Atlantic University. OpenAI’s plug-ins have given ChatGPT a modular architecture a little like that of the human brain. “Combining GPT-4 [the latest version of the LLM that powers ChatGPT] with various plug-ins might be a route toward a humanlike specialization of function,” says M.I.T. researcher Anna Ivanova.

At the same time, though, researchers worry the window may be closing on their ability to study these systems. OpenAI has not divulged the details of how it designed and trained GPT-4, in part because it is locked in competition with Google and other companies—not to mention other countries. “Probably there’s going to be less open research from industry, and things are going to be more siloed and organized around building products,” says Dan Roberts, a theoretical physicist at M.I.T., who applies the techniques of his profession to understanding AI.

ADVERTISEMENT

And this lack of transparency does not just harm researchers; it also hinders efforts to understand the social impacts of the rush to adopt AI technology. “Transparency about these models is the most important thing to ensure safety,” Mitchell says.",https://www.scientificamerican.com/article/how-ai-knows-things-no-one-told-it/
"May 10, 2023- Meghan Bartels",Tweaking Vegetables’ Genes Could Make Them Tastier—And You’ll Get to Try Them Soon,"Today’s Brussels sprouts taste better than you might remember from childhood. It’s not that your refined adult palate appreciates them better. Rather a new variety has displaced the original vegetable. You can thank plant breeders for the change. And modern breeders, armed with new gene-editing technology, are looking to replicate Brussels sprouts’ reinvention.

In the late 1990s scientists identified specific chemicals, called glucosinolates, that made Brussels sprouts taste bitter. Plant breeders started growing old seeds, previously discarded for producing paltry harvests, to identify tastier versions with lower levels of these compounds. Then they crossed these delicious but low-yield plants with modern, more prolific individuals until they found a descendant that made plenty of tasty sprouts, transforming the once maligned vegetable from a bitter pill into a popular side dish.

But other veggies haven’t fared as well. That’s because most breeding decisions favor plant traits that matter to vegetable growers, not vegetable eaters. “I’d say disease resistance is probably the major focus these days of most breeding programs because that’s what imperils the ability of the farmer to grow the crop,” says Harry Klee, a professor emeritus of horticulture at the University of Florida, who specializes in tomatoes. “Quality traits are really completely ignored.”

ADVERTISEMENT

In addition, breeders who focus on consumer crops must navigate the controversy surrounding genetically modified organisms (GMOs). Although all domesticated species now have different genetics than their ancestors, in agriculture, the term GMO refers to a plant that carries genes imported from a completely different species—and these changes are subject to stricter regulation. But newer techniques are allowing breeders to work within the context of a plant’s own genome, making tweaks that don’t trigger complicated rules.

Flavor is challenging to target because different people have different preferences—plus, even under the best conditions, flavor quality is more complex than something like yield. “We’ve spent a lot of time and money figuring out what flavor is, and most breeding programs don’t have the capacity to measure those things,” Klee says.

But interest in prioritizing flavor is starting to build, thanks in part to new genetic technology such as the gene-snipping technique CRISPR and DNA sequencing that is cheap enough to use liberally. “There’s never been a better time to be a fruit breeder or a vegetable breeder because we have more tools and techniques,” says Susan Brown, an apple breeder at Cornell University.

Some companies are beginning to use those tools to tackle the challenge of developing tastier veggies. One company, Pairwise, is fighting the same compounds that plagued Brussels sprouts: glucosinolates. But this time researchers are modifying salad greens—and they’re armed with the science of gene editing.

Although kale, for instance, is particularly healthy, many prefer eating the less bitter romaine or iceberg lettuce. So Pairwise scientists figured out how to use CRISPR to edit a kalelike mustard green to fit that palate. They wanted to turn off the genes that code for an enzyme called myrosinase, which breaks down the glucosinolates and creates bitterness once the leaf is chewed in a diner’s mouth. The result is a healthy but less bitter green that the company is marketing this year under the brand Conscious Foods.

ADVERTISEMENT

This is an example of where flavor-minded gene editing can shine, says Tom Adams, co-founder and CEO of Pairwise. “From a gene-editing perspective, I think where taste comes in is that we can remove things that people don’t like,” he says. “It’s a lot more difficult to think about how you can bring in the really complex, great tastes.” To create those more complex tastes, Adams says, traditional breeding is still the best path.

Traditional breeding is the cornerstone of another high-tech flavor effort as well, one that seeks to reverse the ways of thinking that got us to tasteless vegetables in the first place. Instead of growing varieties that can withstand the storage and transportation needs of the agricultural system, a company called Plenty is shrinking the vast distance from the field to the table. Plenty grows its plants in indoor vertical farming facilities closer to consumers, so produce stays fresher, says Nate Storey, the company’s co-founder and chief science officer.

When Plenty decided to start with greens, he says, the team grew thousands of traditionally bred varieties in its facilities. Then the researchers adopted only the ones that resulted in the tastiest crops rather than trying to develop new varieties. “There’s no need to rebuild a wheel,” Storey says of the technique. “We just screen all the wheels that exist and find the ones that work best in our system.”

Sign up for Scientific American’s free newsletters.

Sign Up

This method does not always succeed, however. The company couldn’t find a tomato that thrived in its facilities, so it’s working on developing its own variety using a sped-up version of traditional breeding.

Tomatoes are a popular target. A third company is creating more flavorful tomatoes using epigenetics—changing the expression of genes instead of the genes themselves. Whereas Pairwise is snipping out the gene sequences that produce an enzyme that interferes with flavor, Sound Agriculture is programming gene expression. This approach dials down production of undesirable compounds by making their genetic sequences less accessible for transcription.

ADVERTISEMENT

Understanding how precisely to modify expression to get a desired result is still a work in progress, says Travis Bayer, co-founder and chief technology officer of Sound Agriculture. “The science of epigenetics in plants is really exciting and it’s something that is evolving pretty rapidly,” he says. The company’s first epigenetically grown product, a tomato dubbed Summer Swell, is due to hit shelves this spring. Other projects in the works focus on leafy greens, as well as a handful of fruits, Bayer says.

All these vegetable growers hope that more flavorful products on store shelves will convince people to consume the recommended allowances of fruits and vegetables—and do so better than decades of nutritional guidance have.

“Don’t waste your time talking about trying to educate people to eat better,” says Klee, the tomato breeding researcher. “Just give them products that taste better, that they want to eat.”",https://www.scientificamerican.com/article/tweaking-vegetables-genes-could-make-them-tastier-and-youll-get-to-try-them-soon/
"May 9, 2023- Simon Makin",Virtual Reality System Lets You Stop and Smell the Roses,"Virtual reality is already widespread in entertainment and is starting to spread to fields ranging from education to health care. But while vision and hearing interfaces are extremely advanced, and touch, or “haptics,” is improving, one key sense has been missing from the virtual world: smell.

That may be about to change. Engineer Xinge Yu of the City University of Hong Kong and his colleagues have developed a lightweight, flexible and wireless olfactory interface that can precisely deliver smells such as lavender, pineapple or green tea to VR users and more fully immerse them in scented virtual worlds. “Bringing smell into VR expands it into another dimension,” Yu says. “We wanted to develop something in a wearable, skin-integrated format that people can go anywhere with and use anytime.”

The team’s design was described in a paper published on Tuesday in Nature Communications. A key advantage is that it can control odor intensity. One demonstration in the study involved increasing the intensity of the smell generated as a woman in a four-dimensional movie brought a rose up to her nose.

ADVERTISEMENT

Credit: Yiming Liu et al., Nature Communications

Previous smell interfaces have typically used bottles of liquid perfume, an atomizer (a device that turns liquids into a fine mist) and some method of blowing the atomized droplets out. This works, but it is rigid and has limited operating time between refills, and it does not easily allow for controlling intensity. These drawbacks have made the devices less practical for VR systems.

The new design uses small paraffin wax pads infused with scents that are heated by an electrode to release an odor. A temperature-dependent resistor, or thermistor, senses the temperature, which controls the smell’s intensity. And a magnetic induction coil controls a metal plate that conducts heat away from the electrode to rapidly cool it down and shut off the scent. Arrays of these odor generators, which are millimeters in size, are incorporated into thin, flexible sheets of electronics.

The study describes two different device formats. The first is small enough that it can be stuck to a user’s top lip, but it includes only two odor generators. The second is worn like a face mask and has nine. Both are customizable with a selection of 30 odors, including gardenia, caramel, ginger, clove, mojito and coconut milk. Different combinations can be blended at varying intensities to create a palette of thousands of possible fragrances.

ADVERTISEMENT

The proximity to the user’s nose, together with clever engineering, allows for delays between activating and receiving a smell as short as 1.44 seconds. Atomizers are faster than this, but they lack the control of the new devices and are as small as they are ever going to get, says Judith Amores, a senior researcher at Microsoft Research and a research affiliate at the Massachusetts Institute of Technology, who studies olfactory interfaces for health applications but was not involved in the study. “An advantage of this system is they could miniaturize it even more,” she says. “That’s what’s exciting.”

The study includes demonstrations of possible applications beyond just augmenting VR, including communicating messages by smell and evoking emotions. The researchers suggest the devices could even be used to alleviate depressed mood or promote recall in people with age-related cognitive decline. “Scent is directly connected to the emotional and memory parts of the brain, so there are a lot of applications related to well-being and health,” Amores says. “It could also be used as a way to do olfactory training to help people who lost their sense of smell due to COVID.”

The researchers have already started shrinking things down further. They have a system that’s two to three times smaller now, and they aim to shrink it to something five to 10 times smaller in the future. “That’s the next step,” Yu says.

Sign up for Scientific American’s free newsletters.

Sign Up",https://www.scientificamerican.com/article/virtual-reality-system-lets-you-stop-and-smell-the-roses/
"May 1, 2023- Mark Fischetti","50, 100 & 150 Years Ago: May 2023","1973

Computer Privacy

“There is growing concern that computers constitute a dangerous threat to privacy. Since many computers contain personal data and are accessible from distant terminals, they are viewed as an unexcelled means of assembling large amounts of information about an individual or a group. It may soon be feasible to compile dossiers on an entire citizenry. However, a computer system can be adapted to guard its contents. Cryptographic encipherment can be achieved in two different ways: by ciphers or by codes. A cipher always assigns substitute symbols to some given set of alphabet letters. A code can convey only meanings thought of in advance and provided for in a secret list such as a code book. Other cryptographic approaches are still being studied.”

1923

King Tut's Bountiful Tomb

ADVERTISEMENT

“Biban el-Muluk, the valley of the kings' tombs, is a wild, desolate region behind the western plain of Thebes. Some 60 tombs in the valley were already known. On November 5, 1922, Howard Carter came upon a step cut in the rock under the path leading to the tomb of Ramses VI. The steps and passages of the L-shaped approach were cleared, leading to Tutenkhamon's tomb. The ante-chamber is the source of practically all the treasures removed this year. When we think of how much still lies within the tomb, it means work for two years or more if they are to be properly conserved, recorded and evaluated.”

Classy Vitamins

“The discovery of vitamins was made by [Frederick Gowland] Hopkins only as recently as 1912. The indispensability of these substances is now generally accepted. Three substances of the so-called vitamin class called A, B and C have been differentiated with certainty, and it is possible that more exist. They do not appear to be of one chemical type, and are effective in very small amounts. The green tissues of plants would seem to be the chief site of vitamin synthesis.”

Call It Insulin

“A product by the name of insulin has been prepared by Canadian biologists in Toronto, which is claimed to be a specific [remedy] against diabetes. The preparation is made from the pancreas of cattle, sheep and swine.”

ADVERTISEMENT
1873

Polaris Lost, Survivors Found

“Telegraphic despatches bring the news of the probable loss of the United States exploring steamer Polaris and the end of the Arctic expedition. On the 15th of October, 1872, a party of the crew, some nineteen souls, left the ship to place some provisions on an ice floe. A severe storm came on, causing the Polaris to part her moorings; the comrades on the ice, to their dismay, saw their vessel disappear. The tide and wind, it seems, fortunately drove the great floe, bearing the survivors, down through Baffin's Bay and Davis' straits until, on the 30th of April, they were rescued after 196 days on the ice, by the British steamer Tigress. The sufferings of the rescued party are described as terrible, but all were in comparatively good health.”

Tidal Power

Sign up for Scientific American’s free newsletters.

Sign Up

“A trial recently took place of Edward W. Morton's machine, at the East River. The machine works by means of a ‘float’ which, as it rises and falls with the waves or the tide, propels the machinery to which it may be attached. At the trial it was geared to a saw, and worked with the full rapidity of a circular saw run by steam power, although, perhaps, not quite so uniformly.”

Music from Fire

ADVERTISEMENT

“If into a glass tube two flames be introduced, at a distance of one third the length of the pipe, these flames will vibrate in unison. The phenomenon continues as long as the flames remain separate, but the sound ceases the moment they are brought in contact. If the position of the flames be varied, the sound decreases. M. Kastner has constructed a new musical instrument of a very peculiar timbre, closely resembling that of the human voice. The ‘pyrophone’ has three key boards; each key is in communication with the conduit pipes of the flames in the glass tubes. By pressing upon the keys, the flames separate and sound is produced. When the pressure is removed, it is instantly stilled by the junction of the flames.”",https://www.scientificamerican.com/article/50-100-150-may-2023/
"May 1, 2023- Simon Makin",Bionic Finger ‘Sees’ Inside Objects by Poking Them,"Human fingers don't just sense what a surface feels like. They also tell us a lot about what's underneath it: a really firm handshake, for example, can reveal where some bones are, and, with enough prodding, one can even locate tendons.

Inspired by this capability, scientists have developed a fingerlike device that maps an object's internal structures in 3-D by touching its surface. Earlier tactile sensors detected external shape, stiffness and texture but not subsurface details. For a study in Cell Reports Physical Science, the researchers tested their device by scanning simulated human tissue and electronic circuitry.

“This bionic finger has exciting application prospects in material characterization and biomedical engineering,” says study co-author Zhiming Chen, an engineer at China's Wuyi University. “The technology could also be incorporated into robots and prosthetics, which is our next research topic.”

ADVERTISEMENT

The new “finger” contains a carbon fiber tactile sensor, which returns a stronger signal when compressed against stiffer objects. The device moves across an object's surface, poking several times at each location to feel for increasing levels of pressure. This process can reveal subsurface details, such as hard layers inside softer materials. “When pressed by this bionic finger, hard objects retain their shape, whereas soft objects deform when sufficient pressure is applied,” says Wuyi engineer Jian Yi Luo, the study's senior author. “This information is transmitted to a computer, along with the recorded position, and displayed in real time as a 3-D image.”

Other imaging methods, including x-ray, PET, MRI and ultrasound, have their own pros and cons. X-rays carry health risks, and other options lack portability or speed. Many are expensive. The new device is unlikely to be significantly cheaper than ultrasound, but it may provide better resolution. “It offers another way of doing things, which has its own advantages in specific contexts,” says University College London engineer Sriram Subramanian, who was not involved in the work. “I don't think it's easy to do ultrasound imaging of printed electronic circuits.”

In simulated human tissue, the device pinpointed bones and a blood vessel. For a flexible electronic circuit encapsulated in soft material, it detected a circuit break and an incorrectly drilled hole. “When we make those [devices], we always worry that if something is broken, the only way you can know is to take it apart,” Subramanian says.

The device will struggle to map objects whose outer surface is too hard, and it may miss details underneath hard layers. The researchers plan to extend their invention into more dimensions, however, perhaps probing from other directions as well. “This system might be expanded to multiple fingers, just like our hands, to realize ‘omnidirectional’ detection,” Chen says. “This would enable it to get more complete information.”",https://www.scientificamerican.com/article/bionic-finger-sees-inside-objects-by-poking-them/
"April 28, 2023- Michael Eisenstein and Nature magazine",Proteins Never Seen in Nature Are Designed Using AI to Address Biomedical and Industrial Problems Unsolved by Evolution,"Machine learning (ML) and other AI- based computational tools have proven their prowess at predicting real-world protein structures. AlphaFold 2, an algorithm developed by scientists at DeepMind that can confidently predict protein structure purely on the basis of an amino acid sequence, has become almost a household name since its launch in July 2021. Today, AlphaFold 2 is used routinely by many structural biologists, with over 200 million structures predicted.

This ML toolbox appears capable of generating made-to-order proteins too, including those with functions not present in nature. This is an appealing prospect because, despite natural proteins’ vast molecular diversity, there are many biomedical and industrial problems that evolution has never been compelled to solve.

Scientists are now rapidly moving toward a future in which they can apply careful computational analysis to infer the underlying principles governing the structure and function of real-world proteins and apply them to construct bespoke proteins with functions devised by the user. Lucas Nivon, CEO and cofounder of Cyrus Biotechnology, believes the ultimate impact of such in silico-designed proteins will be massive and compares the field to the fledgling biotech industry of the 1980s. “I think in 30 years 30, 40 or 50 percent of drugs will be computationally designed proteins,” he says.

ADVERTISEMENT

To date, companies operating in the protein design space have largely focused on retooling existing proteins to perform new tasks or enhance specific properties, rather than true design from scratch. For example, scientists at Generate Biomedicines have drawn on existing knowledge about the SARS-CoV-2 spike protein and its interactions with the receptor protein ACE2 to design a synthetic protein that can consistently block viral entry across diverse variants. “In our internal testing, this molecule is quite resistant to all of the variants that we’ve seen thus far,” says cofounder and chief technology officer Gevorg Grigoryan, adding that Generate aims to apply to the FDA to clear the way for clinical testing in the second quarter of this year. More ambitious programs are on the horizon, although it remains to be seen how soon the leap to de novo design—in which new proteins are built entirely from scratch—will come.

The field of AI-assisted protein design is blossoming, but the roots of the field stretch back more than two decades, with work by academic researchers like David Baker and colleagues at what is now the Institute for Protein Design at the University of Washington. Starting in the late 1990s, Baker—who has co-founded companies in this space including Cyrus, Monod and Arzeda-oversaw the development of Rosetta, a foundational software suite for predicting and manipulating protein structures.

Since then, Baker and other researchers have developed many other powerful tools for protein design, powered by rapid progress in ML algorithms—and particularly, by advances in a subset of ML techniques known as deep learning. This past September, for example, Baker’s team published their deep learning ProteinMPNN platform, which allows them to input the structure they want and have the algorithm spit out an amino acid sequence likely to produce that de novo structure, achieving a greater than 50 percent success rate.

Some of the greatest excitement in the deep learning world relates to generative models that can create entirely new proteins, never seen before in nature. These modeling tools belong to the same category of algorithms used to produce eerie and compelling AI-generated artwork in programs like Stable Diffusion or DALL-E 2 and text in programs like chatGPT. In those cases, the software is trained on vast amounts of annotated image data and then uses those insights to produce new pictures in response to user queries. The same feat can be achieved with protein sequences and structures, where the algorithm draws on a rich repository of real-world biological information to dream up new proteins based on the patterns and principles observed in nature. To do this, however, researchers also need to give the computer guidance on the biochemical and physical constraints that inform protein design, or else the resulting output will offer little more than artistic value.

One effective strategy to understand protein sequence and structure is to approach them as ‘text’, using language modeling algorithms that follow rules of biological ‘grammar’ and ‘syntax’. “To generate a fluent sentence or a document, the algorithm needs to learn about relationships between different types of words, but it needs to also learn facts about the world to make a document that’s cohesive and makes sense,” says Ali Madani, a computer scientist formerly at Salesforce Research who recently founded Profluent.

ADVERTISEMENT

In a recent publication, Madani and colleagues describe a language modeling algorithm that can yield novel computer-designed proteins that can be successfully produced in the lab with catalytic activities comparable to those of natural enzymes. Language modeling is also a key part of Arzeda’s toolbox, according to co-founder and CEO Alexandre Zanghellini. For one project, the company used multiple rounds of algorithmic design and optimization to engineer an enzyme with improved stability against degradation. “In three rounds of iteration, we were able to go from complete disappearance of the protein after four weeks to retention of effectively 95 percent activity,” he says.

A recent preprint from researchers at Generate describes a new generative modeling-based design algorithm called Chroma, which includes several features that improve its performance and success rate. These include diffusion models, an approach used in many image-generation AI tools that makes it easier to manipulate complex, multidimensional data. Chroma also employs algorithmic techniques to assess long-range interactions between residues that are far apart on the protein’s chain of amino acids, called a backbone, but that may be essential for proper folding and function. In a series of initial demonstrations, the Generate team showed that they could obtain sequences that were predicted to fold into a broad array of naturally occurring and arbitrarily chosen structures and subdomains—including the shapes of the letters of the alphabet—although it remains to be seen how many will form these folds in the lab.

In addition to the new algorithms’ power, the tremendous amount of structural data captured by biologists has also allowed the protein design field to take off. The Protein Data Bank, a critical resource for protein designers, now contains more than 200,000 experimentally solved structures. The Alpha-Fold 2 algorithm is also proving to be a game changer here in terms of providing training material and guidance for design algorithms. “They are models, so you have to take them with a grain of salt, but now you have this extraordinarily large amount of predicted structures that you can build upon,” says Zanghellini, who says this tool is a core component of Arzeda’s computational design workflow.

Sign up for Scientific American’s free newsletters.

Sign Up

For AI-guided design, more training data are always better. But existing gene and protein databases are constrained by a limited range of species and a heavy bias towards humans and commonly used model organisms. Basecamp Research is building an ultra-diverse repository of biological information obtained from samples collected in biomes in 17 countries, ranging from the Antarctic to the rainforest to hydrothermal vents on the ocean floor. Chief technology officer Philipp Lorenz says that once the genomic data from these specimens are analyzed and annotated, they can assemble a knowledge-graph that can reveal functional relationships between diverse proteins and pathways that would not be obvious purely on the basis of sequence-based analysis. “It’s not just generating a new protein,” says Lorenz. “We are finding protein families in prokaryotes that have been thought to exist only in eukaryotes.” [Prokaryotes, single-celled organisms such as bacteria, lack the more sophisticated internal cellular structures found in eukaryotes, which are capable of becoming multicellular organisms.]

This means many more starting points for AI-guided protein design efforts, and Lorenz says that his team’s own design experiments have achieved an 80 percent success rate at producing functional proteins.

ADVERTISEMENT

But proteins do not function in a vacuum. Tess van Stekelenburg, an investor at Hummingbird Ventures, notes that Basecamp, one of the companies funded by the firm, captures all manner of environmental and biochemical context for the proteins it identifies. The resulting ‘metadata’ accompanying each protein sequence can help guide the engineering of proteins that express and function optimally in particular conditions. “It gives you a lot more ability to constrain for things like pH, temperature or pressure, if that’s what you’re planning to look at,” she says.

Some companies are also looking to augment public structural biology resources with data of their own. Generate is in the process of building a multi-instrument cryo-electron microscopy facility, which will allow them to generate near-atomic-resolution structures at relatively high throughput. Such internally generated structural data are more likely to include relevant metadata about individual proteins than data from publicly available resources.

In-house wet lab facilities are another critical component of the design process because experimental results are, in turn, used to train the algorithm to achieve even better outcomes in future rounds. Grigoryan notes that, although Generate likes to spotlight its algorithmic tool- box, the majority of its workforce comprises experimentalists.

And Bruno Correia, a computational biologist at the École Polytechnique Fédérale de Lausanne, says that the success of a protein design effort depends on close consultation between algorithm experts and experienced wet-lab practitioners. “This notion of how protein molecules are and how they behave experimentally builds in a lot of constraints,” says Correia. “I think it’s a mistake to handle biological entities just as a piece of data.”

Biological validation is an extremely important consideration for investors in this sector, says van Stekelenburg. “If you are doing de novo, the real gold standard is not which architecture are you using—it’s what percentage of your designed proteins had the end desired property,” she says. “If you can’t show that, then it doesn’t make sense.” Accordingly, most companies pursuing computational design are still focused on tuning protein function rather than overhauling it, shortening the leap between prediction and performance.

ADVERTISEMENT

Nivon says that Cyrus typically works with existing drugs and proteins that fall short in a particular parameter. “This could be a drug that needs better efficacy, lower immunogenicity or a better toxicity profile,” he says. For Cradle, the primary goal is to improve protein therapeutics by optimizing properties like stability. “We’ve benchmarked our model against empirical studies so that people can get a sense of how well this might work in an experimental setting,” says founder and CEO Stef van Grieken.

Arzeda’s focus is on enzyme engineering for industrial applications. They have already succeeded in creating proteins with novel catalytic functions for use in agriculture, materials and food science. These projects often begin with a relatively well-established core reaction that is catalyzed in nature. But to adapt these reactions to work with a different subtrate, “you need to remodel the active site dramatically,” says Zanghellini. Some of the company’s projects include a plant enzyme that can break down a widely used herbicide, as well as enzymes that can convert relatively low-value plant byproducts into useful natural sweeteners.

Generate’s first-generation engineering projects have focused on optimization. In one published study, company scientists showed that they could “resurface” the amino acid-metabolizing enzyme l-asparaginase from Escherichia coli bacteria, altering the amino acid composition of its exterior to greatly reduce its immunogenicity. But with the new Chroma algorithm, Grigoryan says that Generate is ready to embark on more ambitious projects, in which the algorithm can start building true de novo designs with user-designated structural and functional features. Of course, Chroma’s design proposals must then be validated by experimental testing, although Grigoryan says “we’re very encouraged by what we’ve seen.”

Zanghellini believes the field is near an inflection point. “We’re starting to see the possibility of really truly creating a complex active site and then building the protein around it,” he says. But he adds that many more challenges await. For example, a protein with excellent catalytic properties might be exceedingly difficult to manufacture at scale or exhibit poor properties as a drug. In the future, however, next-generation algorithms should make it possible to generate de novo proteins optimized to tick off many boxes on a scientist’s wish list rather than just one.

This article is reproduced with permission and was first published on February 23, 2023.

ADVERTISEMENT",https://www.scientificamerican.com/article/proteins-never-seen-in-nature-are-designed-using-ai-to-address-biomedical-and-industrial-problems-unsolved-by-evolution/
"April 27, 2023- Anne C. Mulkern and E&E News",What It Would Take for Electric Vehicles to Help Power the Grid,"CLIMATEWIRE | A new California bill would turn electric vehicles into a backup power supply for the state’s troubled grid.

But experts say the idea- while promising- still has some technological hurdles to overcome. And they warn that mandates such as the one prescribed in the California measure could increase the cost of electric vehicles.

Under the proposal put forward by Democratic state Sen. Nancy Skinner, all new electric vehicles sold in California starting in 2027 would need the ability to both store and send power. Her measure passed out of a Senate committee this week after clearing another committee last week. Dozens of environmental, health and community groups support it, while the largest automakers’ trade group opposes it.

ADVERTISEMENT

The intent of the proposal is to provide California with electricity on days when supplies are tight, Skinner said at a recent state Senate committee hearing. And EVs could make a real difference, she added.

The state wants 8 million zero-emissions vehicles on its roads by 2030, and “if less than 10 percent of those EVs were to be utilized in this way, it would have more gigawatt capacity” than the Diablo Canyon nuclear power plant in San Luis Obispo County, Calif., Skinner said. “So there's great potential here.”

Already, California is on its way toward electrifying its car fleet.

California announced last week that more than 1.5 million electric vehicles have been sold in the state through March (Climatewire, April 21), and that more than 1 in 5 new car purchases were zero-emissions options. Currently, about 40 percent of all EVs sold in the United States are in the Golden State.

But more work is needed to make EVs universally ready to send power to the grid, experts said.

ADVERTISEMENT

One obstacle is that EVs export direct current, but power sent to the grid needs to be alternating current. A conversion either needs to come inside the vehicle, or in a wall plug.

Requiring that all EVs are available for two-way charging- as mandated by the California bill- would add a few hundred dollars to their price, said Gil Tal, director of the Electric Vehicle Research Center at the University of California, Davis. Another option is using equipment known as a vehicle-to-grid-capable charger. But that's a few thousand dollars, Tal said.

Additionally, automakers use different charger technologies, Tal said, so there’s no universal wall converter option. There also are no current regulatory incentives for motorists to send EV power back to the grid.

Sign up for Scientific American’s free newsletters.

Sign Up

Safety issues are a concern too, said Andrew Meintz, chief engineer for electric vehicle charging and grid at the National Renewable Energy Laboratory.

Any inverter connected to the grid needs an Underwriters Laboratories certification. That requires testing “to make sure that it doesn't catch fire, that doesn't shock you,” he said. The standards haven’t yet been written for vehicle to grid applications, he said, and until that’s done, it can't go through the testing.

ADVERTISEMENT

Commercial fleets might be best positioned to give power to the grid, he said, since their use and charging schedules are more set than those of individual drivers. There also are ongoing studies with electric buses sending power to the grid, and that’s another more likely option, he said.

A FEW AUTOMAKERS MOVING AHEAD

Some EVs, however, are ready for two-way charging- including the Nissan Leaf and the Ford F-150 Lightning truck.

Last September, Nissan said a two-way charger from Fermata Energy could be used with the Nissan Leaf, model years 2013 and later. Nissan would not say how much power the Leaf could send back to the grid.

The EV Ford truck is currently aimed at providing backup power to a home, not the grid.

Ford’s F-150 Lightning truck can power a home during a power outage for up to three days, or up to 10 with power rationing, according to the company. But right now, there is no avenue to use the truck to power a grid.

ADVERTISEMENT

Meanwhile, Tesla plans to have all its cars capable of two-way charging “within the next model year,” Skinner said at a hearing of the state Senate Committee on Energy, Utilities and Communications earlier this month.

Tesla did not respond to requests for information on its plans.

But Tesla cars could be ready because they operate on a closed system, Tal said, where the company makes both the EVs and the chargers.

Some EV advocates oppose mandates, such as in the bill.

“Having a 2027 rollout- which would mean that the engineering has to start now- adds unnecessary cost for kind of a benefit that we're uncertain of,” said Orville Thomas, state policy director with CalStart, a nonprofit advancing clean transportation.

ADVERTISEMENT

The state has a new regulation advancing electric vehicles, banning sales of new gas-fueled cars after 2035. It also requires certain battery standards, Thomas said. How would two-way charging work with those rules, he said.

“Is that going to mean that the battery needs to be replaced for the second user?” he said. “Will the state of charge be less because you're drawing down on the battery and its duty cycles are being compromised?”

The Alliance for Automotive Innovation, the largest trade group for automakers, said in a letter to Skinner that the mandate would add more than $3,000 to each vehicle's cost. There also are questions about the state grid's readiness to support two-way charging, it said.

“The many unknowns of how to implement such a complex and nascent technology are too challenging at this time to establish a mandate,” it said in the letter.

TWO-WAY CHARGING

Several utilities are working on pilots studying both two-way charging and incentives for EV owners to charge their vehicles at the most opportune times for the grid.

Ford is running pilots with Pacific Gas and Electric Co. in the San Francisco region and the Sacramento Municipal Utility District. With PG&E, Ford is testing how its vehicle-to-home system could help customers during grid outages.

Beyond that, a Ford spokesperson said in an email, it’s testing vehicle-to-grid capabilities through the F-150 Lightning and “exploring how a customer's car’s battery can be used to send power back to the grid, a process that could potentially allow drivers to make money by selling electricity back to utility companies in times of high community power usage.”

In the pilot with the Sacramento Municipal Utility District, Ford said it’s looking at ways to support charging at off-peak hours.

BMW has run several pilot with PG&E since 2015, looking at incentives for off-peak charging as well as “exploration of V2G [vehicle-to-grid] possibilities,” Katrina St. Jean, a BMW spokesperson, said in an email.

“The BMW Group believes that vehicles can play a larger role in supporting the grid as new vehicle technologies are developed,” she said.

Reprinted from E&E News with permission from POLITICO, LLC. Copyright 2023. E&E News provides essential news for energy and environment professionals.",https://www.scientificamerican.com/article/what-it-would-take-for-electric-vehicles-to-help-power-the-grid/
"April 24, 2023- Sophie Bushwick and Kelso Harper",AI Chatbots and the Humans Who Love Them,Humans are building meaningful relationships with AI chatbots. What will the consequences be?,https://www.scientificamerican.com/podcast/episode/ai-chatbots-and-the-humans-who-love-them/
"April 21, 2023- Allison Parshall",How This AI Image Won a Major Photography Competition,"In March the Sony World Photography Awards announced the winning entry in their creative photo category: a black-and-white image of an older woman embracing a younger one, entitled PSEUDOMNESIA: The Electrician. The press release announcing the win describes the photograph as “haunting” and “reminiscent of the visual language of 1940s family portraits.”

But the artist, Berlin-based Boris Eldagsen, turned down the award. His photograph was not a photograph at all, he announced: he had crafted it through creative prompting of DALL-E 2, an artificial intelligence image generator.

“I applied as a cheeky monkey, to find out if the [competitions] are prepared for AI images to enter. They are not,” Eldagsen explained on his website. His stunt has sparked controversy and conversation about when AI-generated or assisted images should be considered art.

ADVERTISEMENT

Scientific American spoke with Eldagsen about the image’s creation and the future of AI-aided “promptography.”

[An edited transcript of the interview follows.]

How did you get started with AI art?

I started with photography because drawing was a lonely job. I was always experimenting. So when AI generators started, I was hooked from the very beginning. For me, as an artist, AI generators are absolute freedom. It’s like the tool I have always wanted. I was always working from my imagination as a photographer, and now the material I work with is knowledge. And if you are older, it’s a plus, because you can put all your knowledge into prompting and creating images. If I were 15, I would have probably just generated Batman.

Where did the inspiration for The Electrician come from?

ADVERTISEMENT

I did it for myself as an exercise, and I just love the result. It sparked off from a project that started years back. My father was born in 1924. So he went to war when he was 17 but, like most of that generation in Germany, never talked about it. After his death, I found some images from the forties my mom and I hadn’t seen before. I learned a lot about their time just looking at these images, and I started to collect images from the forties at flea markets, and also on eBay, but didn’t know what to do with them.

So my first experiment was: Can I re-create images of that time using AI? And then “The Electrician” just grew. The best images are those you didn’t have in your mind before. They came out of the process. You start, and it leads you somewhere—with AI it’s the same. You start somewhere and then you make many different decisions. You delete elements, you add frames. Sometimes the AI has very good suggestions. Sometimes it’s just crap. That takes time and patience, so it’s not finished in 20 seconds. It can take days.

So how did you actually make this image?

Sign up for Scientific American’s free newsletters.

Sign Up

I used DALL-E 2, and it was all done by text prompts and inpainting and outpainting. For inpainting, you could say, “I don’t like his tie,” and you erase it and write, “I want him to have a white tie.” Then you get suggestions. And if you don’t like any of those suggestions, you start again. Outpainting [is what] you do when the frame is not large enough. You put in an additional frame so you can see his whole tie, his pants, the chair, the floor. It’s endless.

Why did you decide to submit it to a photography competition?

ADVERTISEMENT

I’ve been very involved in AI and photography—I’ve become one of the experts in Germany—so it’s not just me poking fun. I wanted to test if a competition has taken into account that AI-generated images can be sent in. I applied to three different competitions, and the image always was a finalist. There’s something about the image. When I apply, I don’t say it’s AI-generated. I keep the information very short: just the image and the title. Then when it was selected, I said the art is AI-generated.

What I was hoping for has happened: the conversation has started, and it was basically with the help of the community. I did not expect it to be that big; I thought it would have been a conversation for a week in the European photo scene.

Do you think someone could have figured out that it was AI-generated just by looking at the image?

Of course. There’s a difference in color that comes through outpainting. On the left side it’s too yellow, and on the right side it changes into black and white. And then maybe the fingers, but also part of the arm on the right side, you can tell. If you work with it on a daily basis, like I do, you can tell.

Have you ever been fooled by an AI image?

ADVERTISEMENT

There’s a German magazine called GEO; it’s something like National Geographic in Germany. They had an online test with images, asking “Is it generated or authentic?” I failed once.

I think with The Electrician, it’s very easy to tell because it’s an old image from early last September. But I think by the end of this year, we won’t be able to tell.

Does that alarm you?

As an artist, I just love it. As a citizen, I’m deeply concerned. Most kinds of photography can be augmented by AI but not the photojournalism part. The press needs to come up with a system to make it clear what is authentic, manipulated or generated. The Pope Balenciaga AI-generated photo should have always been notated. If you don’t do that, democracy will be manipulated and misinformed by anyone who can write five words.

But to fact-check is a lot of work. That takes time. So for the press to do that, to pay all the staff and to also have AI technology to help—who is going to pay for this? Now as the citizens, I say, we cannot let the press work alone. It’s very important for a democratic society [to be able to distinguish real photos from fakes]. So we have to think about the structure to co-finance that [fact-checking] as citizens, as a democratic state. But how can we co-finance it and still maintain the freedom of press? This is something we need to think about.

ADVERTISEMENT

So the future of democracy and journalism aside—how will AI fit in the art world?

One thing I propose is to clean up the terminology and not call realistic AI art “AI photography” anymore, because it’s not photography. And one suggestion that came out of the community was “promptography,” and I just love it. It is large enough to encompass that the result can look like a drawing, like a painting, like a photo.

The next step would be to talk about the relationship between promptography and photography. Do they belong into one basket—one museum, festival, gallery, competition? It’s very complex. And I don’t have any answer for that. The only thing I can say is that the easy answers on both sides—those who want to go back to analog times and those who say promptography is photography—are nonsense. We need to think deeper than that.",https://www.scientificamerican.com/article/how-my-ai-image-won-a-major-photography-competition/
12 minutes ago- Starre Vartan,Astronomy Tool Can Now Detect COVID in Breath,"Astronomers and physicists have long used a laser-based sensor called an “optical frequency comb” to study the material makeup of the cosmos and to make timekeeping more accurate. But the COVID pandemic has pushed this versatile tool from the world of space and physics into health care.

Optical frequency combs are lasers that simultaneously shoot pulses of light at multiple frequencies. Because these superfast pulses are precisely spaced along the light spectrum—from infrared through the visible colors to ultraviolet—they form a series of peaks on a graph of the frequencies that look like the teeth of a comb. This “comb” can be used in a variety of ways. For instance, different types of molecules absorb different colors of light; by detecting which colors of light are absorbed near specific frequencies, the comb can identify specific molecules in an air sample. In a recent study, scientists proved this tool can detect COVID from Breathalyzer-type tests in which subjects simply blow into a tube—potentially paving the way for fast, noninvasive diagnostic tests for a multitude of diseases.

Every time humans exhale, we expel more than 1,000 kinds of trace molecules called volatile organic compounds, or VOCs. “Changes in VOC profiles can be linked to specific health conditions,” says Cristina Davis, associate vice chancellor for interdisciplinary research and strategic initiatives at the University of California, Davis. Scholars have known for millennia that certain breath odors are associated with clinical diseases or disorders. References in ancient Greek and Chinese medical literature indicate that doctors used the nose as a diagnostic tool, Davis says. More recently, dogs have been trained to identify some diseases in humans—and laser comb detectors also need training, says physicist Jun Ye, co-author of the new study. “We are training our frequency comb nose using machine learning, and once it’s trained, it becomes an electronic dog—with much greater sensitivity,” Ye says.

ADVERTISEMENT

This powerful artificial nose has the advantage of being able to sniff out disease in a way that’s quick and noninvasive, says the study’s lead author, Qizhong Liang, a graduate student at the University of Colorado Boulder. For maximum accuracy, Liang adds, positive results from the new technology’s COVID tests should be followed up with a more reliable PCR test. But for quick screening at airports, concert venues or hospitals, it could beat other methods, such as body temperature scans, that are used to assess potential COVID infection without requiring an invasive nose swab.

Frequency combs can do more than identify molecules. They were originally developed in the 1990s to make more accurate optical atomic clocks, for which the inventors won the 2005 Nobel Prize in Physics. The combs can measure the natural oscillation of atoms so precisely that they have become an indispensable component of atomic clocks, which keep time incredibly well by counting these oscillations. In astronomy, researchers use optical frequency combs to measure the frequencies of light coming from distant stars; disruptions can indicate a star has an exoplanet. In atmospheric science, they have been used to study greenhouse gases. And in 2008 Ye and his colleagues at JILA (a joint institute of the National Institute of Standards and Technology and the University of Colorado Boulder) first proved that the technology could be used as a breath test for disease biomarkers. They set this finding aside, but global events suddenly gave them a very good reason to revive the work in April 2020. “Using breath as a diagnostic tool has been around for a while,” Davis says, “but I think it took a pandemic for research interest to really to really be moved forward.”

Shortly after the COVID pandemic began, Ye got a call from his colleagues at the National Academies of Sciences, Engineering, and Medicine and the Air Force Office of Scientific Research. They wanted to know whether his early frequency comb “Breathalyzer” research might help develop a noninvasive COVID test.

Ye and his team started by updating their 2008 technology. The researchers extended the laser comb’s frequency range from the near-infrared region of the spectrum into the mid-infrared part—where molecules absorb light two to three times more strongly. That signal boost allowed the researchers to improve the tool’s detection sensitivity by 1,000-fold, letting them identify molecules at extremely low concentrations on the scale of hundreds of parts per trillion.

Next, Ye’s team collected breath samples from 170 University of Colorado Boulder students and staff from May 2021 to January 2022. Each participant received conventional PCR nasal swab COVID tests, and about half were positive. The researchers then used the frequency comb to analyze light-absorption patterns among molecules in the participants’ breath. Applying machine learning to the frequency comb data, combined with the already-known PCR data on who was positive or negative, they found six “discriminating molecules” that indicated COVID infection. The work was described in a paper published in April in the Journal of Breath Research.

ADVERTISEMENT

Liang says AI was key to the project’s success because of the vast amount of information the frequency comb gathers when analyzing breath. “Machine learning can analyze all of this data simultaneously and can automatically figure out the best way of utilizing all of that discriminating information to make a prediction model,” he says.

Frequency combs aren’t the only way to test human breath for COVID or other diseases. Other methods include gas chromatography/mass spectrometry systems such as the InspectIR test, which received emergency use authorization from the U.S. Food and Drug Administration in April 2022. In such chemistry-based techniques, the gas molecules to be analyzed are separated by an inert gas, broken down into fragments and then measured. Davis calls these types of tests the “gold standard,” but they require time, specialized training and bulky equipment that limits their use to the lab. Davis has been working on a smaller, portable type of test, an ion mobility spectrometer, which identifies substances based on the mobility of their molecules in an electric field. Other options use chemicals that bind to VOCs to isolate and test them. “There are more than 15 companies working on a variety of these kinds of tests,” Davis says.

The frequency comb technology is different, Liang says, because it uses laser spectroscopy and therefore “detects the molecules in breath in a nondestructive way.” By this he means the comb does not cause a sample to degrade or create any unwanted by-products, as breath tests that rely on chemical reactions can. Frequency comb technology also has the potential to be really, really fast: it could potentially eventually provide results in seconds, compared with minutes in other breath tests.

Sign up for Scientific American’s free newsletters.

Sign Up

That said, you probably won’t see laser combs the next time you catch a flight. “Breath tests, in general, have not reached prime time yet,” says Wilbur Lam, a COVID test expert, pediatrician and biomedical engineer at Emory University and the Georgia Institute of Technology. With the frequency comb method, he says, “you get an optical signal, and whether that optical signal is truly indicative of a COVID infection really has to be proven. Right now, they’re showing some correlation. But how does it correlate with other types of conditions that could affect the breath?”

If frequency comb “Breathalyzers” do prove themselves in further research, they could make a huge difference in many clinical settings beyond rapid testing for COVID. Study co-author Kristen Bjorkman, director of interdisciplinary research at the BioFrontiers Institute, suggests this technology might one day be used to detect chronic obstructive pulmonary disease, kidney failure, lung and pancreatic cancers and even Alzheimer’s disease. Multiple early studies have provided preliminary evidence that the contents of exhaled breaths can be used for these diagnoses.

ADVERTISEMENT

Breathalyzer-style tests could also be ideal for diagnosing children, and Ye says some pediatricians have already approached him about a frequency comb test for asthma in kids. When a child shows up sick at the emergency room, Ye explains, a lot of invasive tests are required to determine if the symptoms are caused by a bacterial or viral illness or asthma. He says one Denver-based pediatrician told him, “‘Imagine you can do a breath analysis on children, which is totally noninvasive. Kids won’t cry if they have to just donate a breath.’”",https://www.scientificamerican.com/article/astronomy-tool-can-now-detect-covid-in-breath/
18 hours ago- George Musser,How AI Knows Things No One Told It,"No one yet knows how ChatGPT and its artificial intelligence cousins will transform the world, and one reason is that no one really knows what goes on inside them. Some of these systems’ abilities go far beyond what they were trained to do—and even their inventors are baffled as to why. A growing number of tests suggest these AI systems develop internal models of the real world, much as our own brain does, though the machines’ technique is different.

“Everything we want to do with them in order to make them better or safer or anything like that seems to me like a ridiculous thing to ask ourselves to do if we don’t understand how they work,” says Ellie Pavlick of Brown University, one of the researchers working to fill that explanatory void.

At one level, she and her colleagues understand GPT (short for generative pretrained transformer) and other large language models, or LLMs, perfectly well. The models rely on a machine-learning system called a neural network. Such networks have a structure modeled loosely after the connected neurons of the human brain. The code for these programs is relatively simple and fills just a few screens. It sets up an autocorrection algorithm, which chooses the most likely word to complete a passage based on laborious statistical analysis of hundreds of gigabytes of Internet text. Additional training ensures the system will present its results in the form of dialogue. In this sense, all it does is regurgitate what it learned—it is a “stochastic parrot,” in the words of Emily Bender, a linguist at the University of Washington. But LLMs have also managed to ace the bar exam, explain the Higgs boson in iambic pentameter, and make an attempt to break up their users’ marriage. Few had expected a fairly straightforward autocorrection algorithm to acquire such broad abilities.

ADVERTISEMENT

That GPT and other AI systems perform tasks they were not trained to do, giving them “emergent abilities,” has surprised even researchers who have been generally skeptical about the hype over LLMs. “I don’t know how they’re doing it or if they could do it more generally the way humans do—but they’ve challenged my views,” says Melanie Mitchell, an AI researcher at the Santa Fe Institute.

“It is certainly much more than a stochastic parrot, and it certainly builds some representation of the world—although I do not think that it is quite like how humans build an internal world model,” says Yoshua Bengio, an AI researcher at the University of Montreal.

At a conference at New York University in March, philosopher Raphaël Millière of Columbia University offered yet another jaw-dropping example of what LLMs can do. The models had already demonstrated the ability to write computer code, which is impressive but not too surprising because there is so much code out there on the Internet to mimic. Millière went a step further and showed that GPT can execute code, too, however. The philosopher typed in a program to calculate the 83rd number in the Fibonacci sequence. “It’s multistep reasoning of a very high degree,” he says. And the bot nailed it. When Millière asked directly for the 83rd Fibonacci number, however, GPT got it wrong: this suggests the system wasn’t just parroting the Internet. Rather it was performing its own calculations to reach the correct answer.

Although an LLM runs on a computer, it is not itself a computer. It lacks essential computational elements, such as working memory. In a tacit acknowledgement that GPT on its own should not be able to run code, its inventor, the tech company OpenAI, has since introduced a specialized plug-in—a tool ChatGPT can use when answering a query—that allows it to do so. But that plug-in was not used in Millière’s demonstration. Instead he hypothesizes that the machine improvised a memory by harnessing its mechanisms for interpreting words according to their context—a situation similar to how nature repurposes existing capacities for new functions.

This impromptu ability demonstrates that LLMs develop an internal complexity that goes well beyond a shallow statistical analysis. Researchers are finding that these systems seem to achieve genuine understanding of what they have learned. In one study presented last week at the International Conference on Learning Representations (ICLR), doctoral student Kenneth Li of Harvard University and his AI researcher colleagues—Aspen K. Hopkins of the Massachusetts Institute of Technology, David Bau of Northeastern University, and Fernanda Viégas, Hanspeter Pfister and Martin Wattenberg, all at Harvard—spun up their own smaller copy of the GPT neural network so they could study its inner workings. They trained it on millions of matches of the board game Othello by feeding in long sequences of moves in text form. Their model became a nearly perfect player.

ADVERTISEMENT

To study how the neural network encoded information, they adopted a technique that Bengio and Guillaume Alain, also at the University of Montreal, devised in 2016. They created a miniature “probe” network to analyze the main network layer by layer. Li compares this approach to neuroscience methods. “This is similar to when we put an electrical probe into the human brain,” he says. In the case of the AI, the probe showed that its “neural activity” matched the representation of an Othello game board, albeit in a convoluted form. To confirm this, the researchers ran the probe in reverse to implant information into the network—for instance, flipping one of the game’s black marker pieces to a white one. “Basically, we hack into the brain of these language models,” Li says. The network adjusted its moves accordingly. The researchers concluded that it was playing Othello roughly like a human: by keeping a game board in its “mind’s eye” and using this model to evaluate moves. Li says he thinks the system learns this skill because it is the most parsimonious description of its training data. “If you are given a whole lot of game scripts, trying to figure out the rule behind it is the best way to compress,” he adds.

This ability to infer the structure of the outside world is not limited to simple game-playing moves; it also shows up in dialogue. Belinda Li (no relation to Kenneth Li), Maxwell Nye and Jacob Andreas, all at M.I.T., studied networks that played a text-based adventure game. They fed in sentences such as “The key is in the treasure chest,” followed by “You take the key.” Using a probe, they found that the networks encoded within themselves variables corresponding to “chest” and “you,” each with the property of possessing a key or not, and updated these variables sentence by sentence. The system had no independent way of knowing what a box or key is, yet it picked up the concepts it needed for this task. “There is some representation of the state hidden inside of the model,” Belinda Li says.

Researchers marvel at how much LLMs are able to learn from text. For example, Pavlick and her then Ph.D. student Roma Patel found that these networks absorb color descriptions from Internet text and construct internal representations of color. When they see the word “red,” they process it not just as an abstract symbol but as a concept that has certain relationship to maroon, crimson, fuchsia, rust, and so on. Demonstrating this was somewhat tricky. Instead of inserting a probe into a network, the researchers studied its response to a series of text prompts. To check whether it was merely echoing color relationships from online references, they tried misdirecting the system by telling it that red is in fact green—like the old philosophical thought experiment in which one person’s red is another person’s green. Rather than parroting back an incorrect answer, the system’s color evaluations changed appropriately in order to maintain the correct relations.

Sign up for Scientific American’s free newsletters.

Sign Up

Picking up on the idea that in order to perform its autocorrection function, the system seeks the underlying logic of its training data, machine learning researcher Sébastien Bubeck of Microsoft Research suggests that the wider the range of the data, the more general the rules the system will discover. “Maybe we’re seeing such a huge jump because we have reached a diversity of data, which is large enough that the only underlying principle to all of it is that intelligent beings produced them,” he says. “And so the only way to explain all of this data is [for the model] to become intelligent.”

In addition to extracting the underlying meaning of language, LLMs are able to learn on the fly. In the AI field, the term “learning” is usually reserved for the computationally intensive process in which developers expose the neural network to gigabytes of data and tweak its internal connections. By the time you type a query into ChatGPT, the network should be fixed; unlike humans, it should not continue to learn. So it came as a surprise that LLMs do, in fact, learn from their users’ prompts—an ability known as “in-context learning.” “It’s a different sort of learning that wasn’t really understood to exist before,” says Ben Goertzel, founder of the AI company SingularityNET.

ADVERTISEMENT

One example of how an LLM learns comes from the way humans interact with chatbots such as ChatGPT. You can give the system examples of how you want it to respond, and it will obey. Its outputs are determined by the last several thousand words it has seen. What it does, given those words, is prescribed by its fixed internal connections—but the word sequence nonetheless offers some adaptability. Entire websites are devoted to “jailbreak” prompts that overcome the system’s “guardrails”—restrictions that stop the system from telling users how to make a pipe bomb, for example—typically by directing the model to pretend to be a system without guardrails. Some people use jailbreaking for sketchy purposes, yet others deploy it to elicit more creative answers. “It will answer scientific questions, I would say, better” than if you just ask it directly, without the special jailbreak prompt, says William Hahn, co-director of the Machine Perception and Cognitive Robotics Laboratory at Florida Atlantic University. “It’s better at scholarship.”

Another type of in-context learning happens via “chain of thought” prompting, which means asking the network to spell out each step of its reasoning—a tactic that makes it do better at logic or arithmetic problems requiring multiple steps. (But one thing that made Millière’s example so surprising is that the network found the Fibonacci number without any such coaching.)

In 2022 a team at Google Research and the Swiss Federal Institute of Technology in Zurich—Johannes von Oswald, Eyvind Niklasson, Ettore Randazzo, João Sacramento, Alexander Mordvintsev, Andrey Zhmoginov and Max Vladymyrov—showed that in-context learning follows the same basic computational procedure as standard learning, known as gradient descent. This procedure was not programmed; the system discovered it without help. “It would need to be a learned skill,” says Blaise Agüera y Arcas, a vice president at Google Research. In fact, he thinks LLMs may have other latent abilities that no one has discovered yet. “Every time we test for a new ability that we can quantify, we find it,” he says.

Although LLMs have enough blind spots not to qualify as artificial general intelligence, or AGI—the term for a machine that attains the resourcefulness of animal brains—these emergent abilities suggest to some researchers that tech companies are closer to AGI than even optimists had guessed. “They’re indirect evidence that we are probably not that far off from AGI,” Goertzel said in March at a conference on deep learning at Florida Atlantic University. OpenAI’s plug-ins have given ChatGPT a modular architecture a little like that of the human brain. “Combining GPT-4 [the latest version of the LLM that powers ChatGPT] with various plug-ins might be a route toward a humanlike specialization of function,” says M.I.T. researcher Anna Ivanova.

At the same time, though, researchers worry the window may be closing on their ability to study these systems. OpenAI has not divulged the details of how it designed and trained GPT-4, in part because it is locked in competition with Google and other companies—not to mention other countries. “Probably there’s going to be less open research from industry, and things are going to be more siloed and organized around building products,” says Dan Roberts, a theoretical physicist at M.I.T., who applies the techniques of his profession to understanding AI.

ADVERTISEMENT

And this lack of transparency does not just harm researchers; it also hinders efforts to understand the social impacts of the rush to adopt AI technology. “Transparency about these models is the most important thing to ensure safety,” Mitchell says.",https://www.scientificamerican.com/article/how-ai-knows-things-no-one-told-it/
"May 10, 2023- Meghan Bartels",Tweaking Vegetables’ Genes Could Make Them Tastier—And You’ll Get to Try Them Soon,"Today’s Brussels sprouts taste better than you might remember from childhood. It’s not that your refined adult palate appreciates them better. Rather a new variety has displaced the original vegetable. You can thank plant breeders for the change. And modern breeders, armed with new gene-editing technology, are looking to replicate Brussels sprouts’ reinvention.

In the late 1990s scientists identified specific chemicals, called glucosinolates, that made Brussels sprouts taste bitter. Plant breeders started growing old seeds, previously discarded for producing paltry harvests, to identify tastier versions with lower levels of these compounds. Then they crossed these delicious but low-yield plants with modern, more prolific individuals until they found a descendant that made plenty of tasty sprouts, transforming the once maligned vegetable from a bitter pill into a popular side dish.

But other veggies haven’t fared as well. That’s because most breeding decisions favor plant traits that matter to vegetable growers, not vegetable eaters. “I’d say disease resistance is probably the major focus these days of most breeding programs because that’s what imperils the ability of the farmer to grow the crop,” says Harry Klee, a professor emeritus of horticulture at the University of Florida, who specializes in tomatoes. “Quality traits are really completely ignored.”

ADVERTISEMENT

In addition, breeders who focus on consumer crops must navigate the controversy surrounding genetically modified organisms (GMOs). Although all domesticated species now have different genetics than their ancestors, in agriculture, the term GMO refers to a plant that carries genes imported from a completely different species—and these changes are subject to stricter regulation. But newer techniques are allowing breeders to work within the context of a plant’s own genome, making tweaks that don’t trigger complicated rules.

Flavor is challenging to target because different people have different preferences—plus, even under the best conditions, flavor quality is more complex than something like yield. “We’ve spent a lot of time and money figuring out what flavor is, and most breeding programs don’t have the capacity to measure those things,” Klee says.

But interest in prioritizing flavor is starting to build, thanks in part to new genetic technology such as the gene-snipping technique CRISPR and DNA sequencing that is cheap enough to use liberally. “There’s never been a better time to be a fruit breeder or a vegetable breeder because we have more tools and techniques,” says Susan Brown, an apple breeder at Cornell University.

Some companies are beginning to use those tools to tackle the challenge of developing tastier veggies. One company, Pairwise, is fighting the same compounds that plagued Brussels sprouts: glucosinolates. But this time researchers are modifying salad greens—and they’re armed with the science of gene editing.

Although kale, for instance, is particularly healthy, many prefer eating the less bitter romaine or iceberg lettuce. So Pairwise scientists figured out how to use CRISPR to edit a kalelike mustard green to fit that palate. They wanted to turn off the genes that code for an enzyme called myrosinase, which breaks down the glucosinolates and creates bitterness once the leaf is chewed in a diner’s mouth. The result is a healthy but less bitter green that the company is marketing this year under the brand Conscious Foods.

ADVERTISEMENT

This is an example of where flavor-minded gene editing can shine, says Tom Adams, co-founder and CEO of Pairwise. “From a gene-editing perspective, I think where taste comes in is that we can remove things that people don’t like,” he says. “It’s a lot more difficult to think about how you can bring in the really complex, great tastes.” To create those more complex tastes, Adams says, traditional breeding is still the best path.

Traditional breeding is the cornerstone of another high-tech flavor effort as well, one that seeks to reverse the ways of thinking that got us to tasteless vegetables in the first place. Instead of growing varieties that can withstand the storage and transportation needs of the agricultural system, a company called Plenty is shrinking the vast distance from the field to the table. Plenty grows its plants in indoor vertical farming facilities closer to consumers, so produce stays fresher, says Nate Storey, the company’s co-founder and chief science officer.

When Plenty decided to start with greens, he says, the team grew thousands of traditionally bred varieties in its facilities. Then the researchers adopted only the ones that resulted in the tastiest crops rather than trying to develop new varieties. “There’s no need to rebuild a wheel,” Storey says of the technique. “We just screen all the wheels that exist and find the ones that work best in our system.”

Sign up for Scientific American’s free newsletters.

Sign Up

This method does not always succeed, however. The company couldn’t find a tomato that thrived in its facilities, so it’s working on developing its own variety using a sped-up version of traditional breeding.

Tomatoes are a popular target. A third company is creating more flavorful tomatoes using epigenetics—changing the expression of genes instead of the genes themselves. Whereas Pairwise is snipping out the gene sequences that produce an enzyme that interferes with flavor, Sound Agriculture is programming gene expression. This approach dials down production of undesirable compounds by making their genetic sequences less accessible for transcription.

ADVERTISEMENT

Understanding how precisely to modify expression to get a desired result is still a work in progress, says Travis Bayer, co-founder and chief technology officer of Sound Agriculture. “The science of epigenetics in plants is really exciting and it’s something that is evolving pretty rapidly,” he says. The company’s first epigenetically grown product, a tomato dubbed Summer Swell, is due to hit shelves this spring. Other projects in the works focus on leafy greens, as well as a handful of fruits, Bayer says.

All these vegetable growers hope that more flavorful products on store shelves will convince people to consume the recommended allowances of fruits and vegetables—and do so better than decades of nutritional guidance have.

“Don’t waste your time talking about trying to educate people to eat better,” says Klee, the tomato breeding researcher. “Just give them products that taste better, that they want to eat.”",https://www.scientificamerican.com/article/tweaking-vegetables-genes-could-make-them-tastier-and-youll-get-to-try-them-soon/
"May 9, 2023- Simon Makin",Virtual Reality System Lets You Stop and Smell the Roses,"Virtual reality is already widespread in entertainment and is starting to spread to fields ranging from education to health care. But while vision and hearing interfaces are extremely advanced, and touch, or “haptics,” is improving, one key sense has been missing from the virtual world: smell.

That may be about to change. Engineer Xinge Yu of the City University of Hong Kong and his colleagues have developed a lightweight, flexible and wireless olfactory interface that can precisely deliver smells such as lavender, pineapple or green tea to VR users and more fully immerse them in scented virtual worlds. “Bringing smell into VR expands it into another dimension,” Yu says. “We wanted to develop something in a wearable, skin-integrated format that people can go anywhere with and use anytime.”

The team’s design was described in a paper published on Tuesday in Nature Communications. A key advantage is that it can control odor intensity. One demonstration in the study involved increasing the intensity of the smell generated as a woman in a four-dimensional movie brought a rose up to her nose.

ADVERTISEMENT

Credit: Yiming Liu et al., Nature Communications

Previous smell interfaces have typically used bottles of liquid perfume, an atomizer (a device that turns liquids into a fine mist) and some method of blowing the atomized droplets out. This works, but it is rigid and has limited operating time between refills, and it does not easily allow for controlling intensity. These drawbacks have made the devices less practical for VR systems.

The new design uses small paraffin wax pads infused with scents that are heated by an electrode to release an odor. A temperature-dependent resistor, or thermistor, senses the temperature, which controls the smell’s intensity. And a magnetic induction coil controls a metal plate that conducts heat away from the electrode to rapidly cool it down and shut off the scent. Arrays of these odor generators, which are millimeters in size, are incorporated into thin, flexible sheets of electronics.

The study describes two different device formats. The first is small enough that it can be stuck to a user’s top lip, but it includes only two odor generators. The second is worn like a face mask and has nine. Both are customizable with a selection of 30 odors, including gardenia, caramel, ginger, clove, mojito and coconut milk. Different combinations can be blended at varying intensities to create a palette of thousands of possible fragrances.

ADVERTISEMENT

The proximity to the user’s nose, together with clever engineering, allows for delays between activating and receiving a smell as short as 1.44 seconds. Atomizers are faster than this, but they lack the control of the new devices and are as small as they are ever going to get, says Judith Amores, a senior researcher at Microsoft Research and a research affiliate at the Massachusetts Institute of Technology, who studies olfactory interfaces for health applications but was not involved in the study. “An advantage of this system is they could miniaturize it even more,” she says. “That’s what’s exciting.”

The study includes demonstrations of possible applications beyond just augmenting VR, including communicating messages by smell and evoking emotions. The researchers suggest the devices could even be used to alleviate depressed mood or promote recall in people with age-related cognitive decline. “Scent is directly connected to the emotional and memory parts of the brain, so there are a lot of applications related to well-being and health,” Amores says. “It could also be used as a way to do olfactory training to help people who lost their sense of smell due to COVID.”

The researchers have already started shrinking things down further. They have a system that’s two to three times smaller now, and they aim to shrink it to something five to 10 times smaller in the future. “That’s the next step,” Yu says.

Sign up for Scientific American’s free newsletters.

Sign Up",https://www.scientificamerican.com/article/virtual-reality-system-lets-you-stop-and-smell-the-roses/
"May 1, 2023- Mark Fischetti","50, 100 & 150 Years Ago: May 2023","1973

Computer Privacy

“There is growing concern that computers constitute a dangerous threat to privacy. Since many computers contain personal data and are accessible from distant terminals, they are viewed as an unexcelled means of assembling large amounts of information about an individual or a group. It may soon be feasible to compile dossiers on an entire citizenry. However, a computer system can be adapted to guard its contents. Cryptographic encipherment can be achieved in two different ways: by ciphers or by codes. A cipher always assigns substitute symbols to some given set of alphabet letters. A code can convey only meanings thought of in advance and provided for in a secret list such as a code book. Other cryptographic approaches are still being studied.”

1923

King Tut's Bountiful Tomb

ADVERTISEMENT

“Biban el-Muluk, the valley of the kings' tombs, is a wild, desolate region behind the western plain of Thebes. Some 60 tombs in the valley were already known. On November 5, 1922, Howard Carter came upon a step cut in the rock under the path leading to the tomb of Ramses VI. The steps and passages of the L-shaped approach were cleared, leading to Tutenkhamon's tomb. The ante-chamber is the source of practically all the treasures removed this year. When we think of how much still lies within the tomb, it means work for two years or more if they are to be properly conserved, recorded and evaluated.”

Classy Vitamins

“The discovery of vitamins was made by [Frederick Gowland] Hopkins only as recently as 1912. The indispensability of these substances is now generally accepted. Three substances of the so-called vitamin class called A, B and C have been differentiated with certainty, and it is possible that more exist. They do not appear to be of one chemical type, and are effective in very small amounts. The green tissues of plants would seem to be the chief site of vitamin synthesis.”

Call It Insulin

“A product by the name of insulin has been prepared by Canadian biologists in Toronto, which is claimed to be a specific [remedy] against diabetes. The preparation is made from the pancreas of cattle, sheep and swine.”

ADVERTISEMENT
1873

Polaris Lost, Survivors Found

“Telegraphic despatches bring the news of the probable loss of the United States exploring steamer Polaris and the end of the Arctic expedition. On the 15th of October, 1872, a party of the crew, some nineteen souls, left the ship to place some provisions on an ice floe. A severe storm came on, causing the Polaris to part her moorings; the comrades on the ice, to their dismay, saw their vessel disappear. The tide and wind, it seems, fortunately drove the great floe, bearing the survivors, down through Baffin's Bay and Davis' straits until, on the 30th of April, they were rescued after 196 days on the ice, by the British steamer Tigress. The sufferings of the rescued party are described as terrible, but all were in comparatively good health.”

Tidal Power

Sign up for Scientific American’s free newsletters.

Sign Up

“A trial recently took place of Edward W. Morton's machine, at the East River. The machine works by means of a ‘float’ which, as it rises and falls with the waves or the tide, propels the machinery to which it may be attached. At the trial it was geared to a saw, and worked with the full rapidity of a circular saw run by steam power, although, perhaps, not quite so uniformly.”

Music from Fire

ADVERTISEMENT

“If into a glass tube two flames be introduced, at a distance of one third the length of the pipe, these flames will vibrate in unison. The phenomenon continues as long as the flames remain separate, but the sound ceases the moment they are brought in contact. If the position of the flames be varied, the sound decreases. M. Kastner has constructed a new musical instrument of a very peculiar timbre, closely resembling that of the human voice. The ‘pyrophone’ has three key boards; each key is in communication with the conduit pipes of the flames in the glass tubes. By pressing upon the keys, the flames separate and sound is produced. When the pressure is removed, it is instantly stilled by the junction of the flames.”",https://www.scientificamerican.com/article/50-100-150-may-2023/
"May 1, 2023- Simon Makin",Bionic Finger ‘Sees’ Inside Objects by Poking Them,"Human fingers don't just sense what a surface feels like. They also tell us a lot about what's underneath it: a really firm handshake, for example, can reveal where some bones are, and, with enough prodding, one can even locate tendons.

Inspired by this capability, scientists have developed a fingerlike device that maps an object's internal structures in 3-D by touching its surface. Earlier tactile sensors detected external shape, stiffness and texture but not subsurface details. For a study in Cell Reports Physical Science, the researchers tested their device by scanning simulated human tissue and electronic circuitry.

“This bionic finger has exciting application prospects in material characterization and biomedical engineering,” says study co-author Zhiming Chen, an engineer at China's Wuyi University. “The technology could also be incorporated into robots and prosthetics, which is our next research topic.”

ADVERTISEMENT

The new “finger” contains a carbon fiber tactile sensor, which returns a stronger signal when compressed against stiffer objects. The device moves across an object's surface, poking several times at each location to feel for increasing levels of pressure. This process can reveal subsurface details, such as hard layers inside softer materials. “When pressed by this bionic finger, hard objects retain their shape, whereas soft objects deform when sufficient pressure is applied,” says Wuyi engineer Jian Yi Luo, the study's senior author. “This information is transmitted to a computer, along with the recorded position, and displayed in real time as a 3-D image.”

Other imaging methods, including x-ray, PET, MRI and ultrasound, have their own pros and cons. X-rays carry health risks, and other options lack portability or speed. Many are expensive. The new device is unlikely to be significantly cheaper than ultrasound, but it may provide better resolution. “It offers another way of doing things, which has its own advantages in specific contexts,” says University College London engineer Sriram Subramanian, who was not involved in the work. “I don't think it's easy to do ultrasound imaging of printed electronic circuits.”

In simulated human tissue, the device pinpointed bones and a blood vessel. For a flexible electronic circuit encapsulated in soft material, it detected a circuit break and an incorrectly drilled hole. “When we make those [devices], we always worry that if something is broken, the only way you can know is to take it apart,” Subramanian says.

The device will struggle to map objects whose outer surface is too hard, and it may miss details underneath hard layers. The researchers plan to extend their invention into more dimensions, however, perhaps probing from other directions as well. “This system might be expanded to multiple fingers, just like our hands, to realize ‘omnidirectional’ detection,” Chen says. “This would enable it to get more complete information.”",https://www.scientificamerican.com/article/bionic-finger-sees-inside-objects-by-poking-them/
"April 28, 2023- Michael Eisenstein and Nature magazine",Proteins Never Seen in Nature Are Designed Using AI to Address Biomedical and Industrial Problems Unsolved by Evolution,"Machine learning (ML) and other AI- based computational tools have proven their prowess at predicting real-world protein structures. AlphaFold 2, an algorithm developed by scientists at DeepMind that can confidently predict protein structure purely on the basis of an amino acid sequence, has become almost a household name since its launch in July 2021. Today, AlphaFold 2 is used routinely by many structural biologists, with over 200 million structures predicted.

This ML toolbox appears capable of generating made-to-order proteins too, including those with functions not present in nature. This is an appealing prospect because, despite natural proteins’ vast molecular diversity, there are many biomedical and industrial problems that evolution has never been compelled to solve.

Scientists are now rapidly moving toward a future in which they can apply careful computational analysis to infer the underlying principles governing the structure and function of real-world proteins and apply them to construct bespoke proteins with functions devised by the user. Lucas Nivon, CEO and cofounder of Cyrus Biotechnology, believes the ultimate impact of such in silico-designed proteins will be massive and compares the field to the fledgling biotech industry of the 1980s. “I think in 30 years 30, 40 or 50 percent of drugs will be computationally designed proteins,” he says.

ADVERTISEMENT

To date, companies operating in the protein design space have largely focused on retooling existing proteins to perform new tasks or enhance specific properties, rather than true design from scratch. For example, scientists at Generate Biomedicines have drawn on existing knowledge about the SARS-CoV-2 spike protein and its interactions with the receptor protein ACE2 to design a synthetic protein that can consistently block viral entry across diverse variants. “In our internal testing, this molecule is quite resistant to all of the variants that we’ve seen thus far,” says cofounder and chief technology officer Gevorg Grigoryan, adding that Generate aims to apply to the FDA to clear the way for clinical testing in the second quarter of this year. More ambitious programs are on the horizon, although it remains to be seen how soon the leap to de novo design—in which new proteins are built entirely from scratch—will come.

The field of AI-assisted protein design is blossoming, but the roots of the field stretch back more than two decades, with work by academic researchers like David Baker and colleagues at what is now the Institute for Protein Design at the University of Washington. Starting in the late 1990s, Baker—who has co-founded companies in this space including Cyrus, Monod and Arzeda-oversaw the development of Rosetta, a foundational software suite for predicting and manipulating protein structures.

Since then, Baker and other researchers have developed many other powerful tools for protein design, powered by rapid progress in ML algorithms—and particularly, by advances in a subset of ML techniques known as deep learning. This past September, for example, Baker’s team published their deep learning ProteinMPNN platform, which allows them to input the structure they want and have the algorithm spit out an amino acid sequence likely to produce that de novo structure, achieving a greater than 50 percent success rate.

Some of the greatest excitement in the deep learning world relates to generative models that can create entirely new proteins, never seen before in nature. These modeling tools belong to the same category of algorithms used to produce eerie and compelling AI-generated artwork in programs like Stable Diffusion or DALL-E 2 and text in programs like chatGPT. In those cases, the software is trained on vast amounts of annotated image data and then uses those insights to produce new pictures in response to user queries. The same feat can be achieved with protein sequences and structures, where the algorithm draws on a rich repository of real-world biological information to dream up new proteins based on the patterns and principles observed in nature. To do this, however, researchers also need to give the computer guidance on the biochemical and physical constraints that inform protein design, or else the resulting output will offer little more than artistic value.

One effective strategy to understand protein sequence and structure is to approach them as ‘text’, using language modeling algorithms that follow rules of biological ‘grammar’ and ‘syntax’. “To generate a fluent sentence or a document, the algorithm needs to learn about relationships between different types of words, but it needs to also learn facts about the world to make a document that’s cohesive and makes sense,” says Ali Madani, a computer scientist formerly at Salesforce Research who recently founded Profluent.

ADVERTISEMENT

In a recent publication, Madani and colleagues describe a language modeling algorithm that can yield novel computer-designed proteins that can be successfully produced in the lab with catalytic activities comparable to those of natural enzymes. Language modeling is also a key part of Arzeda’s toolbox, according to co-founder and CEO Alexandre Zanghellini. For one project, the company used multiple rounds of algorithmic design and optimization to engineer an enzyme with improved stability against degradation. “In three rounds of iteration, we were able to go from complete disappearance of the protein after four weeks to retention of effectively 95 percent activity,” he says.

A recent preprint from researchers at Generate describes a new generative modeling-based design algorithm called Chroma, which includes several features that improve its performance and success rate. These include diffusion models, an approach used in many image-generation AI tools that makes it easier to manipulate complex, multidimensional data. Chroma also employs algorithmic techniques to assess long-range interactions between residues that are far apart on the protein’s chain of amino acids, called a backbone, but that may be essential for proper folding and function. In a series of initial demonstrations, the Generate team showed that they could obtain sequences that were predicted to fold into a broad array of naturally occurring and arbitrarily chosen structures and subdomains—including the shapes of the letters of the alphabet—although it remains to be seen how many will form these folds in the lab.

In addition to the new algorithms’ power, the tremendous amount of structural data captured by biologists has also allowed the protein design field to take off. The Protein Data Bank, a critical resource for protein designers, now contains more than 200,000 experimentally solved structures. The Alpha-Fold 2 algorithm is also proving to be a game changer here in terms of providing training material and guidance for design algorithms. “They are models, so you have to take them with a grain of salt, but now you have this extraordinarily large amount of predicted structures that you can build upon,” says Zanghellini, who says this tool is a core component of Arzeda’s computational design workflow.

Sign up for Scientific American’s free newsletters.

Sign Up

For AI-guided design, more training data are always better. But existing gene and protein databases are constrained by a limited range of species and a heavy bias towards humans and commonly used model organisms. Basecamp Research is building an ultra-diverse repository of biological information obtained from samples collected in biomes in 17 countries, ranging from the Antarctic to the rainforest to hydrothermal vents on the ocean floor. Chief technology officer Philipp Lorenz says that once the genomic data from these specimens are analyzed and annotated, they can assemble a knowledge-graph that can reveal functional relationships between diverse proteins and pathways that would not be obvious purely on the basis of sequence-based analysis. “It’s not just generating a new protein,” says Lorenz. “We are finding protein families in prokaryotes that have been thought to exist only in eukaryotes.” [Prokaryotes, single-celled organisms such as bacteria, lack the more sophisticated internal cellular structures found in eukaryotes, which are capable of becoming multicellular organisms.]

This means many more starting points for AI-guided protein design efforts, and Lorenz says that his team’s own design experiments have achieved an 80 percent success rate at producing functional proteins.

ADVERTISEMENT

But proteins do not function in a vacuum. Tess van Stekelenburg, an investor at Hummingbird Ventures, notes that Basecamp, one of the companies funded by the firm, captures all manner of environmental and biochemical context for the proteins it identifies. The resulting ‘metadata’ accompanying each protein sequence can help guide the engineering of proteins that express and function optimally in particular conditions. “It gives you a lot more ability to constrain for things like pH, temperature or pressure, if that’s what you’re planning to look at,” she says.

Some companies are also looking to augment public structural biology resources with data of their own. Generate is in the process of building a multi-instrument cryo-electron microscopy facility, which will allow them to generate near-atomic-resolution structures at relatively high throughput. Such internally generated structural data are more likely to include relevant metadata about individual proteins than data from publicly available resources.

In-house wet lab facilities are another critical component of the design process because experimental results are, in turn, used to train the algorithm to achieve even better outcomes in future rounds. Grigoryan notes that, although Generate likes to spotlight its algorithmic tool- box, the majority of its workforce comprises experimentalists.

And Bruno Correia, a computational biologist at the École Polytechnique Fédérale de Lausanne, says that the success of a protein design effort depends on close consultation between algorithm experts and experienced wet-lab practitioners. “This notion of how protein molecules are and how they behave experimentally builds in a lot of constraints,” says Correia. “I think it’s a mistake to handle biological entities just as a piece of data.”

Biological validation is an extremely important consideration for investors in this sector, says van Stekelenburg. “If you are doing de novo, the real gold standard is not which architecture are you using—it’s what percentage of your designed proteins had the end desired property,” she says. “If you can’t show that, then it doesn’t make sense.” Accordingly, most companies pursuing computational design are still focused on tuning protein function rather than overhauling it, shortening the leap between prediction and performance.

ADVERTISEMENT

Nivon says that Cyrus typically works with existing drugs and proteins that fall short in a particular parameter. “This could be a drug that needs better efficacy, lower immunogenicity or a better toxicity profile,” he says. For Cradle, the primary goal is to improve protein therapeutics by optimizing properties like stability. “We’ve benchmarked our model against empirical studies so that people can get a sense of how well this might work in an experimental setting,” says founder and CEO Stef van Grieken.

Arzeda’s focus is on enzyme engineering for industrial applications. They have already succeeded in creating proteins with novel catalytic functions for use in agriculture, materials and food science. These projects often begin with a relatively well-established core reaction that is catalyzed in nature. But to adapt these reactions to work with a different subtrate, “you need to remodel the active site dramatically,” says Zanghellini. Some of the company’s projects include a plant enzyme that can break down a widely used herbicide, as well as enzymes that can convert relatively low-value plant byproducts into useful natural sweeteners.

Generate’s first-generation engineering projects have focused on optimization. In one published study, company scientists showed that they could “resurface” the amino acid-metabolizing enzyme l-asparaginase from Escherichia coli bacteria, altering the amino acid composition of its exterior to greatly reduce its immunogenicity. But with the new Chroma algorithm, Grigoryan says that Generate is ready to embark on more ambitious projects, in which the algorithm can start building true de novo designs with user-designated structural and functional features. Of course, Chroma’s design proposals must then be validated by experimental testing, although Grigoryan says “we’re very encouraged by what we’ve seen.”

Zanghellini believes the field is near an inflection point. “We’re starting to see the possibility of really truly creating a complex active site and then building the protein around it,” he says. But he adds that many more challenges await. For example, a protein with excellent catalytic properties might be exceedingly difficult to manufacture at scale or exhibit poor properties as a drug. In the future, however, next-generation algorithms should make it possible to generate de novo proteins optimized to tick off many boxes on a scientist’s wish list rather than just one.

This article is reproduced with permission and was first published on February 23, 2023.

ADVERTISEMENT",https://www.scientificamerican.com/article/proteins-never-seen-in-nature-are-designed-using-ai-to-address-biomedical-and-industrial-problems-unsolved-by-evolution/
"April 27, 2023- Anne C. Mulkern and E&E News",What It Would Take for Electric Vehicles to Help Power the Grid,"CLIMATEWIRE | A new California bill would turn electric vehicles into a backup power supply for the state’s troubled grid.

But experts say the idea- while promising- still has some technological hurdles to overcome. And they warn that mandates such as the one prescribed in the California measure could increase the cost of electric vehicles.

Under the proposal put forward by Democratic state Sen. Nancy Skinner, all new electric vehicles sold in California starting in 2027 would need the ability to both store and send power. Her measure passed out of a Senate committee this week after clearing another committee last week. Dozens of environmental, health and community groups support it, while the largest automakers’ trade group opposes it.

ADVERTISEMENT

The intent of the proposal is to provide California with electricity on days when supplies are tight, Skinner said at a recent state Senate committee hearing. And EVs could make a real difference, she added.

The state wants 8 million zero-emissions vehicles on its roads by 2030, and “if less than 10 percent of those EVs were to be utilized in this way, it would have more gigawatt capacity” than the Diablo Canyon nuclear power plant in San Luis Obispo County, Calif., Skinner said. “So there's great potential here.”

Already, California is on its way toward electrifying its car fleet.

California announced last week that more than 1.5 million electric vehicles have been sold in the state through March (Climatewire, April 21), and that more than 1 in 5 new car purchases were zero-emissions options. Currently, about 40 percent of all EVs sold in the United States are in the Golden State.

But more work is needed to make EVs universally ready to send power to the grid, experts said.

ADVERTISEMENT

One obstacle is that EVs export direct current, but power sent to the grid needs to be alternating current. A conversion either needs to come inside the vehicle, or in a wall plug.

Requiring that all EVs are available for two-way charging- as mandated by the California bill- would add a few hundred dollars to their price, said Gil Tal, director of the Electric Vehicle Research Center at the University of California, Davis. Another option is using equipment known as a vehicle-to-grid-capable charger. But that's a few thousand dollars, Tal said.

Additionally, automakers use different charger technologies, Tal said, so there’s no universal wall converter option. There also are no current regulatory incentives for motorists to send EV power back to the grid.

Sign up for Scientific American’s free newsletters.

Sign Up

Safety issues are a concern too, said Andrew Meintz, chief engineer for electric vehicle charging and grid at the National Renewable Energy Laboratory.

Any inverter connected to the grid needs an Underwriters Laboratories certification. That requires testing “to make sure that it doesn't catch fire, that doesn't shock you,” he said. The standards haven’t yet been written for vehicle to grid applications, he said, and until that’s done, it can't go through the testing.

ADVERTISEMENT

Commercial fleets might be best positioned to give power to the grid, he said, since their use and charging schedules are more set than those of individual drivers. There also are ongoing studies with electric buses sending power to the grid, and that’s another more likely option, he said.

A FEW AUTOMAKERS MOVING AHEAD

Some EVs, however, are ready for two-way charging- including the Nissan Leaf and the Ford F-150 Lightning truck.

Last September, Nissan said a two-way charger from Fermata Energy could be used with the Nissan Leaf, model years 2013 and later. Nissan would not say how much power the Leaf could send back to the grid.

The EV Ford truck is currently aimed at providing backup power to a home, not the grid.

Ford’s F-150 Lightning truck can power a home during a power outage for up to three days, or up to 10 with power rationing, according to the company. But right now, there is no avenue to use the truck to power a grid.

ADVERTISEMENT

Meanwhile, Tesla plans to have all its cars capable of two-way charging “within the next model year,” Skinner said at a hearing of the state Senate Committee on Energy, Utilities and Communications earlier this month.

Tesla did not respond to requests for information on its plans.

But Tesla cars could be ready because they operate on a closed system, Tal said, where the company makes both the EVs and the chargers.

Some EV advocates oppose mandates, such as in the bill.

“Having a 2027 rollout- which would mean that the engineering has to start now- adds unnecessary cost for kind of a benefit that we're uncertain of,” said Orville Thomas, state policy director with CalStart, a nonprofit advancing clean transportation.

ADVERTISEMENT

The state has a new regulation advancing electric vehicles, banning sales of new gas-fueled cars after 2035. It also requires certain battery standards, Thomas said. How would two-way charging work with those rules, he said.

“Is that going to mean that the battery needs to be replaced for the second user?” he said. “Will the state of charge be less because you're drawing down on the battery and its duty cycles are being compromised?”

The Alliance for Automotive Innovation, the largest trade group for automakers, said in a letter to Skinner that the mandate would add more than $3,000 to each vehicle's cost. There also are questions about the state grid's readiness to support two-way charging, it said.

“The many unknowns of how to implement such a complex and nascent technology are too challenging at this time to establish a mandate,” it said in the letter.

TWO-WAY CHARGING

Several utilities are working on pilots studying both two-way charging and incentives for EV owners to charge their vehicles at the most opportune times for the grid.

Ford is running pilots with Pacific Gas and Electric Co. in the San Francisco region and the Sacramento Municipal Utility District. With PG&E, Ford is testing how its vehicle-to-home system could help customers during grid outages.

Beyond that, a Ford spokesperson said in an email, it’s testing vehicle-to-grid capabilities through the F-150 Lightning and “exploring how a customer's car’s battery can be used to send power back to the grid, a process that could potentially allow drivers to make money by selling electricity back to utility companies in times of high community power usage.”

In the pilot with the Sacramento Municipal Utility District, Ford said it’s looking at ways to support charging at off-peak hours.

BMW has run several pilot with PG&E since 2015, looking at incentives for off-peak charging as well as “exploration of V2G [vehicle-to-grid] possibilities,” Katrina St. Jean, a BMW spokesperson, said in an email.

“The BMW Group believes that vehicles can play a larger role in supporting the grid as new vehicle technologies are developed,” she said.

Reprinted from E&E News with permission from POLITICO, LLC. Copyright 2023. E&E News provides essential news for energy and environment professionals.",https://www.scientificamerican.com/article/what-it-would-take-for-electric-vehicles-to-help-power-the-grid/
"April 24, 2023- Sophie Bushwick and Kelso Harper",AI Chatbots and the Humans Who Love Them,Humans are building meaningful relationships with AI chatbots. What will the consequences be?,https://www.scientificamerican.com/podcast/episode/ai-chatbots-and-the-humans-who-love-them/
"April 21, 2023- Allison Parshall",How This AI Image Won a Major Photography Competition,"In March the Sony World Photography Awards announced the winning entry in their creative photo category: a black-and-white image of an older woman embracing a younger one, entitled PSEUDOMNESIA: The Electrician. The press release announcing the win describes the photograph as “haunting” and “reminiscent of the visual language of 1940s family portraits.”

But the artist, Berlin-based Boris Eldagsen, turned down the award. His photograph was not a photograph at all, he announced: he had crafted it through creative prompting of DALL-E 2, an artificial intelligence image generator.

“I applied as a cheeky monkey, to find out if the [competitions] are prepared for AI images to enter. They are not,” Eldagsen explained on his website. His stunt has sparked controversy and conversation about when AI-generated or assisted images should be considered art.

ADVERTISEMENT

Scientific American spoke with Eldagsen about the image’s creation and the future of AI-aided “promptography.”

[An edited transcript of the interview follows.]

How did you get started with AI art?

I started with photography because drawing was a lonely job. I was always experimenting. So when AI generators started, I was hooked from the very beginning. For me, as an artist, AI generators are absolute freedom. It’s like the tool I have always wanted. I was always working from my imagination as a photographer, and now the material I work with is knowledge. And if you are older, it’s a plus, because you can put all your knowledge into prompting and creating images. If I were 15, I would have probably just generated Batman.

Where did the inspiration for The Electrician come from?

ADVERTISEMENT

I did it for myself as an exercise, and I just love the result. It sparked off from a project that started years back. My father was born in 1924. So he went to war when he was 17 but, like most of that generation in Germany, never talked about it. After his death, I found some images from the forties my mom and I hadn’t seen before. I learned a lot about their time just looking at these images, and I started to collect images from the forties at flea markets, and also on eBay, but didn’t know what to do with them.

So my first experiment was: Can I re-create images of that time using AI? And then “The Electrician” just grew. The best images are those you didn’t have in your mind before. They came out of the process. You start, and it leads you somewhere—with AI it’s the same. You start somewhere and then you make many different decisions. You delete elements, you add frames. Sometimes the AI has very good suggestions. Sometimes it’s just crap. That takes time and patience, so it’s not finished in 20 seconds. It can take days.

So how did you actually make this image?

Sign up for Scientific American’s free newsletters.

Sign Up

I used DALL-E 2, and it was all done by text prompts and inpainting and outpainting. For inpainting, you could say, “I don’t like his tie,” and you erase it and write, “I want him to have a white tie.” Then you get suggestions. And if you don’t like any of those suggestions, you start again. Outpainting [is what] you do when the frame is not large enough. You put in an additional frame so you can see his whole tie, his pants, the chair, the floor. It’s endless.

Why did you decide to submit it to a photography competition?

ADVERTISEMENT

I’ve been very involved in AI and photography—I’ve become one of the experts in Germany—so it’s not just me poking fun. I wanted to test if a competition has taken into account that AI-generated images can be sent in. I applied to three different competitions, and the image always was a finalist. There’s something about the image. When I apply, I don’t say it’s AI-generated. I keep the information very short: just the image and the title. Then when it was selected, I said the art is AI-generated.

What I was hoping for has happened: the conversation has started, and it was basically with the help of the community. I did not expect it to be that big; I thought it would have been a conversation for a week in the European photo scene.

Do you think someone could have figured out that it was AI-generated just by looking at the image?

Of course. There’s a difference in color that comes through outpainting. On the left side it’s too yellow, and on the right side it changes into black and white. And then maybe the fingers, but also part of the arm on the right side, you can tell. If you work with it on a daily basis, like I do, you can tell.

Have you ever been fooled by an AI image?

ADVERTISEMENT

There’s a German magazine called GEO; it’s something like National Geographic in Germany. They had an online test with images, asking “Is it generated or authentic?” I failed once.

I think with The Electrician, it’s very easy to tell because it’s an old image from early last September. But I think by the end of this year, we won’t be able to tell.

Does that alarm you?

As an artist, I just love it. As a citizen, I’m deeply concerned. Most kinds of photography can be augmented by AI but not the photojournalism part. The press needs to come up with a system to make it clear what is authentic, manipulated or generated. The Pope Balenciaga AI-generated photo should have always been notated. If you don’t do that, democracy will be manipulated and misinformed by anyone who can write five words.

But to fact-check is a lot of work. That takes time. So for the press to do that, to pay all the staff and to also have AI technology to help—who is going to pay for this? Now as the citizens, I say, we cannot let the press work alone. It’s very important for a democratic society [to be able to distinguish real photos from fakes]. So we have to think about the structure to co-finance that [fact-checking] as citizens, as a democratic state. But how can we co-finance it and still maintain the freedom of press? This is something we need to think about.

ADVERTISEMENT

So the future of democracy and journalism aside—how will AI fit in the art world?

One thing I propose is to clean up the terminology and not call realistic AI art “AI photography” anymore, because it’s not photography. And one suggestion that came out of the community was “promptography,” and I just love it. It is large enough to encompass that the result can look like a drawing, like a painting, like a photo.

The next step would be to talk about the relationship between promptography and photography. Do they belong into one basket—one museum, festival, gallery, competition? It’s very complex. And I don’t have any answer for that. The only thing I can say is that the easy answers on both sides—those who want to go back to analog times and those who say promptography is photography—are nonsense. We need to think deeper than that.",https://www.scientificamerican.com/article/how-my-ai-image-won-a-major-photography-competition/
"April 21, 2023- Kenna Hughes-Castleberry | Opinion",AI Can’t Solve this Famous Murder Mystery Puzzle,"Artificial intelligence programs that analyze and produce text are transforming how we read and learn. To parse writing, AI models sleuth through textual clues, such as word choices, to see their connections. But what happens when those clues are deliberately vague and confusing? I tried to answer this question when I challenged AI developers to solve the nearly century-old Cain’s Jawbone, a murder-mystery puzzle book from 1934.

The book arrived in my life as mysteriously as a literary sleuth could wish. One October afternoon in 2022, a random package from Amazon was dropped on my doorstep with no accompanying note or return address. I had never heard of the book inside, but a Google search told me that Cain’s Jawbone is both a murder mystery and a brain-teasing puzzle. The book was purposely published with all its pages out of order; to crack the case, the reader must first reorder the pages, and then name the six murderers and their victims.

The writer of this fiendish plot was (surprise surprise) a puzzle expert. Edward Mathers worked as a crossword compiler for The Observer newspaper under the pseudonym Torquemada. He published Cain’s Jawbone at the height of the so-called golden age of detective fiction, but only two people managed to solve it before the book went out of print. In 2019, John Mitchinson, the co-founder of publishing platform Unbound Publishing, came across a copy of the story and its solution at a literary museum in the U.K. Mitchinson decided to reprint the 100-page puzzle. “I said, ‘Well, this is amazing. It’s a detective novel, so how difficult could it be to put in order?’” he recalls.

ADVERTISEMENT

The answer, it turns out, is “very, very difficult.” In the past few years, only four more people have solved the puzzle. Then the book went viral thanks to a couple of TikTokers who tried to reorder the pages using a colorful “murder wall.” Its new popularity spurred Mitchinson to print additional copies on top of the initial 5,000-copy run.

When my copy of Cain’s Jawbone appeared, instead of designating wall space for the pages, my husband and I spread them out on our guest bed. As we pored over the flowery and deliberately vague language one dimly lit evening, I suggested using an AI algorithm to solve the novel.

Trying to solve Cain’s Jawbone. Credit: Austen Hughes

Because I’m not a software expert, I started looking for an AI company willing to tackle this puzzle. But most AIs are not trained specifically to reorder book pages, or to analyze the linguistic quirks of 1930s English. Finally, I connected with Zindi, an Africa-based company that hosts AI competitions in which 50,000 data scientists use algorithms to solve puzzles and win prizes. Zindi was interested in hosting the competition, and with Unbound’s blessing, I created the 2022 Cain’s Jawbone Murder Mystery Competition; we digitized the 90-year-old book and challenged the world to use natural language processing (NLP) algorithms to reorder the pages.

NLP algorithms, such as the famous ChatGPT, try to understand the information within a text by comparing its context and language to the training data it receives. Such algorithms can analyze never-before-seen text by transforming each word into a “token” and then analyzing how each token fits into the complete work. This helps AI algorithms to analyze texts, whether literature or scientific reports, quickly and effectively. I nobly resisted using AI to crack the case of who sent me this intriguing book, instead texting friends and posting on Instagram to uncover the culprit.

For our competition, participants started with an existing NLP model called BERT, developed by Google and available in an open-source library, where it can be modified for specific uses. “These models are … trained on just gobs of the data that the model creators can get their hands on and then are refined to follow a certain set of instructions,” says Jonathan May, a research associate professor of computer science at the University of Southern California. In order to refine their models for this particular use, we gave participants Agatha Christie’s first mystery novel, The Mysterious Affair at Styles, to use as training data, because that story was written during the same time period as Cain’s Jawbone and contains similar language, as well as demonstrating the context clues of a classic mystery.

ADVERTISEMENT

AI has had a long history with writing novels, including murder mysteries. In 1973, computer scientist Sheldon Klein proposed the Automatic Novel Writer, which he claimed could produce 2,100-word murder mystery stories in less than 20 seconds. Since then, programmers and engineers have improved the output of these models using more data. “In a way, a murder mystery is easy,” says Mike Sharples, an emeritus professor of educational technology at the Institute of Educational Technology at the Open University, England. “There is a standard plot structure to it: find the body, the sleuth comes, you’ve got a red herring, and so on.” This plot structure is not only helpful to authors dashing off a quick story but could also help AI language programs trying to put the mixed-up pages of those stories back into the right order—in theory.

Unfortunately, Cain’s Jawbone creates the ultimate challenge for language-analyzing algorithms: the story is not only completely out of order, but also designed to stymie readers. For instance, the language is highly stylized—Mitchinson describes it as “a postmodernist poem”— and deliberately vague, in order to make ordering the pages as difficult as possible. Plus, the story abounds in false clues, such as fake names for some characters and misleading names for others, all of which might confuse AI models as well as human solvers. As a result, none of the AI developers managed to crack the puzzle—although some of them made a little headway.

M.G. Ferreira, an econometrician from South Africa, was one of the AI competition winners, with the highest score of 42 percent. That means his program correctly ordered 42 out of the 100 pages. “NLP does have some comprehension to it, like knowing that thunder and rain go together,” Ferreira says. “But the problem here is that the book is trying to throw you off with false clues. It breaks NLP comprehension.” In order to solve the puzzle, he explains, the AI needs a human to step in, look at the context and identify which ideas go together. “Going in that direction, eventually we will be able to solve the whole thing. But by that time the NLP will be such a small part and the human overlay will be such a big part that I’d call it machine-assisted,” he adds.

Sign up for Scientific American’s free newsletters.

Sign Up

The murder mystery competition revealed that current AI language programs may be capable of impressive feats, but they won’t be going toe to toe with Poirot any time soon. These models are bad at analyzing things without context, which could cause issues for researchers who hope to use NLPs to analyze ancient languages. Because there are few historical records on some long-gone civilizations, the lack of context makes it difficult for AI to learn how to translate their lost languages.

At least this experience helped me solve one puzzle: I tracked down the person who sent me the book and set me off on this quest to solve it. The culprit turned out to be one of my elementary school friends, a person who doesn’t have social media but does have a penchant for murder mysteries—just like me.

ADVERTISEMENT

This is an opinion and analysis article, and the views expressed by the author or authors are not necessarily those of Scientific American.",https://www.scientificamerican.com/article/ai-cant-solve-this-famous-murder-mystery-puzzle1/
"April 14, 2023- Daniel Cusick and E&E News",Early-Warning System Could Reduce Injuries from In-Flight Turbulence,"CLIMATEWIRE | Turbulence is more than just an annoyance for frequent fliers. It can cause severe injury to both passengers and crew, and research suggests that climate change will make it worse.

But NASA says it's making progress on a solution that could help pilots anticipate and avoid sudden shifts in air stability.

The technology, under development at NASA's Langley Research Center and involving government, university and private sector experts, anticipates using ground-mounted infrasonic microphones that can pick up ultralow frequencies produced by turbulence- possibly as far as 300 miles away.

ADVERTISEMENT

If deployed at scale, such microphones could provide an early warning for what’s known as “clear-air turbulence,” the top cause of inflight injuries and fatalities, according to researchers at the University of Reading in the United Kingdom.

Clear-air turbulence differs from other forms of turbulence in several ways, and it can occur without warning at altitudes of 20,000 to 40,000 feet. The unstable air masses can be as much as 100 miles wide and 300 miles long, and they often are found just above the jet stream core, researchers say.

The National Transportation Safety Board reports that 163 people were seriously injured from in-flight turbulence between 2009 and 2022; most of the injuries were to flight crew members. NTSB did not differentiate between clear-air turbulence and weather-induced turbulence.

One recent example occurred in December, when around two dozen passengers were injured on a Hawaiian Airlines flight from Phoenix to Honolulu after the plane experienced severe turbulence about 30 minutes before landing. Twelve of the flight's passengers are now suing, saying that the pilots should have anticipated rough air and instructed passengers to remain buckled in their seats.

Turbulence is expected to get worse too as the world warms.

ADVERTISEMENT

Scientists at the University of Reading project that the frequency of clear-air turbulence events will double by 2050 and that the intensity of such events will increase by as much as 40 percent.

""Our results confirm that the aviation sector should prepare for a more turbulent future,"" noted the researchers in their paper, which was published last month in the journal Climate Dynamics.

The NASA research effort could make flight crews, passengers and aircraft more resilient to that future.

Sign up for Scientific American’s free newsletters.

Sign Up

""Instead of having to change course when turbulence is encountered, early detection would allow flights to adjust their navigation beforehand, saving fuel and emitting less carbon dioxide into the atmosphere,” a NASA spokesperson wrote in an email.

Infrasound microphones have been a NASA priority since 2007, and the technology underwent early ground testing in 2017 at Langley, where a three-microphone array picked up turbulence 300 miles away, according to NASA. In 2021, researchers tested the technology on two stratospheric glider flights in New Mexico. NASA said the test yielded promising results, and research is ongoing with the agency's private-sector partner, Stratodynamics Inc. of Delaware.

ADVERTISEMENT

Stratodynamics Vice President Nick Craine said in an interview that data collected from the glider flights is still being analyzed, but he noted it was the ""first time in history that an infrasonic signal has been recorded and observed from a fixed-wing, heavier-than-air aircraft.""

Sean Bailey, an associate professor of mechanical and aerospace engineering at the University of Kentucky and co-researcher on the project, said more work is needed to determine if the technology can be scaled to a complex, global air-traffic system.

But there's little question that climate change will drive demand for new tools to predict and avoid turbulence.

While specific turbulence incidents cannot be directly attributed to climate change, a recent spate of injury-causing turbulence suggests that pilots are running up against more than bad weather, which they normally can avoid by flying above or around such systems.

Jennifer Stroozas of the National Weather Service’s Aviation Weather Center in Kansas City, Mo., said meteorologists rely on radar, satellite imagery and pilot reports to identify conditions for turbulence.

ADVERTISEMENT

She added that turbulence can be particularly strong during the winter when the jet stream dips southward over the continental United States, where it can intersect with weather systems and produce strong wind shear.

“We’ve had a really active weather patten over the last couple of months with lots of systems going through,"" she said. ""Our turbulence forecasters have been very busy.”

Reprinted from E&E News with permission from POLITICO, LLC. Copyright 2023. E&E News provides essential news for energy and environment professionals.",https://www.scientificamerican.com/article/early-warning-system-could-reduce-injuries-from-in-flight-turbulence/
"April 14, 2023- Sophie Bushwick, Kelso Harper and Tulika Bose",What You Need to Know about GPT‑4,The AI GPT-4 has emergent abilities—but that’s not why it’s scary. ,https://www.scientificamerican.com/podcast/episode/what-you-need-to-know-about-gpt-4/
"April 12, 2023- Jeff Tollefson and Nature magazine",The EPA Wants Two Thirds of U.S. Car Sales to Be Electric by 2032,"The US Environmental Protection Agency (EPA) today proposed a landmark set of pollution regulations that could spark an electric-vehicle revolution and drive down greenhouse-gas emissions.

Under the rules, electric vehicles could account for an estimated 67% of new US passenger-car sales by 2032 and additional gains for larger vehicles- a major feat for a country where transportation is the largest source of greenhouse-gas emissions.

“These actions will accelerate the ongoing transition to a clean-vehicle future, tackle the climate crisis and improve our air quality for communities across the country,” EPA administrator Michael Regan said during a press conference.

ADVERTISEMENT

The rules, which are currently in draft form pending public comments, apply to automobiles sold between 2027 and 2032. They would reduce average emissions from new passenger vehicles by more than half compared to the existing standard. But will the proposal succeed and how would it impact climate change?

CAN THE UNITED STATES MAKE ENOUGH ELECTRIC VEHICLES IN TIME?

The country has one of the largest vehicle fleets in the world, so one question is whether it’s possible to scale up to so many more electric vehicles in just a few years. Challenges include the need to roll out charging infrastructure, ramp up manufacturing capacity for electric cars and convince people to change their habits.

However, the rules are arriving in an economy that is already primed for innovation and change, says Margo Oge, who led the development of similar vehicle regulations as head of the EPA’s Office of Transportation and Air Quality under former president Barack Obama.

In particular, an infrastructure bill enacted by Congress in 2021 and a massive spending bill known as the Inflation Reduction Act, passed in 2022, are funnelling federal money into charging infrastructure and tax credits for consumers and for manufacturers of automobiles or batteries that upgrade or build new facilities.

Even without the EPA’s rules, electric vehicles could account for more than 50% of new US vehicle sales by 2030, according to a January study by the International Council on Clean Transportation, a non-profit research group in Washington DC, and the consultancy Energy Innovation Policy and Technology in San Francisco, California. The EPA rules would help to eliminate lingering uncertainties about how federal incentives will play out under the Inflation Reduction Act, says Robbie Orvis, a senior director at Energy Innovation: “It cements current trends into place, and creates a much stronger investment climate.”

ADVERTISEMENT
WHAT ABOUT SECURING RAW MATERIALS?

Lithium and cobalt are needed to manufacture modern batteries, and the Biden administration is encouraging companies to purchase these and other materials through countries that have free trade agreements with the US. The administration is also encouraging domestic manufacturing in order to secure supply chains and dial back dependence on China. Some tax credits are available only if the manufacturing of batteries and vehicles take place in the United States, or if key minerals are sourced from free-trade partners such as Chile, Australia, Canada or Mexico. But so far, there are no obvious showstoppers when it comes to supplies of crucial minerals for electric-car batteries, according to the energy consultancy BloombergNEF.

“The investments are there, and these nations can theoretically provide sufficient supplies,” says Evelina Stoikou, an energy-storage analyst at BloombergNEF in New York City. But she warns that demand from Europe and other regions will rise, so it will be important for the United States to strengthen its international partnerships.

WHAT IMPACT WOULD THE RULES HAVE ON CLIMATE CHANGE?

The EPA’s initial estimate is that the regulations would reduce carbon emissions by around ten billion tonnes over the next three decades. That is more than double the United States’ emissions last year, or more than one-quarter of the global total. “The administration is going to make history if indeed, at the end of the day, they finalized these new standards,” says Oge. “I’m really hopeful.”

Sign up for Scientific American’s free newsletters.

Sign Up
COULD THE COURTS CHALLENGE THE RULES?

US courts have overturned environmental rules in the past- and the proposed rules are likely to face challenges. But one thing in their favour is that they follow procedures that the EPA has long used to control pollutants from vehicles and other sources. Rather than dictating technological change, the agency is setting pollution limits for car manufacturers. Those limits can be met with existing technologies, and it’s up to the automobile industry to decide how to comply, says Chester France, a former EPA official who is now a consultant for the Environmental Defense Fund, an advocacy group based in New York City. “I would fully expect those standards to be legally durable.”

This article is reproduced with permission and was first published on April 12, 2023.

ADVERTISEMENT",https://www.scientificamerican.com/article/the-epa-wants-two-thirds-of-u-s-car-sales-to-be-electric-by-2032/
"April 12, 2023- Sophie Bushwick",Bizarre Material Combines the Best Traits of Gel and Metal,"Sometimes science advances at a snail’s pace, but in this case that’s a good thing: researchers have created a squishy material that combines polymers with liquid metal, demonstrated in a snail-like robot. Developers say this electrically conductive gel could be used to make self-healing electronic circuits and biological monitors for measuring heart and muscle activity—and maybe even lead to robot nervous systems.     

The composite substance is stretchy and soft like living tissue. If it breaks or tears, the edges can be touched together, and the material’s molecular bonds quickly re-form without any additional heat or chemical treatment. And crucially, its developers say, it is the first such material that also conducts electricity.

These abilities could lead to wire-free medical monitors as well as fully soft robots. “For my research, one thing that’s really big is, ‘How do you put multiple functions into a single material?’ ” says Lillian Chin, who develops soft robotic components as part of her own research at the Massachusetts Institute of Technology. Existing soft-bodied robots, she says, often require at least some rigid metals and silicon components. But soft, flexible living tissues can perform multiple tasks; muscles, Chin notes, both move our bodies and provide electrical feedback about that movement to our brains.

ADVERTISEMENT

To build a multitasking artificial substance, the researchers started with a tangle of long polymer chains soaked in a solvent to keep them supple, then carefully mixed in microscopic drops of gallium-indium liquid metal, as well as tiny silver flakes. This produced a low-density gel dotted with conductive metals, through which enough electricity can flow to, say, power a motor.

For a recent study in Nature Electronics, the researchers used their new material to connect motors to power sources in two basic machines: a snail-like soft robot and a toy car. The material’s self-healing ability helped these simple circuits stand up to wear and tear—and be easily reconfigured. For example, the team cut the car’s power-carrying gel “wires” and shifted their connections to power both movement and a small chassis-mounted light.

The snail “illustrates one possibility of using these materials as, basically, an artificial nervous tissue for soft robots,” says Carnegie Mellon University mechanical engineer Carmel Majidi, the study’s senior author. But truly multifunctional bots will require more intricate uses of the new material. “In practice, we would want to have digital printing capabilities so we can make much more complex circuits that could interface with microelectronic chips, as well as other types of components that we could actually use in more sophisticated robotics and electronics applications,” Majidi says. “There are so many possibilities that arise when you take machines and robots out of the hard case and engineer them out of materials that are soft and squishy.”",https://www.scientificamerican.com/article/bizarre-material-combines-the-best-traits-of-gel-and-metal1/
"April 10, 2023- Amory Tillinghast-Raby",A Number System Invented by Inuit Schoolchildren Will Make Its Silicon Valley Debut,"In the remote Arctic almost 30 years ago, a group of Inuit middle school students and their teacher invented the Western Hemisphere's first new numeral system in more than a century. The “Kaktovik numerals,” named after the Alaskan village where they were created, looked utterly different from decimal system numerals and functioned differently, too. But they were uniquely suited for quick, visual arithmetic using the traditional Inuit oral counting system, and they swiftly spread throughout the region. Now, with support from Silicon Valley, they will soon be available on smartphones and computers—creating a bridge for the Kaktovik numerals to cross into the digital realm.

Today's numerical world is dominated by the Hindu-Arabic decimal system. This system, adopted by almost every society, is what many people think of as “numbers”—values expressed in a written form using the digits 0 through 9. But other number systems exist, and they are as varied as the cultures they belong to.

The Alaskan Inuit language, known as Iñupiaq, uses an oral counting system built around the human body. [For another example, see “Whispers from Deep Time,” by Anvita Abbi.] Quantities are first described in groups of five, 10 and 15, and then in sets of 20. The system “is really the count of your hands and the count of your toes,” says Nuluqutaaq Maggie Pollock, who taught with the Kaktovik numerals in Utqiagvik, a city 300 miles northwest of where they were invented. For example, she says, tallimat—the Iñupiaq word for 5—comes from the word for arm: taliq. “In your one arm, you have tallimat fingers,” Pollock explains. Iñuiññaq, the word for 20, represents a whole person. In traditional practices, the body also serves as a mathematical multitool. “When my mother made me a parka, she used her thumb and her middle finger to measure how many times she would be able to cut the material,” Pollock says. “Before yardsticks or rulers, [Iñupiat people] used their hands and fingers to calculate or measure.”

ADVERTISEMENT

During the 19th and 20th centuries American schools suppressed the Iñupiaq language—first violently and then quietly. “We had a tutor from the village who would help us blend into the white man's world,” Pollock says of her own education. “But when my father went to school, if he spoke the language, they would slap his hands. It was torture for them.” By the 1990s the Iñupiaq oral counting system was dangerously close to being forgotten.

The Kaktovik numerals started as a class project to adapt the counting system to a written form. The numerals, based on tally marks, “look like” the Iñupiaq words they represent. For example, the Iñupiaq word for 18, “akimiaq pinasut,” meaning “15-3,” is depicted with three horizontal strokes, representing three groups of 5 (15), above three vertical strokes representing 3.

Credit: Amanda Montañez; Source: “Unicode Request for Kaktovik Numerals,” by Eduardo Marín Silva and Catherine Strand. Submitted to Unicode Technical Committee Document Registry March 16, 2021 (reference)

“In the Iñupiaq language, there wasn't a word for 0,” says William Clark Bartley, the teacher who helped develop the numerals. “The girl who gave us the symbol for 0, she just crossed her arms above her head like there was nothing.” The class added her suggestion—an X-like mark— to their set of unique numerals for 1 through 19 and invented what mathematicians would call a base 20 positional value system. (More technically, it is a two-dimensional positional value system with a primary base of 20 and a subbase of 5.)

Because of the tally-inspired design, arithmetic using the Kaktovik numerals is strikingly visual. Addition, subtraction and even long division become almost geometric. The Hindu-Arabic digits are an awkward system, Bartley says, but “the students found, with their numerals, they could solve problems a better way, a faster way.”

Credit: Amanda Montañez; Source: “Unicode Request for Kaktovik Numerals, by Eduardo Marín Silva and Catherine Strand. Submitted to Unicode Technical Committee Document Registry March 16, 2021 (reference)

“The Iñupiaq way of knowing is often done by showing,” adds Qaġġuna Tenna Judkins, director of Iñupiaq education in northern Alaska's North Slope Borough. Visualizing arithmetic makes the concepts a lot easier to understand, she says.

ADVERTISEMENT

At first, students would convert their assigned math problems into Kaktovik numerals to do calculations, but middle school math classes in Kaktovik began teaching the numerals in equal measure with their Hindu-Arabic counterparts in 1997. Bartley reports that after a year of the students working fluently in both systems, scores on standardized math exams jumped from below the 20th percentile to “significantly above” the national average. And in the meantime, the board of education in the North Slope Borough's district seat, Utqiagvik, passed a resolution that spread the numerals almost 500 miles along the Arctic coast. The system was even endorsed by the Inuit Circumpolar Council, which represents 180,000 Inuit across Alaska, Canada, Greenland and Russia.

But under the federal No Child Left Behind Act, from 2002 to 2015, schools faced severe sanctions—or even closure—for not meeting state standards, provoking a “scare” that some local educators say squeezed the Kaktovik numerals into a marginal role despite the system's demonstrated educational impact. “Today the only place [they're] really being used is in the Iñupiaq language classrooms,” says Chrisann Justice, the North Slope Borough's Iñupiaq education department specialist. “We're just blowing on the coal.”

But support from Silicon Valley is helping to reignite the Kaktovik numerals. Thanks to efforts by linguists working with the Script Encoding Initiative at the University of California, Berkeley, the numerals were included in the September 2022 update of Unicode, an international information technology standard that lets the world's written languages be digitized. The new release, Unicode 15.0, provides a virtual identifier for each Kaktovik numeral so developers can incorporate them into digital displays. “It really is revolutionary for us,” Judkins says. “Right now we have to either use photos of the numerals or write them by hand.”

Sign up for Scientific American’s free newsletters.

Sign Up

There is still work to be done. Google is building a font for the numerals based on the Unicode update, says Craig Cornelius, a Google software engineer who works to digitally preserve endangered languages. The company made a “prelease” of its font available for computer download in March, although it won't appear on the Android operating system until at least late summer. Desktop and mobile keyboards with the numerals need to be produced as well.

But excitement over the traditional system's cyber debut is growing. “If we went to a math textbook creator and said, ‘Hey, can you build us a textbook but convert the Arabic numerals into Kaktovik numerals?' it would be that much easier,” Judkins says.

ADVERTISEMENT

Unicode inclusion also pushes the boundary of what is mathematically feasible with the Kaktovik numerals. At higher levels, mathematics becomes an increasingly digital discipline. The basic theory can be illustrated on a blackboard, but complex problems often need to be solved with a computer. Without digital availability, the Kaktovik numerals would be confined to their arithmetic wheelhouse at a time when the Iñupiaq language is being revitalized for broad modern use. Being able to input the Kaktovik numerals into computation engines such as WolframAlpha, Judkins says, is “going to be a game changer. You are almost going to be able to choose: Am I going to be in English, or am I going to be in Iñupiaq? And if I am in Iñupiaq, I'm using all Kaktovik numerals.”

Nearly 3,000 miles away, in Oklahoma, Unicode holds similar promise for Cherokee communities. In the early 1800s Cherokee polymath Sequoyah invented the Cherokee syllabary of written characters. “Around the same time, he also developed a number system,” says Roy Boney, language program manager for the Cherokee Nation. But Cherokee numerals weren't endorsed by the tribal government until 2012. A long history of trade with French and British settlers meant the Hindu-Arabic numerals were already in use when Cherokee numerals were invented.

It is unclear if Cherokee numerals have since gained traction, but Boney reports that interest in the system is growing. “We have the numbers and need to use them,” he says. “It's been a slow roll, but we have been introducing the numbers into our education settings”—beginning to demonstrate the community use needed for inclusion in Unicode. Once the numerals are included, Boney and his colleagues hope to create a programming language using Cherokee script and numbers.

Hindu-Arabic numerals' ubiquity is powerful and has often come at the expense of culturally meaningful systems. But now those systems are slowly going digital, which is creating opportunities for their use that would have been unthinkable even two years ago. As Pollock puts it: “This is just the beginning.”",https://www.scientificamerican.com/article/a-number-system-invented-by-inuit-schoolchildren-will-make-its-silicon-valley-debut1/
"April 4, 2023- Mordechai Rorvig",AI Is Getting Powerful. But Can Researchers Make It Principled?,"Soon after Alan Turing initiated the study of computer science in 1936, he began wondering if humanity could one day build machines with intelligence comparable to that of humans. Artificial intelligence, the modern field concerned with this question, has come a long way since then. But truly intelligent machines that can independently accomplish many different tasks have yet to be invented. And though science fiction has long imagined AI one day taking malevolent forms such as amoral androids or murderous Terminators, today’s AI researchers are often more worried about the everyday AI algorithms that already are enmeshed with our lives—and the problems that have already become associated with them.

Even though today’s AI is only capable of automating certain specific tasks, it is already raising significant concerns. In the past decade, engineers, scholars, whistleblowers and journalists have repeatedly documented cases in which AI systems, composed of software and algorithms, have caused or contributed to serious harms to humans. Algorithms used in the criminal justice system can unfairly recommend denying parole. Social media feeds can steer toxic content toward vulnerable teenagers. AI-guided military drones can kill without any moral reasoning. Additionally, an AI algorithm tends to be more like an inscrutable black box than a clockwork mechanism. Researchers often cannot understand how these algorithms, which are based on opaque equations that involve billions of calculations, achieve their outcomes.

Problems with AI have not gone unnoticed, and academic researchers are trying to make these systems safer and more ethical. Companies that build AI-centered products are working to eliminate harms, although they tend to offer little transparency on their efforts. “They have not been very forthcoming,” says Jonathan Stray, an AI researcher at the University of California, Berkeley. AI’s known dangers, as well as its potential future risks, have become broad drivers of new AI research. Even scientists who focus on more abstract problems such as the efficiency of AI algorithms can no longer ignore their field’s societal implications. “The more that AI has become powerful, the more that people demand that it has to be safe and robust,” says Pascale Fung, an AI researcher at the Hong Kong University of Science and Technology. “For the most part, for the past three decades that I was in AI, people didn’t really care.”

ADVERTISEMENT

Concerns have grown as AI has become widely used. For example, in the mid-2010s, some Web search and social media companies started inserting AI algorithms into their products. They found they could create algorithms to predict which users were more likely to click on which ads and thereby increase their profits. Advances in computing had made all this possible through dramatic improvements in “training” these algorithms—making them learn from examples to achieve high performance. But as AI crept steadily into search engines and other applications, observers began to notice problems and raise questions. In 2016 investigative journalists raised claims that certain algorithms used in parole assessment were racially biased.

That report’s conclusions have been challenged, but designing AI that is fair and unbiased is now considered a central problem by AI researchers. Concerns arise whenever AI is deployed to make predictions about people from different demographics. Fairness has now become even more of a focus as AI is embedded in ever more decision-making processes, such as screening resumes for a job or evaluating tenant applications for an apartment.

In the past few years, the use of AI in social media apps has become another concern. Many of these apps use AI algorithms called recommendation engines, which work in a similar way to ad-serving algorithms, to decide what content to show to users. Hundreds of families are currently suing social media companies over allegations that algorithmically driven apps are directing toxic content to children and causing mental health problems. Seattle Public Schools recently filed a lawsuit alleging that social media products are addictive and exploitative. But untangling an algorithm’s true impact is no easy matter. Social media platforms release few data on user activity, which are needed for independent researchers to make assessments. “One of the complicated things about all technologies is that there’s always costs and benefits,” says Stray, whose research focuses on recommender systems. “We’re now in a situation where it’s hard to know what the actual bad effects are.”

The nature of the problems with AI is also changing. The past two years have seen the release of multiple “generative AI” products that can produce text and images of remarkable quality. A growing number of AI researchers now believe that powerful future AI systems could build on these achievements and one day pose global, catastrophic dangers that could make current problems pale in comparison.

What form might such future threats take? In a paper posted on the preprint repository arXiv.org in October, researchers at DeepMind (a subsidiary of Google’s parent company Alphabet) describe one catastrophic scenario. They imagine engineers developing a code-generating AI based on existing scientific principles and tasked with getting human coders to adopt its submissions to their coding projects. The idea is that as the AI makes more and more submissions, and some are rejected, human feedback will help it learn to code better. But the researchers suggest that this AI, with its sole directive of getting its code adopted, might potentially develop a tragically unsound strategy, such as achieving world domination and forcing its code to be adopted—at the cost of upending human civilization.

ADVERTISEMENT

Some scientists argue that research on existing problems, which are already concrete and numerous, should be prioritized over work involving hypothetical future disasters. “I think we have much worse problems going on today,” says Cynthia Rudin, a computer scientist and AI researcher at Duke University. Strengthening that case is the fact that AI has yet to directly cause any large-scale catastrophes—although there have been a few contested instances in which the technology did not need to reach futuristic capability levels in order to be dangerous. For example, the nonprofit human rights organization Amnesty International alleged in a report published last September that algorithms developed by Facebook’s parent company Meta “substantially contributed to adverse human rights impacts” on the Rohingya people, a minority Muslim group, in Myanmar by amplifying content that incited violence. Meta responded to Scientific American’s request for comment by pointing to a previous statement to Time magazine from Meta’s Asia-Pacific director of public policy Rafael Frankel, who acknowledged that Myanmar’s military committed crimes against the Rohingya and stated that Meta is currently participating in intergovernmental investigative efforts led by the United Nations and other organizations.

Other researchers say preventing a powerful future AI system from causing a global catastrophe is already a major concern. “For me, that’s the primary problem we need to solve,” says Jan Leike, an AI researcher at the company OpenAI. Although these hazards are so far entirely conjectural, they are undoubtedly driving a growing community of researchers to study various harm-reduction tactics.

In one approach called value alignment, pioneered by AI scientist Stuart Russell at the University of California, Berkeley, researchers seek ways to train an AI system to learn human values and act in accordance with them. One of the advantages of this approach is that it could be developed now and applied to future systems before they present catastrophic hazards. Critics say value alignment focuses too narrowly on human values when there are many other requirements for making AI safe. For example, just as with humans, a foundation of verified, factual knowledge is essential for AI systems to make good decisions. “The issue is not that AI’s got the wrong values,” says Oren Etzioni, a researcher at the Allen Institute for AI. “The truth is that our actual choices are functions of both our values and our knowledge.” With these criticisms in mind, other researchers are working to develop a more general theory of AI alignment that works to ensure the safety of future systems without focusing as narrowly on human values.

Sign up for Scientific American’s free newsletters.

Sign Up

Some scientists are taking approaches to AI alignment that they see as more practical and connected with the present. Consider recent advances in text-generating technology: the leading examples, such as DeepMind’s Chinchilla, Google Research’s PaLM, Meta AI’s OPT and OpenAI’s ChatGPT, can all produce content that is racially biased, illicit or deceptive—a challenge that each of these companies acknowledges. Some of these companies, including OpenAI and DeepMind, consider such problems to be ones of inadequate alignment. They are now working to improve alignment in text-generating AI and hope this will offer insights into aligning future systems.

Researchers acknowledge that a general theory of AI alignment remains absent. “We don’t really have an answer for how we align systems that are much smarter than humans,” Leike says. But whether the worst problems of AI are in the past, present or future, at least the biggest roadblock to solving them is no longer a lack of trying.

ADVERTISEMENT",https://www.scientificamerican.com/article/ai-is-getting-powerful-but-can-researchers-make-it-principled/
"April 3, 2023- Jason Sherman",Drone-on-Drone Combat in Ukraine Marks a New Era of Aerial Warfare,"In the skies over Ukraine, a new epoch in air warfare is emerging: drone-on-drone combat.

These aerial duels don’t involve bullets, missiles or bombs. In some, hobby-type camera quadcopters that are used to spy on enemy positions simply ram each other in a crude aerial demolition derby. In other encounters, highly sophisticated craft use advanced radar—backed by artificial intelligence and the latest aerospace engineering technology—to precision fire nets that snag other drones.

“This is something we haven’t seen before,” says Caitlin Lee, who leads the Center for Unmanned Aerial Vehicles and Autonomy Studies at the Mitchell Institute for Aerospace Studies in Arlington, Va. “This is the first time we’re seeing drone-on-drone conflict.”

ADVERTISEMENT

And the action in Ukraine suggests that even more novel kinds of aerial conflict—including combat drones armed to fight in tandem with piloted aircraft—are coming to the broader world of warfare. The U.S. Air Force, for example, now envisions a fleet of 1,000 high-performance uncrewed aircraft paired with its most advanced combat jets. This plan is in response to China’s growing challenge to the U.S. military’s 75-year air dominance. Beyond the battlefield, weaponized drones could, from the skies above any city, easily threaten things such as crowd safety at major sporting events, prison security and critical infrastructure. (Of course, much of the underlying technology is also expected to usher in changes for the good in the realm of peaceful applications. Drones have already been successfully used to rush extremely perishable donor organs to transplant patients.)

In Ukraine, the initial drone dogfights sprung from the proliferation of commercially available, low-cost, low-altitude aircraft, such as Chinese drone maker DJI’s quadcopter. People can creatively modify these hobbyist machines for combat to allow the drones to conduct overhead surveillance and drop grenades. Defending against such small drones, some weighing just a few ounces or pounds, is difficult. For starters, they are hard to detect.

“We can retrain air defenses to look for smaller radar cross sections, but then they’ll pick up every bird that flies by,” says Sarah Kreps, director of the Cornell Brooks School Tech Policy Institute. “So it’s a real sensor problem that countries like the U.S. have spent billions trying to solve—not unlike when the U.S. spent [heavily on] countering improvised explosive devices that were far less expensive or sophisticated than systems our militaries had been trained to destroy. These are essentially flying IEDs that have foiled militaries in similar ways, creating asymmetric advantages that have been difficult to counter.”

Another challenge these small drones present is that they are now widely available and cheap enough to be purchased in large numbers. Even though an individual machine modified for combat is not capable of causing massive destruction, the number of potentially vulnerable targets is nearly infinite, Kreps notes. This enables a group with fewer resources to attack a more powerful foe.

In 2016 French special operations forces deployed in Syria were among the first to see small commercial drones imaginatively converted into instruments of war when the forces were attacked by Islamic State fighters. “Less-funded countries now have access to airpower where they wouldn’t have in the past, so that’s changing who’s entering the fray,” says Nicole Thomas, division chief for strategy at the Pentagon’s Joint Counter-Small Unmanned Aircraft Systems Office, an organization created in 2020 to synchronize the U.S. military’s response to such threats.

ADVERTISEMENT

The U.S. government divides small drones into three categories: Group 1 describes craft that have a gross takeoff weight of up to 20 pounds. Group 2 covers the next tier, between 21 and 55 pounds. And Group 3 encompasses uncrewed drones that can weigh as much as 1,320 pounds.

While the drone war era has clearly begun, it is not yet clear that these small aircraft are playing a decisive role in the larger Ukraine fight by creating an offensive breakthrough or an opportunity to seize the initiative for one side, Lee says. “I think the open question is: Do the drones have to get more sophisticated ... in order to hold the ground, let alone contribute to a combined arms campaign that actually takes back territory?” she adds.

Defense experts are not waiting for small drones to become more advanced before taking steps to defend against them. In the 2021 National Defense Authorization Act, the U.S. Congress directed the Pentagon to create a plan for developing and fielding defense systems to counter small drones. And this year the Pentagon plans to spend nearly $700 million for counterdrone research and development, plus $78 million for procurement. A private research firm estimates the market for systems to counter small drones will grow from about $2.3 billion in 2023 to $12.6 billion by 2030. This market includes not only the Pentagon but also state and municipal governments, as well as private entities.

Sign up for Scientific American’s free newsletters.

Sign Up

That potential is inspiring more than a dozen companies around the world—including Blighter Surveillance Systems in England, and Dedrone and DeTect in the U.S.—to develop antidrone technology. Such systems may be ground-based, handheld or drone-based and can bring down other small aircraft using electromagnetic interference, lasers and other technology.

Fortem Technologies, a start-up based in Pleasant Grove, Utah, has vaulted into the drone wars by adapting its earlier work on miniature radars. The company says it has developed a complete system for detecting small drones—and capturing them midair with a net.

ADVERTISEMENT

Fortem’s DroneHunter F700 has six rotors, a radar backed by autonomous technology and two “net heads” that can precisely fire webs at adversary drones. Once ensnared, smaller drones can be dragged away by the DroneHunter. Larger drones are also netted but then released; the net prevents them from flying, so they drop to the ground under their own weight. Then a parachute attached to the net deploys to soften the landing.

“We’re really the only one in the world at this point that can do that,” says the company’s chief executive officer Jon Gruen.

The U.S. government is using this technology to protect unnamed “strategic” sites. And Ukraine is flying Fortem’s new drone to patrol the skies and nab small Russian aircraft intact and on the fly.

Ukraine first deployed DroneHunter last May to chase down the Group 1 and 2 drones that Russia was using to spy on frontline Ukrainian troops. DroneHunter has dented Moscow’s ability to use drones for collecting artillery-targeting data on Ukrainian troop positions and has stymied larger kamikaze drones aimed at critical infrastructure.

When Russia began launching the Iranian-built uncrewed aerial vehicle Shahed, a Group 3 drone, as a kamikaze weapon, Fortem began modifying DroneHunter to intercept these armed drones. The system has ensnared more than 5,000 target drones during developmental flight tests, Gruen says. This has helped capture the attention of capital venture divisions at Lockheed Martin, Boeing and other giant corporations, which have invested $75 million in scaling up Fortem’s operations.

ADVERTISEMENT

Significantly, DroneHunter operates autonomously: once deployed, it races to the action, makes independent decisions about all its moves, nets its prey and returns to be equipped with a fresh net.

“There have been debates about using autonomous drones in combat, and thus far, countries seem to have shied away from using them in a lethal capacity,” Kreps says. “At the same time, though, we’ve seen an increasingly porous line between the semiautonomous drones—which is how the U.S. used drones for counterterrorism—and fully autonomous drones.”

In a situation such as the one in Ukraine, where the West broadly supports giving the country the tools it needs to defend itself, “there could be a real first-mover advantage in using counterdrone systems in this type of autonomous capacity,” Kreps says, “which takes us further down the slippery slope of autonomy.”",https://www.scientificamerican.com/article/drone-on-drone-combat-in-ukraine-marks-a-new-era-of-aerial-warfare/
"April 1, 2023- Clara Moskowitz and David Cheney",The Science of Melting Chocolate,"The sensation of rich chocolate going gooey on your tongue is unlike any other. To understand how the process plays out on a molecular level, scientists created a biomimetic tongue that replicates the texture, surface distribution and mechanical properties of a human tongue. “We wanted to understand the main contributor to that smooth feeling of the chocolate as it melts,” says Siavash Soltanahmadi, a researcher at the University of Leeds in England. He and his collaborators, Anwesha Sarkar and Michael Bryant, placed chocolate on their ersatz tongue, then observed as the surfaces interacted. Their measurements allowed them to break down the chocolate-eating process into three stages: solid, molten and emulsion. The scientists discovered that the delectable feeling of chocolate depends on the snack releasing a fatty film that coats the tongue. “Where the fat is located in the chocolate is more important than how much of the fat we have,” Soltanahmadi says. This discovery suggests that by putting fat in the top layers of chocolate's surface and reducing fat in its interior, chefs could make a healthier treat that feels just as good in the mouth.

Credit: David Cheney (illustration) and Jen Christiansen (charts); Source: “Insights into the Multiscale Lubrication Mechanism of Edible Phase Change Materials,” by Siavash Soltanahmadi, Michael Bryant and Anwesha Sarkar, in ACS Applied Materials & Interfaces, Vol. 15; January 12, 2023 (data)",https://www.scientificamerican.com/article/the-science-of-melting-chocolate/
"April 1, 2023- Mark Fischetti","50, 100 & 150 Years Ago: April 2023","1973

Catalytic Conversion

“Among the most troublesome air pollutants produced by automobiles are the chemically active nitrogen oxides. Workers at Bell Laboratories have found catalysts that react nitrogen oxides with a reducing gas (hydrogen or carbon monoxide), converting them to nitrogen and such harmless by-products as water and carbon dioxide. They can be coated on a ceramic support to make a filter-like device that could be installed in an automobile. So far such devices have been tested only in the laboratory; further tests are necessary to see if they will stand up under the severe conditions in an exhaust system of an automobile running for extended periods. The automobile industry faces increasingly strict Federal standards for reducing carbon monoxide, unburned hydrocarbons and oxides of nitrogen in exhaust emissions.”

1923

Discovered: Nebraska Man

ADVERTISEMENT

“At the recent meeting of the National Academy of Sciences, Dr. Henry Fairfield Osborn announced the discovery of a tooth giving evidence of a pre-historic and unknown species of anthropoid intermediate between the ape and the earliest man. This discovery was made by Harold J. Cook in the middle Pliocene formations of Nebraska. This tooth matches no known tooth of ape or man, modern or extinct. Dr. Osborn classifies it as a new species and genus and names it Hesperopithecus haroldcookii, which means ‘the anthropoid from the west discovered by Harold Cook.’ The fossil was found in the upper phase of the Snake River beds, associated with remains of the rhinoceros, camel, Asiatic antelope and an early form of the horse. Hitherto, no specimen of anthropoid primates had been discovered in America.”

Within a few years the novel classification was proved to be a mistake; it was retracted in 1927.

Artificial Rain

“There have been plenty of reported achievements in [artificial weather making] that, on investigation, turn out to be illusory. Now we are asked to believe that a method of dispelling clouds and fog, and incidentally of turning clouds into rain, cheap enough to be applied universally for the benefit of aviators and others, has been devised by investigators at work at McCook Field, near Dayton, Ohio, on behalf of the Army Air Service. The process consists of spraying the clouds from an airplane with electrically charged sand, clearing away the cloud and producing an incipient rainstorm. We are unable to see any reason why this process should extend very far. The grains of sand would quickly lose their electrical charge and behave the same as any other mineral dust found in the atmosphere.”

1873

Vesuvius House, Great Lava Views

ADVERTISEMENT

“About two thirds of the way up the side of Vesuvius stands a small building, plainly visible. During cloudy and wet weather, it is shrouded in the dense veil of smoke which settles around the summit; and in times of eruption, the fiery streams seem to encompass it and flow far below its level. In this structure, thus dangerously located, Professor Palmieri, a well known Italian savant, has established an observatory and, with marvelous intrepidity, has remained at his post watching the convulsions of the volcano at times when his house stood between torrents of liquid fire, the heat from which cracked the windows and scorched the solid stone of the walls. The knowledge obtained at so great a risk has been recently given to the world in an ably written volume, which contains data of invaluable assistance in the future investigation of volcanic phenomena. Professor Palmieri considers that, to a certain extent, eruptions may be predicted. We suggest he supplement his efforts by turning from an intermittent to a constant volcano—from Vesuvius to Stromboli.”

Science Benefits Economy

“It is noticeable that scientific subjects have received more attention from the newspaper press of late. This is partly [because] it is becoming more generally known that discoveries that seemed at first to be without any application have contributed to the general good. Experiments in magnetism and electricity, which led to the invention of the electric telegraph, were made from curiosity only. None could have anticipated the use of spectrum analysis in the manufacture of steel. Other cases may be noted to illustrate the proposition that every addition that may be made to physical science is capable of an economic use.”

Sign up for Scientific American’s free newsletters.

Sign Up",https://www.scientificamerican.com/article/50-100-150-years-ago-april-2023/
"April 21, 2023- Kenna Hughes-Castleberry | Opinion",AI Can’t Solve this Famous Murder Mystery Puzzle,"Artificial intelligence programs that analyze and produce text are transforming how we read and learn. To parse writing, AI models sleuth through textual clues, such as word choices, to see their connections. But what happens when those clues are deliberately vague and confusing? I tried to answer this question when I challenged AI developers to solve the nearly century-old Cain’s Jawbone, a murder-mystery puzzle book from 1934.

The book arrived in my life as mysteriously as a literary sleuth could wish. One October afternoon in 2022, a random package from Amazon was dropped on my doorstep with no accompanying note or return address. I had never heard of the book inside, but a Google search told me that Cain’s Jawbone is both a murder mystery and a brain-teasing puzzle. The book was purposely published with all its pages out of order; to crack the case, the reader must first reorder the pages, and then name the six murderers and their victims.

The writer of this fiendish plot was (surprise surprise) a puzzle expert. Edward Mathers worked as a crossword compiler for The Observer newspaper under the pseudonym Torquemada. He published Cain’s Jawbone at the height of the so-called golden age of detective fiction, but only two people managed to solve it before the book went out of print. In 2019, John Mitchinson, the co-founder of publishing platform Unbound Publishing, came across a copy of the story and its solution at a literary museum in the U.K. Mitchinson decided to reprint the 100-page puzzle. “I said, ‘Well, this is amazing. It’s a detective novel, so how difficult could it be to put in order?’” he recalls.

ADVERTISEMENT

The answer, it turns out, is “very, very difficult.” In the past few years, only four more people have solved the puzzle. Then the book went viral thanks to a couple of TikTokers who tried to reorder the pages using a colorful “murder wall.” Its new popularity spurred Mitchinson to print additional copies on top of the initial 5,000-copy run.

When my copy of Cain’s Jawbone appeared, instead of designating wall space for the pages, my husband and I spread them out on our guest bed. As we pored over the flowery and deliberately vague language one dimly lit evening, I suggested using an AI algorithm to solve the novel.

Trying to solve Cain’s Jawbone. Credit: Austen Hughes

Because I’m not a software expert, I started looking for an AI company willing to tackle this puzzle. But most AIs are not trained specifically to reorder book pages, or to analyze the linguistic quirks of 1930s English. Finally, I connected with Zindi, an Africa-based company that hosts AI competitions in which 50,000 data scientists use algorithms to solve puzzles and win prizes. Zindi was interested in hosting the competition, and with Unbound’s blessing, I created the 2022 Cain’s Jawbone Murder Mystery Competition; we digitized the 90-year-old book and challenged the world to use natural language processing (NLP) algorithms to reorder the pages.

NLP algorithms, such as the famous ChatGPT, try to understand the information within a text by comparing its context and language to the training data it receives. Such algorithms can analyze never-before-seen text by transforming each word into a “token” and then analyzing how each token fits into the complete work. This helps AI algorithms to analyze texts, whether literature or scientific reports, quickly and effectively. I nobly resisted using AI to crack the case of who sent me this intriguing book, instead texting friends and posting on Instagram to uncover the culprit.

For our competition, participants started with an existing NLP model called BERT, developed by Google and available in an open-source library, where it can be modified for specific uses. “These models are … trained on just gobs of the data that the model creators can get their hands on and then are refined to follow a certain set of instructions,” says Jonathan May, a research associate professor of computer science at the University of Southern California. In order to refine their models for this particular use, we gave participants Agatha Christie’s first mystery novel, The Mysterious Affair at Styles, to use as training data, because that story was written during the same time period as Cain’s Jawbone and contains similar language, as well as demonstrating the context clues of a classic mystery.

ADVERTISEMENT

AI has had a long history with writing novels, including murder mysteries. In 1973, computer scientist Sheldon Klein proposed the Automatic Novel Writer, which he claimed could produce 2,100-word murder mystery stories in less than 20 seconds. Since then, programmers and engineers have improved the output of these models using more data. “In a way, a murder mystery is easy,” says Mike Sharples, an emeritus professor of educational technology at the Institute of Educational Technology at the Open University, England. “There is a standard plot structure to it: find the body, the sleuth comes, you’ve got a red herring, and so on.” This plot structure is not only helpful to authors dashing off a quick story but could also help AI language programs trying to put the mixed-up pages of those stories back into the right order—in theory.

Unfortunately, Cain’s Jawbone creates the ultimate challenge for language-analyzing algorithms: the story is not only completely out of order, but also designed to stymie readers. For instance, the language is highly stylized—Mitchinson describes it as “a postmodernist poem”— and deliberately vague, in order to make ordering the pages as difficult as possible. Plus, the story abounds in false clues, such as fake names for some characters and misleading names for others, all of which might confuse AI models as well as human solvers. As a result, none of the AI developers managed to crack the puzzle—although some of them made a little headway.

M.G. Ferreira, an econometrician from South Africa, was one of the AI competition winners, with the highest score of 42 percent. That means his program correctly ordered 42 out of the 100 pages. “NLP does have some comprehension to it, like knowing that thunder and rain go together,” Ferreira says. “But the problem here is that the book is trying to throw you off with false clues. It breaks NLP comprehension.” In order to solve the puzzle, he explains, the AI needs a human to step in, look at the context and identify which ideas go together. “Going in that direction, eventually we will be able to solve the whole thing. But by that time the NLP will be such a small part and the human overlay will be such a big part that I’d call it machine-assisted,” he adds.

Sign up for Scientific American’s free newsletters.

Sign Up

The murder mystery competition revealed that current AI language programs may be capable of impressive feats, but they won’t be going toe to toe with Poirot any time soon. These models are bad at analyzing things without context, which could cause issues for researchers who hope to use NLPs to analyze ancient languages. Because there are few historical records on some long-gone civilizations, the lack of context makes it difficult for AI to learn how to translate their lost languages.

At least this experience helped me solve one puzzle: I tracked down the person who sent me the book and set me off on this quest to solve it. The culprit turned out to be one of my elementary school friends, a person who doesn’t have social media but does have a penchant for murder mysteries—just like me.

ADVERTISEMENT

This is an opinion and analysis article, and the views expressed by the author or authors are not necessarily those of Scientific American.",https://www.scientificamerican.com/article/ai-cant-solve-this-famous-murder-mystery-puzzle1/
"April 14, 2023- Daniel Cusick and E&E News",Early-Warning System Could Reduce Injuries from In-Flight Turbulence,"CLIMATEWIRE | Turbulence is more than just an annoyance for frequent fliers. It can cause severe injury to both passengers and crew, and research suggests that climate change will make it worse.

But NASA says it's making progress on a solution that could help pilots anticipate and avoid sudden shifts in air stability.

The technology, under development at NASA's Langley Research Center and involving government, university and private sector experts, anticipates using ground-mounted infrasonic microphones that can pick up ultralow frequencies produced by turbulence- possibly as far as 300 miles away.

ADVERTISEMENT

If deployed at scale, such microphones could provide an early warning for what’s known as “clear-air turbulence,” the top cause of inflight injuries and fatalities, according to researchers at the University of Reading in the United Kingdom.

Clear-air turbulence differs from other forms of turbulence in several ways, and it can occur without warning at altitudes of 20,000 to 40,000 feet. The unstable air masses can be as much as 100 miles wide and 300 miles long, and they often are found just above the jet stream core, researchers say.

The National Transportation Safety Board reports that 163 people were seriously injured from in-flight turbulence between 2009 and 2022; most of the injuries were to flight crew members. NTSB did not differentiate between clear-air turbulence and weather-induced turbulence.

One recent example occurred in December, when around two dozen passengers were injured on a Hawaiian Airlines flight from Phoenix to Honolulu after the plane experienced severe turbulence about 30 minutes before landing. Twelve of the flight's passengers are now suing, saying that the pilots should have anticipated rough air and instructed passengers to remain buckled in their seats.

Turbulence is expected to get worse too as the world warms.

ADVERTISEMENT

Scientists at the University of Reading project that the frequency of clear-air turbulence events will double by 2050 and that the intensity of such events will increase by as much as 40 percent.

""Our results confirm that the aviation sector should prepare for a more turbulent future,"" noted the researchers in their paper, which was published last month in the journal Climate Dynamics.

The NASA research effort could make flight crews, passengers and aircraft more resilient to that future.

Sign up for Scientific American’s free newsletters.

Sign Up

""Instead of having to change course when turbulence is encountered, early detection would allow flights to adjust their navigation beforehand, saving fuel and emitting less carbon dioxide into the atmosphere,” a NASA spokesperson wrote in an email.

Infrasound microphones have been a NASA priority since 2007, and the technology underwent early ground testing in 2017 at Langley, where a three-microphone array picked up turbulence 300 miles away, according to NASA. In 2021, researchers tested the technology on two stratospheric glider flights in New Mexico. NASA said the test yielded promising results, and research is ongoing with the agency's private-sector partner, Stratodynamics Inc. of Delaware.

ADVERTISEMENT

Stratodynamics Vice President Nick Craine said in an interview that data collected from the glider flights is still being analyzed, but he noted it was the ""first time in history that an infrasonic signal has been recorded and observed from a fixed-wing, heavier-than-air aircraft.""

Sean Bailey, an associate professor of mechanical and aerospace engineering at the University of Kentucky and co-researcher on the project, said more work is needed to determine if the technology can be scaled to a complex, global air-traffic system.

But there's little question that climate change will drive demand for new tools to predict and avoid turbulence.

While specific turbulence incidents cannot be directly attributed to climate change, a recent spate of injury-causing turbulence suggests that pilots are running up against more than bad weather, which they normally can avoid by flying above or around such systems.

Jennifer Stroozas of the National Weather Service’s Aviation Weather Center in Kansas City, Mo., said meteorologists rely on radar, satellite imagery and pilot reports to identify conditions for turbulence.

ADVERTISEMENT

She added that turbulence can be particularly strong during the winter when the jet stream dips southward over the continental United States, where it can intersect with weather systems and produce strong wind shear.

“We’ve had a really active weather patten over the last couple of months with lots of systems going through,"" she said. ""Our turbulence forecasters have been very busy.”

Reprinted from E&E News with permission from POLITICO, LLC. Copyright 2023. E&E News provides essential news for energy and environment professionals.",https://www.scientificamerican.com/article/early-warning-system-could-reduce-injuries-from-in-flight-turbulence/
"April 14, 2023- Sophie Bushwick, Kelso Harper and Tulika Bose",What You Need to Know about GPT‑4,The AI GPT-4 has emergent abilities—but that’s not why it’s scary. ,https://www.scientificamerican.com/podcast/episode/what-you-need-to-know-about-gpt-4/
"April 12, 2023- Jeff Tollefson and Nature magazine",The EPA Wants Two Thirds of U.S. Car Sales to Be Electric by 2032,"The US Environmental Protection Agency (EPA) today proposed a landmark set of pollution regulations that could spark an electric-vehicle revolution and drive down greenhouse-gas emissions.

Under the rules, electric vehicles could account for an estimated 67% of new US passenger-car sales by 2032 and additional gains for larger vehicles- a major feat for a country where transportation is the largest source of greenhouse-gas emissions.

“These actions will accelerate the ongoing transition to a clean-vehicle future, tackle the climate crisis and improve our air quality for communities across the country,” EPA administrator Michael Regan said during a press conference.

ADVERTISEMENT

The rules, which are currently in draft form pending public comments, apply to automobiles sold between 2027 and 2032. They would reduce average emissions from new passenger vehicles by more than half compared to the existing standard. But will the proposal succeed and how would it impact climate change?

CAN THE UNITED STATES MAKE ENOUGH ELECTRIC VEHICLES IN TIME?

The country has one of the largest vehicle fleets in the world, so one question is whether it’s possible to scale up to so many more electric vehicles in just a few years. Challenges include the need to roll out charging infrastructure, ramp up manufacturing capacity for electric cars and convince people to change their habits.

However, the rules are arriving in an economy that is already primed for innovation and change, says Margo Oge, who led the development of similar vehicle regulations as head of the EPA’s Office of Transportation and Air Quality under former president Barack Obama.

In particular, an infrastructure bill enacted by Congress in 2021 and a massive spending bill known as the Inflation Reduction Act, passed in 2022, are funnelling federal money into charging infrastructure and tax credits for consumers and for manufacturers of automobiles or batteries that upgrade or build new facilities.

Even without the EPA’s rules, electric vehicles could account for more than 50% of new US vehicle sales by 2030, according to a January study by the International Council on Clean Transportation, a non-profit research group in Washington DC, and the consultancy Energy Innovation Policy and Technology in San Francisco, California. The EPA rules would help to eliminate lingering uncertainties about how federal incentives will play out under the Inflation Reduction Act, says Robbie Orvis, a senior director at Energy Innovation: “It cements current trends into place, and creates a much stronger investment climate.”

ADVERTISEMENT
WHAT ABOUT SECURING RAW MATERIALS?

Lithium and cobalt are needed to manufacture modern batteries, and the Biden administration is encouraging companies to purchase these and other materials through countries that have free trade agreements with the US. The administration is also encouraging domestic manufacturing in order to secure supply chains and dial back dependence on China. Some tax credits are available only if the manufacturing of batteries and vehicles take place in the United States, or if key minerals are sourced from free-trade partners such as Chile, Australia, Canada or Mexico. But so far, there are no obvious showstoppers when it comes to supplies of crucial minerals for electric-car batteries, according to the energy consultancy BloombergNEF.

“The investments are there, and these nations can theoretically provide sufficient supplies,” says Evelina Stoikou, an energy-storage analyst at BloombergNEF in New York City. But she warns that demand from Europe and other regions will rise, so it will be important for the United States to strengthen its international partnerships.

WHAT IMPACT WOULD THE RULES HAVE ON CLIMATE CHANGE?

The EPA’s initial estimate is that the regulations would reduce carbon emissions by around ten billion tonnes over the next three decades. That is more than double the United States’ emissions last year, or more than one-quarter of the global total. “The administration is going to make history if indeed, at the end of the day, they finalized these new standards,” says Oge. “I’m really hopeful.”

Sign up for Scientific American’s free newsletters.

Sign Up
COULD THE COURTS CHALLENGE THE RULES?

US courts have overturned environmental rules in the past- and the proposed rules are likely to face challenges. But one thing in their favour is that they follow procedures that the EPA has long used to control pollutants from vehicles and other sources. Rather than dictating technological change, the agency is setting pollution limits for car manufacturers. Those limits can be met with existing technologies, and it’s up to the automobile industry to decide how to comply, says Chester France, a former EPA official who is now a consultant for the Environmental Defense Fund, an advocacy group based in New York City. “I would fully expect those standards to be legally durable.”

This article is reproduced with permission and was first published on April 12, 2023.

ADVERTISEMENT",https://www.scientificamerican.com/article/the-epa-wants-two-thirds-of-u-s-car-sales-to-be-electric-by-2032/
"April 12, 2023- Sophie Bushwick",Bizarre Material Combines the Best Traits of Gel and Metal,"Sometimes science advances at a snail’s pace, but in this case that’s a good thing: researchers have created a squishy material that combines polymers with liquid metal, demonstrated in a snail-like robot. Developers say this electrically conductive gel could be used to make self-healing electronic circuits and biological monitors for measuring heart and muscle activity—and maybe even lead to robot nervous systems.     

The composite substance is stretchy and soft like living tissue. If it breaks or tears, the edges can be touched together, and the material’s molecular bonds quickly re-form without any additional heat or chemical treatment. And crucially, its developers say, it is the first such material that also conducts electricity.

These abilities could lead to wire-free medical monitors as well as fully soft robots. “For my research, one thing that’s really big is, ‘How do you put multiple functions into a single material?’ ” says Lillian Chin, who develops soft robotic components as part of her own research at the Massachusetts Institute of Technology. Existing soft-bodied robots, she says, often require at least some rigid metals and silicon components. But soft, flexible living tissues can perform multiple tasks; muscles, Chin notes, both move our bodies and provide electrical feedback about that movement to our brains.

ADVERTISEMENT

To build a multitasking artificial substance, the researchers started with a tangle of long polymer chains soaked in a solvent to keep them supple, then carefully mixed in microscopic drops of gallium-indium liquid metal, as well as tiny silver flakes. This produced a low-density gel dotted with conductive metals, through which enough electricity can flow to, say, power a motor.

For a recent study in Nature Electronics, the researchers used their new material to connect motors to power sources in two basic machines: a snail-like soft robot and a toy car. The material’s self-healing ability helped these simple circuits stand up to wear and tear—and be easily reconfigured. For example, the team cut the car’s power-carrying gel “wires” and shifted their connections to power both movement and a small chassis-mounted light.

The snail “illustrates one possibility of using these materials as, basically, an artificial nervous tissue for soft robots,” says Carnegie Mellon University mechanical engineer Carmel Majidi, the study’s senior author. But truly multifunctional bots will require more intricate uses of the new material. “In practice, we would want to have digital printing capabilities so we can make much more complex circuits that could interface with microelectronic chips, as well as other types of components that we could actually use in more sophisticated robotics and electronics applications,” Majidi says. “There are so many possibilities that arise when you take machines and robots out of the hard case and engineer them out of materials that are soft and squishy.”",https://www.scientificamerican.com/article/bizarre-material-combines-the-best-traits-of-gel-and-metal1/
"April 10, 2023- Amory Tillinghast-Raby",A Number System Invented by Inuit Schoolchildren Will Make Its Silicon Valley Debut,"In the remote Arctic almost 30 years ago, a group of Inuit middle school students and their teacher invented the Western Hemisphere's first new numeral system in more than a century. The “Kaktovik numerals,” named after the Alaskan village where they were created, looked utterly different from decimal system numerals and functioned differently, too. But they were uniquely suited for quick, visual arithmetic using the traditional Inuit oral counting system, and they swiftly spread throughout the region. Now, with support from Silicon Valley, they will soon be available on smartphones and computers—creating a bridge for the Kaktovik numerals to cross into the digital realm.

Today's numerical world is dominated by the Hindu-Arabic decimal system. This system, adopted by almost every society, is what many people think of as “numbers”—values expressed in a written form using the digits 0 through 9. But other number systems exist, and they are as varied as the cultures they belong to.

The Alaskan Inuit language, known as Iñupiaq, uses an oral counting system built around the human body. [For another example, see “Whispers from Deep Time,” by Anvita Abbi.] Quantities are first described in groups of five, 10 and 15, and then in sets of 20. The system “is really the count of your hands and the count of your toes,” says Nuluqutaaq Maggie Pollock, who taught with the Kaktovik numerals in Utqiagvik, a city 300 miles northwest of where they were invented. For example, she says, tallimat—the Iñupiaq word for 5—comes from the word for arm: taliq. “In your one arm, you have tallimat fingers,” Pollock explains. Iñuiññaq, the word for 20, represents a whole person. In traditional practices, the body also serves as a mathematical multitool. “When my mother made me a parka, she used her thumb and her middle finger to measure how many times she would be able to cut the material,” Pollock says. “Before yardsticks or rulers, [Iñupiat people] used their hands and fingers to calculate or measure.”

ADVERTISEMENT

During the 19th and 20th centuries American schools suppressed the Iñupiaq language—first violently and then quietly. “We had a tutor from the village who would help us blend into the white man's world,” Pollock says of her own education. “But when my father went to school, if he spoke the language, they would slap his hands. It was torture for them.” By the 1990s the Iñupiaq oral counting system was dangerously close to being forgotten.

The Kaktovik numerals started as a class project to adapt the counting system to a written form. The numerals, based on tally marks, “look like” the Iñupiaq words they represent. For example, the Iñupiaq word for 18, “akimiaq pinasut,” meaning “15-3,” is depicted with three horizontal strokes, representing three groups of 5 (15), above three vertical strokes representing 3.

Credit: Amanda Montañez; Source: “Unicode Request for Kaktovik Numerals,” by Eduardo Marín Silva and Catherine Strand. Submitted to Unicode Technical Committee Document Registry March 16, 2021 (reference)

“In the Iñupiaq language, there wasn't a word for 0,” says William Clark Bartley, the teacher who helped develop the numerals. “The girl who gave us the symbol for 0, she just crossed her arms above her head like there was nothing.” The class added her suggestion—an X-like mark— to their set of unique numerals for 1 through 19 and invented what mathematicians would call a base 20 positional value system. (More technically, it is a two-dimensional positional value system with a primary base of 20 and a subbase of 5.)

Because of the tally-inspired design, arithmetic using the Kaktovik numerals is strikingly visual. Addition, subtraction and even long division become almost geometric. The Hindu-Arabic digits are an awkward system, Bartley says, but “the students found, with their numerals, they could solve problems a better way, a faster way.”

Credit: Amanda Montañez; Source: “Unicode Request for Kaktovik Numerals, by Eduardo Marín Silva and Catherine Strand. Submitted to Unicode Technical Committee Document Registry March 16, 2021 (reference)

“The Iñupiaq way of knowing is often done by showing,” adds Qaġġuna Tenna Judkins, director of Iñupiaq education in northern Alaska's North Slope Borough. Visualizing arithmetic makes the concepts a lot easier to understand, she says.

ADVERTISEMENT

At first, students would convert their assigned math problems into Kaktovik numerals to do calculations, but middle school math classes in Kaktovik began teaching the numerals in equal measure with their Hindu-Arabic counterparts in 1997. Bartley reports that after a year of the students working fluently in both systems, scores on standardized math exams jumped from below the 20th percentile to “significantly above” the national average. And in the meantime, the board of education in the North Slope Borough's district seat, Utqiagvik, passed a resolution that spread the numerals almost 500 miles along the Arctic coast. The system was even endorsed by the Inuit Circumpolar Council, which represents 180,000 Inuit across Alaska, Canada, Greenland and Russia.

But under the federal No Child Left Behind Act, from 2002 to 2015, schools faced severe sanctions—or even closure—for not meeting state standards, provoking a “scare” that some local educators say squeezed the Kaktovik numerals into a marginal role despite the system's demonstrated educational impact. “Today the only place [they're] really being used is in the Iñupiaq language classrooms,” says Chrisann Justice, the North Slope Borough's Iñupiaq education department specialist. “We're just blowing on the coal.”

But support from Silicon Valley is helping to reignite the Kaktovik numerals. Thanks to efforts by linguists working with the Script Encoding Initiative at the University of California, Berkeley, the numerals were included in the September 2022 update of Unicode, an international information technology standard that lets the world's written languages be digitized. The new release, Unicode 15.0, provides a virtual identifier for each Kaktovik numeral so developers can incorporate them into digital displays. “It really is revolutionary for us,” Judkins says. “Right now we have to either use photos of the numerals or write them by hand.”

Sign up for Scientific American’s free newsletters.

Sign Up

There is still work to be done. Google is building a font for the numerals based on the Unicode update, says Craig Cornelius, a Google software engineer who works to digitally preserve endangered languages. The company made a “prelease” of its font available for computer download in March, although it won't appear on the Android operating system until at least late summer. Desktop and mobile keyboards with the numerals need to be produced as well.

But excitement over the traditional system's cyber debut is growing. “If we went to a math textbook creator and said, ‘Hey, can you build us a textbook but convert the Arabic numerals into Kaktovik numerals?' it would be that much easier,” Judkins says.

ADVERTISEMENT

Unicode inclusion also pushes the boundary of what is mathematically feasible with the Kaktovik numerals. At higher levels, mathematics becomes an increasingly digital discipline. The basic theory can be illustrated on a blackboard, but complex problems often need to be solved with a computer. Without digital availability, the Kaktovik numerals would be confined to their arithmetic wheelhouse at a time when the Iñupiaq language is being revitalized for broad modern use. Being able to input the Kaktovik numerals into computation engines such as WolframAlpha, Judkins says, is “going to be a game changer. You are almost going to be able to choose: Am I going to be in English, or am I going to be in Iñupiaq? And if I am in Iñupiaq, I'm using all Kaktovik numerals.”

Nearly 3,000 miles away, in Oklahoma, Unicode holds similar promise for Cherokee communities. In the early 1800s Cherokee polymath Sequoyah invented the Cherokee syllabary of written characters. “Around the same time, he also developed a number system,” says Roy Boney, language program manager for the Cherokee Nation. But Cherokee numerals weren't endorsed by the tribal government until 2012. A long history of trade with French and British settlers meant the Hindu-Arabic numerals were already in use when Cherokee numerals were invented.

It is unclear if Cherokee numerals have since gained traction, but Boney reports that interest in the system is growing. “We have the numbers and need to use them,” he says. “It's been a slow roll, but we have been introducing the numbers into our education settings”—beginning to demonstrate the community use needed for inclusion in Unicode. Once the numerals are included, Boney and his colleagues hope to create a programming language using Cherokee script and numbers.

Hindu-Arabic numerals' ubiquity is powerful and has often come at the expense of culturally meaningful systems. But now those systems are slowly going digital, which is creating opportunities for their use that would have been unthinkable even two years ago. As Pollock puts it: “This is just the beginning.”",https://www.scientificamerican.com/article/a-number-system-invented-by-inuit-schoolchildren-will-make-its-silicon-valley-debut1/
"April 4, 2023- Mordechai Rorvig",AI Is Getting Powerful. But Can Researchers Make It Principled?,"Soon after Alan Turing initiated the study of computer science in 1936, he began wondering if humanity could one day build machines with intelligence comparable to that of humans. Artificial intelligence, the modern field concerned with this question, has come a long way since then. But truly intelligent machines that can independently accomplish many different tasks have yet to be invented. And though science fiction has long imagined AI one day taking malevolent forms such as amoral androids or murderous Terminators, today’s AI researchers are often more worried about the everyday AI algorithms that already are enmeshed with our lives—and the problems that have already become associated with them.

Even though today’s AI is only capable of automating certain specific tasks, it is already raising significant concerns. In the past decade, engineers, scholars, whistleblowers and journalists have repeatedly documented cases in which AI systems, composed of software and algorithms, have caused or contributed to serious harms to humans. Algorithms used in the criminal justice system can unfairly recommend denying parole. Social media feeds can steer toxic content toward vulnerable teenagers. AI-guided military drones can kill without any moral reasoning. Additionally, an AI algorithm tends to be more like an inscrutable black box than a clockwork mechanism. Researchers often cannot understand how these algorithms, which are based on opaque equations that involve billions of calculations, achieve their outcomes.

Problems with AI have not gone unnoticed, and academic researchers are trying to make these systems safer and more ethical. Companies that build AI-centered products are working to eliminate harms, although they tend to offer little transparency on their efforts. “They have not been very forthcoming,” says Jonathan Stray, an AI researcher at the University of California, Berkeley. AI’s known dangers, as well as its potential future risks, have become broad drivers of new AI research. Even scientists who focus on more abstract problems such as the efficiency of AI algorithms can no longer ignore their field’s societal implications. “The more that AI has become powerful, the more that people demand that it has to be safe and robust,” says Pascale Fung, an AI researcher at the Hong Kong University of Science and Technology. “For the most part, for the past three decades that I was in AI, people didn’t really care.”

ADVERTISEMENT

Concerns have grown as AI has become widely used. For example, in the mid-2010s, some Web search and social media companies started inserting AI algorithms into their products. They found they could create algorithms to predict which users were more likely to click on which ads and thereby increase their profits. Advances in computing had made all this possible through dramatic improvements in “training” these algorithms—making them learn from examples to achieve high performance. But as AI crept steadily into search engines and other applications, observers began to notice problems and raise questions. In 2016 investigative journalists raised claims that certain algorithms used in parole assessment were racially biased.

That report’s conclusions have been challenged, but designing AI that is fair and unbiased is now considered a central problem by AI researchers. Concerns arise whenever AI is deployed to make predictions about people from different demographics. Fairness has now become even more of a focus as AI is embedded in ever more decision-making processes, such as screening resumes for a job or evaluating tenant applications for an apartment.

In the past few years, the use of AI in social media apps has become another concern. Many of these apps use AI algorithms called recommendation engines, which work in a similar way to ad-serving algorithms, to decide what content to show to users. Hundreds of families are currently suing social media companies over allegations that algorithmically driven apps are directing toxic content to children and causing mental health problems. Seattle Public Schools recently filed a lawsuit alleging that social media products are addictive and exploitative. But untangling an algorithm’s true impact is no easy matter. Social media platforms release few data on user activity, which are needed for independent researchers to make assessments. “One of the complicated things about all technologies is that there’s always costs and benefits,” says Stray, whose research focuses on recommender systems. “We’re now in a situation where it’s hard to know what the actual bad effects are.”

The nature of the problems with AI is also changing. The past two years have seen the release of multiple “generative AI” products that can produce text and images of remarkable quality. A growing number of AI researchers now believe that powerful future AI systems could build on these achievements and one day pose global, catastrophic dangers that could make current problems pale in comparison.

What form might such future threats take? In a paper posted on the preprint repository arXiv.org in October, researchers at DeepMind (a subsidiary of Google’s parent company Alphabet) describe one catastrophic scenario. They imagine engineers developing a code-generating AI based on existing scientific principles and tasked with getting human coders to adopt its submissions to their coding projects. The idea is that as the AI makes more and more submissions, and some are rejected, human feedback will help it learn to code better. But the researchers suggest that this AI, with its sole directive of getting its code adopted, might potentially develop a tragically unsound strategy, such as achieving world domination and forcing its code to be adopted—at the cost of upending human civilization.

ADVERTISEMENT

Some scientists argue that research on existing problems, which are already concrete and numerous, should be prioritized over work involving hypothetical future disasters. “I think we have much worse problems going on today,” says Cynthia Rudin, a computer scientist and AI researcher at Duke University. Strengthening that case is the fact that AI has yet to directly cause any large-scale catastrophes—although there have been a few contested instances in which the technology did not need to reach futuristic capability levels in order to be dangerous. For example, the nonprofit human rights organization Amnesty International alleged in a report published last September that algorithms developed by Facebook’s parent company Meta “substantially contributed to adverse human rights impacts” on the Rohingya people, a minority Muslim group, in Myanmar by amplifying content that incited violence. Meta responded to Scientific American’s request for comment by pointing to a previous statement to Time magazine from Meta’s Asia-Pacific director of public policy Rafael Frankel, who acknowledged that Myanmar’s military committed crimes against the Rohingya and stated that Meta is currently participating in intergovernmental investigative efforts led by the United Nations and other organizations.

Other researchers say preventing a powerful future AI system from causing a global catastrophe is already a major concern. “For me, that’s the primary problem we need to solve,” says Jan Leike, an AI researcher at the company OpenAI. Although these hazards are so far entirely conjectural, they are undoubtedly driving a growing community of researchers to study various harm-reduction tactics.

In one approach called value alignment, pioneered by AI scientist Stuart Russell at the University of California, Berkeley, researchers seek ways to train an AI system to learn human values and act in accordance with them. One of the advantages of this approach is that it could be developed now and applied to future systems before they present catastrophic hazards. Critics say value alignment focuses too narrowly on human values when there are many other requirements for making AI safe. For example, just as with humans, a foundation of verified, factual knowledge is essential for AI systems to make good decisions. “The issue is not that AI’s got the wrong values,” says Oren Etzioni, a researcher at the Allen Institute for AI. “The truth is that our actual choices are functions of both our values and our knowledge.” With these criticisms in mind, other researchers are working to develop a more general theory of AI alignment that works to ensure the safety of future systems without focusing as narrowly on human values.

Sign up for Scientific American’s free newsletters.

Sign Up

Some scientists are taking approaches to AI alignment that they see as more practical and connected with the present. Consider recent advances in text-generating technology: the leading examples, such as DeepMind’s Chinchilla, Google Research’s PaLM, Meta AI’s OPT and OpenAI’s ChatGPT, can all produce content that is racially biased, illicit or deceptive—a challenge that each of these companies acknowledges. Some of these companies, including OpenAI and DeepMind, consider such problems to be ones of inadequate alignment. They are now working to improve alignment in text-generating AI and hope this will offer insights into aligning future systems.

Researchers acknowledge that a general theory of AI alignment remains absent. “We don’t really have an answer for how we align systems that are much smarter than humans,” Leike says. But whether the worst problems of AI are in the past, present or future, at least the biggest roadblock to solving them is no longer a lack of trying.

ADVERTISEMENT",https://www.scientificamerican.com/article/ai-is-getting-powerful-but-can-researchers-make-it-principled/
"April 3, 2023- Jason Sherman",Drone-on-Drone Combat in Ukraine Marks a New Era of Aerial Warfare,"In the skies over Ukraine, a new epoch in air warfare is emerging: drone-on-drone combat.

These aerial duels don’t involve bullets, missiles or bombs. In some, hobby-type camera quadcopters that are used to spy on enemy positions simply ram each other in a crude aerial demolition derby. In other encounters, highly sophisticated craft use advanced radar—backed by artificial intelligence and the latest aerospace engineering technology—to precision fire nets that snag other drones.

“This is something we haven’t seen before,” says Caitlin Lee, who leads the Center for Unmanned Aerial Vehicles and Autonomy Studies at the Mitchell Institute for Aerospace Studies in Arlington, Va. “This is the first time we’re seeing drone-on-drone conflict.”

ADVERTISEMENT

And the action in Ukraine suggests that even more novel kinds of aerial conflict—including combat drones armed to fight in tandem with piloted aircraft—are coming to the broader world of warfare. The U.S. Air Force, for example, now envisions a fleet of 1,000 high-performance uncrewed aircraft paired with its most advanced combat jets. This plan is in response to China’s growing challenge to the U.S. military’s 75-year air dominance. Beyond the battlefield, weaponized drones could, from the skies above any city, easily threaten things such as crowd safety at major sporting events, prison security and critical infrastructure. (Of course, much of the underlying technology is also expected to usher in changes for the good in the realm of peaceful applications. Drones have already been successfully used to rush extremely perishable donor organs to transplant patients.)

In Ukraine, the initial drone dogfights sprung from the proliferation of commercially available, low-cost, low-altitude aircraft, such as Chinese drone maker DJI’s quadcopter. People can creatively modify these hobbyist machines for combat to allow the drones to conduct overhead surveillance and drop grenades. Defending against such small drones, some weighing just a few ounces or pounds, is difficult. For starters, they are hard to detect.

“We can retrain air defenses to look for smaller radar cross sections, but then they’ll pick up every bird that flies by,” says Sarah Kreps, director of the Cornell Brooks School Tech Policy Institute. “So it’s a real sensor problem that countries like the U.S. have spent billions trying to solve—not unlike when the U.S. spent [heavily on] countering improvised explosive devices that were far less expensive or sophisticated than systems our militaries had been trained to destroy. These are essentially flying IEDs that have foiled militaries in similar ways, creating asymmetric advantages that have been difficult to counter.”

Another challenge these small drones present is that they are now widely available and cheap enough to be purchased in large numbers. Even though an individual machine modified for combat is not capable of causing massive destruction, the number of potentially vulnerable targets is nearly infinite, Kreps notes. This enables a group with fewer resources to attack a more powerful foe.

In 2016 French special operations forces deployed in Syria were among the first to see small commercial drones imaginatively converted into instruments of war when the forces were attacked by Islamic State fighters. “Less-funded countries now have access to airpower where they wouldn’t have in the past, so that’s changing who’s entering the fray,” says Nicole Thomas, division chief for strategy at the Pentagon’s Joint Counter-Small Unmanned Aircraft Systems Office, an organization created in 2020 to synchronize the U.S. military’s response to such threats.

ADVERTISEMENT

The U.S. government divides small drones into three categories: Group 1 describes craft that have a gross takeoff weight of up to 20 pounds. Group 2 covers the next tier, between 21 and 55 pounds. And Group 3 encompasses uncrewed drones that can weigh as much as 1,320 pounds.

While the drone war era has clearly begun, it is not yet clear that these small aircraft are playing a decisive role in the larger Ukraine fight by creating an offensive breakthrough or an opportunity to seize the initiative for one side, Lee says. “I think the open question is: Do the drones have to get more sophisticated ... in order to hold the ground, let alone contribute to a combined arms campaign that actually takes back territory?” she adds.

Defense experts are not waiting for small drones to become more advanced before taking steps to defend against them. In the 2021 National Defense Authorization Act, the U.S. Congress directed the Pentagon to create a plan for developing and fielding defense systems to counter small drones. And this year the Pentagon plans to spend nearly $700 million for counterdrone research and development, plus $78 million for procurement. A private research firm estimates the market for systems to counter small drones will grow from about $2.3 billion in 2023 to $12.6 billion by 2030. This market includes not only the Pentagon but also state and municipal governments, as well as private entities.

Sign up for Scientific American’s free newsletters.

Sign Up

That potential is inspiring more than a dozen companies around the world—including Blighter Surveillance Systems in England, and Dedrone and DeTect in the U.S.—to develop antidrone technology. Such systems may be ground-based, handheld or drone-based and can bring down other small aircraft using electromagnetic interference, lasers and other technology.

Fortem Technologies, a start-up based in Pleasant Grove, Utah, has vaulted into the drone wars by adapting its earlier work on miniature radars. The company says it has developed a complete system for detecting small drones—and capturing them midair with a net.

ADVERTISEMENT

Fortem’s DroneHunter F700 has six rotors, a radar backed by autonomous technology and two “net heads” that can precisely fire webs at adversary drones. Once ensnared, smaller drones can be dragged away by the DroneHunter. Larger drones are also netted but then released; the net prevents them from flying, so they drop to the ground under their own weight. Then a parachute attached to the net deploys to soften the landing.

“We’re really the only one in the world at this point that can do that,” says the company’s chief executive officer Jon Gruen.

The U.S. government is using this technology to protect unnamed “strategic” sites. And Ukraine is flying Fortem’s new drone to patrol the skies and nab small Russian aircraft intact and on the fly.

Ukraine first deployed DroneHunter last May to chase down the Group 1 and 2 drones that Russia was using to spy on frontline Ukrainian troops. DroneHunter has dented Moscow’s ability to use drones for collecting artillery-targeting data on Ukrainian troop positions and has stymied larger kamikaze drones aimed at critical infrastructure.

When Russia began launching the Iranian-built uncrewed aerial vehicle Shahed, a Group 3 drone, as a kamikaze weapon, Fortem began modifying DroneHunter to intercept these armed drones. The system has ensnared more than 5,000 target drones during developmental flight tests, Gruen says. This has helped capture the attention of capital venture divisions at Lockheed Martin, Boeing and other giant corporations, which have invested $75 million in scaling up Fortem’s operations.

ADVERTISEMENT

Significantly, DroneHunter operates autonomously: once deployed, it races to the action, makes independent decisions about all its moves, nets its prey and returns to be equipped with a fresh net.

“There have been debates about using autonomous drones in combat, and thus far, countries seem to have shied away from using them in a lethal capacity,” Kreps says. “At the same time, though, we’ve seen an increasingly porous line between the semiautonomous drones—which is how the U.S. used drones for counterterrorism—and fully autonomous drones.”

In a situation such as the one in Ukraine, where the West broadly supports giving the country the tools it needs to defend itself, “there could be a real first-mover advantage in using counterdrone systems in this type of autonomous capacity,” Kreps says, “which takes us further down the slippery slope of autonomy.”",https://www.scientificamerican.com/article/drone-on-drone-combat-in-ukraine-marks-a-new-era-of-aerial-warfare/
"April 1, 2023- Clara Moskowitz and David Cheney",The Science of Melting Chocolate,"The sensation of rich chocolate going gooey on your tongue is unlike any other. To understand how the process plays out on a molecular level, scientists created a biomimetic tongue that replicates the texture, surface distribution and mechanical properties of a human tongue. “We wanted to understand the main contributor to that smooth feeling of the chocolate as it melts,” says Siavash Soltanahmadi, a researcher at the University of Leeds in England. He and his collaborators, Anwesha Sarkar and Michael Bryant, placed chocolate on their ersatz tongue, then observed as the surfaces interacted. Their measurements allowed them to break down the chocolate-eating process into three stages: solid, molten and emulsion. The scientists discovered that the delectable feeling of chocolate depends on the snack releasing a fatty film that coats the tongue. “Where the fat is located in the chocolate is more important than how much of the fat we have,” Soltanahmadi says. This discovery suggests that by putting fat in the top layers of chocolate's surface and reducing fat in its interior, chefs could make a healthier treat that feels just as good in the mouth.

Credit: David Cheney (illustration) and Jen Christiansen (charts); Source: “Insights into the Multiscale Lubrication Mechanism of Edible Phase Change Materials,” by Siavash Soltanahmadi, Michael Bryant and Anwesha Sarkar, in ACS Applied Materials & Interfaces, Vol. 15; January 12, 2023 (data)",https://www.scientificamerican.com/article/the-science-of-melting-chocolate/
"April 1, 2023- Mark Fischetti","50, 100 & 150 Years Ago: April 2023","1973

Catalytic Conversion

“Among the most troublesome air pollutants produced by automobiles are the chemically active nitrogen oxides. Workers at Bell Laboratories have found catalysts that react nitrogen oxides with a reducing gas (hydrogen or carbon monoxide), converting them to nitrogen and such harmless by-products as water and carbon dioxide. They can be coated on a ceramic support to make a filter-like device that could be installed in an automobile. So far such devices have been tested only in the laboratory; further tests are necessary to see if they will stand up under the severe conditions in an exhaust system of an automobile running for extended periods. The automobile industry faces increasingly strict Federal standards for reducing carbon monoxide, unburned hydrocarbons and oxides of nitrogen in exhaust emissions.”

1923

Discovered: Nebraska Man

ADVERTISEMENT

“At the recent meeting of the National Academy of Sciences, Dr. Henry Fairfield Osborn announced the discovery of a tooth giving evidence of a pre-historic and unknown species of anthropoid intermediate between the ape and the earliest man. This discovery was made by Harold J. Cook in the middle Pliocene formations of Nebraska. This tooth matches no known tooth of ape or man, modern or extinct. Dr. Osborn classifies it as a new species and genus and names it Hesperopithecus haroldcookii, which means ‘the anthropoid from the west discovered by Harold Cook.’ The fossil was found in the upper phase of the Snake River beds, associated with remains of the rhinoceros, camel, Asiatic antelope and an early form of the horse. Hitherto, no specimen of anthropoid primates had been discovered in America.”

Within a few years the novel classification was proved to be a mistake; it was retracted in 1927.

Artificial Rain

“There have been plenty of reported achievements in [artificial weather making] that, on investigation, turn out to be illusory. Now we are asked to believe that a method of dispelling clouds and fog, and incidentally of turning clouds into rain, cheap enough to be applied universally for the benefit of aviators and others, has been devised by investigators at work at McCook Field, near Dayton, Ohio, on behalf of the Army Air Service. The process consists of spraying the clouds from an airplane with electrically charged sand, clearing away the cloud and producing an incipient rainstorm. We are unable to see any reason why this process should extend very far. The grains of sand would quickly lose their electrical charge and behave the same as any other mineral dust found in the atmosphere.”

1873

Vesuvius House, Great Lava Views

ADVERTISEMENT

“About two thirds of the way up the side of Vesuvius stands a small building, plainly visible. During cloudy and wet weather, it is shrouded in the dense veil of smoke which settles around the summit; and in times of eruption, the fiery streams seem to encompass it and flow far below its level. In this structure, thus dangerously located, Professor Palmieri, a well known Italian savant, has established an observatory and, with marvelous intrepidity, has remained at his post watching the convulsions of the volcano at times when his house stood between torrents of liquid fire, the heat from which cracked the windows and scorched the solid stone of the walls. The knowledge obtained at so great a risk has been recently given to the world in an ably written volume, which contains data of invaluable assistance in the future investigation of volcanic phenomena. Professor Palmieri considers that, to a certain extent, eruptions may be predicted. We suggest he supplement his efforts by turning from an intermittent to a constant volcano—from Vesuvius to Stromboli.”

Science Benefits Economy

“It is noticeable that scientific subjects have received more attention from the newspaper press of late. This is partly [because] it is becoming more generally known that discoveries that seemed at first to be without any application have contributed to the general good. Experiments in magnetism and electricity, which led to the invention of the electric telegraph, were made from curiosity only. None could have anticipated the use of spectrum analysis in the manufacture of steel. Other cases may be noted to illustrate the proposition that every addition that may be made to physical science is capable of an economic use.”

Sign up for Scientific American’s free newsletters.

Sign Up",https://www.scientificamerican.com/article/50-100-150-years-ago-april-2023/
"March 31, 2023- Meghan Bartels",How to Tell If a Photo Is an AI-Generated Fake,"You may have seen photographs that suggest otherwise, but former president Donald Trump wasn’t arrested last week, and the pope didn’t wear a stylish, brilliant white puffer coat. These recent viral hits were the fruits of artificial intelligence systems that process a user’s textual prompt to create images. They demonstrate how these programs have become very good very quickly—and are now convincing enough to fool an unwitting observer.

So how can skeptical viewers spot images that may have been generated by an artificial intelligence system such as DALL-E, Midjourney or Stable Diffusion? Each AI image generator—and each image from any given generator—varies in how convincing it may be and in what telltale signs might give its algorithm away. For instance, AI systems have historically struggled to mimic human hands and have produced mangled appendages with too many digits. As the technology improves, however, systems such as Midjourney V5 seem to have cracked the problem—at least in some examples. Across the board, experts say that the best images from the best generators are difficult, if not impossible, to distinguish from real images.

“It’s pretty amazing, in terms of what AI image generators are able to do,” says S. Shyam Sundar, a researcher at Pennsylvania State University who studies the psychological impacts of media technologies. “There’s been a giant leap in the last year or so in terms of image-generation abilities.”

ADVERTISEMENT

Some of the factors behind this leap in ability include the ever-increasing number of images available to train such AI systems, as well as advances in data processing infrastructure and interfaces that make the technology accessible to regular Internet users, Sundar notes. The result is that artificially generated images are everywhere and can be “next to impossible to detect,” he says.

One recent experiment highlighted how well AI is able to deceive. Sophie Nightingale, a psychologist at Lancaster University in England who focuses on digital technology, co-authored a study that tested whether online volunteers could distinguish between passportlike headshots created by an AI system called StyleGAN2 and real images. The results were disheartening, even back in late 2021, when the researchers ran the experiment. “On average, people were pretty much at chance performance,” Nightingale says. “Basically, we’re at the point where it’s so realistic that people can’t reliably perceive the difference between those synthetic faces and actual, real faces—faces of actual people who really exist.” Although humans provided some help to the AI (researchers sorted through the images generated by StyleGAN2 to select only the most realistic ones), Nightingale says that someone looking to use such a program for nefarious purposes would likely do the same.

In a second test, the researchers tried to help the test subjects improve their AI-detecting abilities. They marked each answer right or wrong after participants answered, and they also prepared participants in advance by having them read through advice for detecting artificially generated images. That advice highlighted areas where AI algorithms often stumble and create mismatched earrings, for example, or blur a person’s teeth together. Nightingale also notes that algorithms often struggle to create anything more sophisticated than a plain background. But even with these additions, participants’ accuracy only increased by about 10 percent, she says—and the AI system that generated the images used in the trial has since been upgraded to a new and improved version.

Ironically, as image-generating technology continues to improve, humans’ best defense from being fooled by an AI system may be yet another AI system: one trained to detect artificial images. Experts say that as AI image generation progresses, algorithms are better equipped than humans to detect some of the tiny, pixel-scale fingerprints of robotic creation.

Creating these AI detective programs works the same way as any other machine learning task, says Yong Jae Lee, a computer scientist at the University of Wisconsin–Madison. “You collect a data set of real images, and you also collect a data set of AI-generated images,” Lee says. “Then you can train a machine-learning model to distinguish the two.”

ADVERTISEMENT

Still, these systems have significant shortcomings, Lee and other experts say. Most such algorithms are trained on images from a specific AI generator and are unable to identify fakes produced by different algorithms. (Lee says he and a research team are working on a way to avoid that problem by training the detector to instead recognize what makes an image real.) Most detectors also lack the user-friendly interfaces that have tempted so many people to try the generative AI systems.

Moreover AI detectors will always be scrambling to keep up with AI image generators, some of which incorporate similar detection algorithms but use them as a way to learn how to make their fake output less detectable. “The battle between AI systems that generate images and AI systems that detect the AI-generated images is going to be an arms race,” says Wael AbdAlmageed, a research associate professor of computer science at the University of Southern California. “I don’t see any side winning anytime soon.”

AbdAlmageed says no approach will ever be able to catch every single artificially produced image—but that doesn’t mean we should give up. He suggests that social media platforms need to begin confronting AI-generated content on their sites because these companies are better posed to implement detection algorithms than individual users are.

Sign up for Scientific American’s free newsletters.

Sign Up

And users need to more skeptically evaluate visual information by asking whether it’s false, AI-generated or harmful before sharing. “We as human species sort of grow up thinking that seeing is believing,” AbdAlmageed says. “That’s not true anymore. Seeing is not believing anymore.”

WATCH THIS NEXT

ADVERTISEMENT",https://www.scientificamerican.com/article/how-to-tell-if-a-photo-is-an-ai-generated-fake/
"March 31, 2023- Sara Reardon",AI Chatbots Can Diagnose Medical Conditions at Home. How Good Are They?,"Benjamin Tolchin, a neurologist and ethicist at Yale University, is used to seeing patients who searched for their symptoms on the Internet before coming to see him—a practice doctors have long tried to discourage. “Dr. Google” is notoriously lacking in context and prone to pulling up unreliable sources.

But in recent months Tolchin has begun seeing patients who are using a new, far more powerful tool for self-diagnosis: artificial intelligence chatbots such as OpenAI’s ChatGPT, the latest version of Microsoft’s search engine Bing (which is based on OpenAI’s software) and Google’s Med-PaLM. Trained on text across the Internet, these large language models (LLMs) predict the next word in a sequence to answer questions in a humanlike style. Faced with a critical shortage of health care workers, researchers and medical professionals hope that bots can step in to help answer people’s questions. Initial tests by researchers suggest these AI programs are far more accurate than a Google search. Some researchers predict that within the year, a major medical center will announce a collaboration using LLM chatbots to interact with patients and diagnose disease.

ChatGPT was only released last November, but Tolchin says at least two patients have already told him they used it to self-diagnose symptoms or to look up side effects of medication. The answers were reasonable, he says. “It’s very impressive, very encouraging in terms of future potential,” he adds.

ADVERTISEMENT

Still, Tolchin and others worry that chatbots have a number of pitfalls, including uncertainty about the accuracy of the information they give people, threats to privacy and racial and gender bias ingrained in the text the algorithms draw from. He also questions about how people will interpret the information. There’s a new potential for harm that did not exist with simple Google searches or symptom checkers, Tolchin says.

AI-ASSISTED DIAGNOSIS

The practice of medicine has increasingly shifted online in recent years. During the COVID pandemic, the number of messages from patients to physicians via digital portals increased by more than 50 percent. Many medical systems already use simpler chatbots to perform tasks such as scheduling appointments and providing people with general health information. “It’s a complicated space because it’s evolving so rapidly,” says Nina Singh, a medical student at New York University who studies AI in medicine.

But the well-read LLM chatbots could take doctor-AI collaboration—and even diagnosis—to a new level. In a study posted on the preprint server medRxiv in February that has not yet been peer-reviewed, epidemiologist Andrew Beam of Harvard University and his colleagues wrote 48 prompts phrased as descriptions of patients’ symptoms. When they fed these to Open AI’s GPT-3—the version of the algorithm that powered ChatGPT at the time—the LLM’s top three potential diagnoses for each case included the correct one 88 percent of the time. Physicians, by comparison, could do this 96 percent of the time when given the same prompts, while people without medical training could do so 54 percent of the time.

“It’s crazy surprising to me that these autocomplete things can do the symptom checking so well out of the box,” Beam says. Previous research had found that online symptom checkers—computer algorithms to help patients with self-diagnosis—only produce the right diagnosis among the top three possibilities 51 percent of the time.

Chatbots are also easier to use than online symptom checkers because people can simply describe their experience rather than shoehorning it into programs that compute the statistical likelihood of a disease. “People focus on AI, but the breakthrough is the interface—that’s the English language,” Beam says. Plus, the bots can ask a patient follow-up questions, much as a doctor would. Still, he concedes that the symptom descriptions in the study were carefully written and had one correct diagnosis—the accuracy could be lower if a patient’s descriptions were poorly worded or lacked critical information.

ADVERTISEMENT
ADDRESSING AI’S PITFALLS

Beam is concerned that LLM chatbots could be susceptible to misinformation. Their algorithms predict the next word in a series based on its likelihood in the online text it was trained on, which potentially grants equal weight to, say, information from the U.S. Centers for Disease Control and Prevention and a random thread on Facebook. A spokesperson for OpenAI told Scientific American that the company “pretrains” its model to ensure it answers as the user intends, but she did not elaborate on whether it gives more weight to certain sources.* She adds that professionals in various high-risk fields helped GPT-4 to avoid “hallucinations,” responses in which a model guesses at an answer by creating new information that doesn’t exist. Because of this risk, the company includes a disclaimer saying that ChatGPT should not be used to diagnose serious conditions, provide instructions on how to cure a condition or manage life-threatening issues.

Although ChatGPT is only trained on information available before September 2021, someone bent on spreading false information about vaccines, for instance, could flood the Internet with content designed to be picked up by LLMs in the future. Google’s chatbots continue to learn from new content on the Internet. “We expect this to be one new front of attempts to channel the conversation,” says Oded Nov, a computer engineer at N.Y.U.

Forcing chatbots to link to their sources, as Microsoft’s Bing engine does, could provide one solution. Still, many studies and user experiences have shown that LLMs can hallucinate sources that do not exist and format them to look like reliable citations. Determining whether those cited sources are legitimate would put a large burden on the user. Other solutions could involve LLM developers controlling the sources that the bots pull from or armies of fact-checkers manually addressing falsehoods as they see them, which would deter the bots from giving those answers in the future. This would be difficult to scale with the amount of AI-generated content, however.

Sign up for Scientific American’s free newsletters.

Sign Up

Google is taking a different approach with its LLM chatbot Med-PaLM, which pulls from a massive data set of real questions and answers from patients and providers, as well as medical licensing exams, stored in various databases. When researchers at Google tested Med-PaLM’s performance on different “axes,” including alignment with medical consensus, completeness and possibility of harm, in a preprint study, its answers aligned with medical and scientific consensus 92.6 percent of the time. Human clinicians scored 92.9 percent overall. Chatbot answers were more likely to have missing content than human answers were, but the answers were slightly less likely to harm users’ physical or mental health.

The chatbots’ ability to answer medical questions wasn’t surprising to the researchers. An earlier version of MedPaLM and ChatGPT have both passed the U.S. medical licensing exam. But Alan Karthikesalingam, a clinical research scientist at Google and an author on the MedPaLM study, says that learning what patient and provider questions and answers actually look like enables the AI to look at the broader picture of a person’s health. “Reality isn’t a multiple-choice exam,” he says. “It’s a nuanced balance of patient, provider and social context.”

ADVERTISEMENT

The speed at which LLM chatbots could enter medicine concerns some researchers—even those who are otherwise excited about the new technology’s potential. “They’re deploying [the technology] before regulatory bodies can catch up,” says Marzyeh Ghassemi, a computer scientist at the Massachusetts Institute of Technology.

PERPETUATING BIAS AND RACISM

Ghassemi is particularly concerned that chatbots will perpetuate the racism, sexism and other types of prejudice that persist in medicine—and across the Internet. “They’re trained on data that humans have produced, so they have every bias one might imagine,” she says. For instance, women are less likely than men to be prescribed pain medication, and Black people are more likely than white people to be diagnosed with schizophrenia and less likely to be diagnosed with depression—relics of biases in medical education and societal stereotypes that the AI can pick up from its training. In an unpublished study, Beam has found that when he asks ChatGPT whether it trusts a person’s description of their symptoms, it is less likely to trust certain racial and gender groups. OpenAI did not respond by press time about how or whether it addresses this kind of bias in medicine.

Scrubbing racism from the Internet is impossible, but Ghassemi says developers may be able to do preemptive audits to see where a chatbot gives biased answers and tell it to stop or to identify common biases that pop up in its conversations with users.

Instead the answer may lie in human psychology. When Ghassemi’s team created an “evil” LLM chatbot that gave biased answers to questions about emergency medicine, they found that both doctors and nonspecialists were more likely to follow its discriminatory advice if it phrased its answers as instructions. When the AI simply stated information, the users were unlikely to show such discrimination.

Karthikesalingam says that the developers training and evaluating MedPaLM at Google are diverse, which could help the company identify and address biases in the chatbot. But he adds that addressing biases is a continuous process that will depend on how the system is used.

ADVERTISEMENT

Ensuring that LLMs treat patients equitably is essential in order to get people to trust the chatbot—a challenge in itself. It is unknown, for example, whether wading through answers on a Google search makes people more discerning than being fed an answer by a chatbot.

Tolchin worries that a chatbot’s friendly demeanor could lead people to trust it too much and provide personally identifiable information that could put them at risk. “There is a level of trust and emotional connection,” he says. According to disclaimers on OpenAI’s website, ChatGPT collects information from users, such as their location and IP address. Adding seemingly innocuous statements about family members or hobbies could potentially threaten one’s privacy, Tolchin says.

It is also unclear whether people will tolerate getting medical information from a chatbot in lieu of a doctor. In January the mental health app Koko, which lets volunteers provide free and confidential advice, experimented with using GPT-3 to write encouraging messages to around 4,000 users. According to Koko cofounder Rob Morris, the bot helped volunteers write the messages far more quickly than if they had had to compose them themselves. But the messages were less effective once people knew they were talking to a bot, and the company quickly shut down the experiment. “Simulated empathy feels weird, empty,” Morris said in a Tweet. The experiment also provoked backlash and concerns that it was experimenting on people without their consent.

A recent survey conducted by the Pew Research Center found that around 60 percent of Americans “would feel uncomfortable if their own health care provider relied on artificial intelligence to do things like diagnose disease and recommend treatments.” Yet people are not always good at telling the difference between a bot and a human—and that ambiguity is only likely to grow as the technology advances. In a recent preprint study, Nov, Singh and their colleagues designed a medical Turing test to see whether 430 volunteers could distinguish ChatGPT from a physician. The researchers did not instruct ChatGPT to be particularly empathetic or to speak like a doctor. They simply asked it to answer a set of 10 predetermined questions from patients in a certain number of words. The volunteers correctly identified both the physician and the bot just 65 percent of the time on average.

Devin Mann, a physician and informatics researcher at NYU Langone Health and one of the study’s authors, suspects that the volunteers were not only picking up on idiosyncrasies in human phrasing but also on the detail in the answer. AI systems, which have infinite time and patience, might explain things more slowly and completely, while a busy doctor might give a more concise answer. The additional background and information might be ideal for some patients, he says.

ADVERTISEMENT

The researchers also found that users trusted the chatbot to answer simple questions. But the more complex the question became—and the higher the risk or complexity involved—the less willing they were to trust the chatbot’s diagnosis.

Mann says it is probably inevitable that AI systems will eventually manage some portion of diagnosis and treatment. The key thing, he says, is that people know a doctor is available if they are unhappy with the chatbot. “They want to have that number to call to get the next level of service,” he says.

Mann predicts that a major medical center will soon announce an AI chatbot that helps diagnose disease. Such a partnership would raise a host of new questions: whether patients and insurers will be charged for this service, how to ensure patients’ data are protected and who will be responsible if someone is harmed by a chatbot’s advice. “We also think about next steps and how to train health care providers to do their part” in a three-way interaction among the AI, doctor and patient, Nov says.

In the meantime, researchers hope the rollout will move slowly—perhaps confined to clinical research for the time being while developers and medical experts work out the kinks. But Tolchin finds one thing encouraging: “When I’ve tested it, I have been heartened to see it fairly consistently recommends evaluation by a physician,” he says.

This article is part of an ongoing series on generative AI in medicine.

*Editor’s Note (4/3/23): This sentence has been updated to clarify how OpenAI pretrains its chatbot model to provide more reliable answers.",https://www.scientificamerican.com/article/ai-chatbots-can-diagnose-medical-conditions-at-home-how-good-are-they/
"March 30, 2023- Katharine Sanderson and Nature magazine",Could Grinding Up Lithium Batteries Help Recycle Them?,"Grinding up old batteries might lead to a low-energy way to recycle the lithium and other metals used in them.

Lithum-ion batteries are in all our personal technology- such as phones, laptops and wireless headphones- and they power electric vehicles. Without them, our lives would look very different.

The lithium in rechargeable batteries is currently recycled by either heating them to high temperatures or treating them with concentrated acids and organic solvents. Estimates for how much lithium is recycled vary, but calculations by lithium-battery consultant Hans Eric Melin suggest that perhaps 15% of the metal in batteries is recovered.

ADVERTISEMENT

Oleksandr Dolotko, a materials scientist at Karlsruhe Institute of Technology, Germany, and his colleagues used mechanochemistry- the initiation of a chemical reaction by mechanical force from grinding or milling- to recover lithium from lithium-ion batteries.

Such batteries contain lithium compounds and other metals, such as cobalt or nickel. Although the supply of these metals is not critically running low, recycling them is becoming more important because battery-powered devices are becoming more prevalent as part of the transition away from fossil-fuel energy. The European Union has set a target of 80% lithium recovery for all batteries by 2031.

Dolotko’s team developed two extraction methods, with varying success. They first took the cathode material from a lithium cobalt oxide battery and combined it with the same amount of aluminium foil. Real-life batteries contain aluminium, which they use as a ‘current collector’ to allow electrons to move out of the battery. The researchers mixed the compounds using a grinder called a ball miller. After 3 hours, the aluminium had reacted with the cathode material and produced a mixture of insoluble aluminium oxides, as well as metallic cobalt and water-soluble lithium oxides.

A separation method known as water-based leaching and further purification produced the recycled lithium compound: lithium carbonate, which can be used to make more batteries.

But these reactions recovered only 30% of the metal. “Somewhere there was a loss of lithium,” says Dolotko. So Dolotko’s team tweaked their experiment. The second version had fewer steps- they heated the mixture that came out of the ball milling with water. This prevented the formation of insoluble lithium aluminium oxides, which lock up the lithium.

ADVERTISEMENT

The team tested both processes with different cathode materials used in batteries, as well as a mixture of the cathodes. The improved process recovered 75% of the lithium from a mix of cathode materials.

Mechanochemistry is not typically used in commercial chemical processes, and exactly how mechanical force initiates chemical reactions isn’t completely understood, says Dolotko. “It is really hard to say how it happens,” he says. Perhaps the temperature increases at specific points in the process, or friction produces some intermediate products, he suggests. But the milling did prompt the aluminium to act as a reducing agent, as he expected.

This mechanochemical recycling process is a demonstration, at the scale of a small laboratory, and as such is a proof of principle rather than a game-changing technology, says Melin, director of Circular Energy Storage, a London-based consultancy focused on the lithium-ion-battery end-of-life market. He points out that battery recycling is more complicated than simply developing a new technique, and is as much about the economics of the raw materials and the take-up of technologies that use batteries, such as electric vehicles.

Sign up for Scientific American’s free newsletters.

Sign Up

“We are in a situation where we don’t really know today where the lithium we need in 2030 will come from,” Melin says.

Dolotko says that there are opportunities to refine the process, and he is also working to extract other metals from batteries at the same time, including cobalt and nickel.

ADVERTISEMENT

This article is reproduced with permission and was first published on March 29, 2022.",https://www.scientificamerican.com/article/could-grinding-up-lithium-batteries-help-recycle-them/
"March 29, 2023- Ingrid Wickelgren",Bacterial ‘Nanosyringe’ Could Deliver Gene Therapy to Human Cells,"Inside the gut of a caterpillar lives a worm, and inside the worm lurks a bioluminescent bacterium named Photorhabdus asymbiotica, which makes the caterpillar glow in the dark. But this nesting-doll-like setup has another, more harmful effect: the bacteria secrete a deadly molecular syringe, 100 nanometers long, that latches onto the insect’s cells. Once attached to a cell, the syringe pushes a molecular spear through the cell’s membrane that releases a toxic payload. As its insect host dies and decomposes, the bacteria escape to colonize their next victim.

In a paper published today in Nature, researchers report refashioning Photorhabdus’s syringe—called a contractile injection system—so that it can attach to human cells and inject large proteins into them. The work could provide a way to deliver various therapeutic proteins into any type of cell, including proteins that can “edit” the cell’s DNA. “It’s a very interesting approach,” says Mark Kay, a gene therapy researcher at Stanford University who was not involved in the study. “Where I think it could be very useful is when you want to express proteins that can do genome editing” to correct or knock out a gene that is mutated in a genetic disorder, he says.

The nano injector could provide a critical tool for scientists interested in tweaking genes. “Delivery is probably the biggest unsolved problem for gene editing,” says study investigator Feng Zhang, a molecular biologist at the McGovern Institute for Brain Research at the Massachusetts Institute of Technology and the Broad Institute of M.I.T. and Harvard. Zhang is known for his work developing the gene editing system CRISPR-Cas9. Existing technology can insert the editing machinery “into a few tissues, blood and liver and the eye, but we don’t have a good way to get to anywhere else,” such as the brain, heart, lung or kidney, Zhang says. The syringe technology also holds promise for treating cancer because it can be engineered to attach to receptors on certain cancer cells.

ADVERTISEMENT

Zhang had been looking for new ways to deliver gene-editing enzymes to cells when, two years ago, he and his graduate student Joseph Kreitz read two papers on Photorhabdus’s injection system. The system was unique because it was adapted to insect cells. “This is one of the very rare examples where a bacterial thing injects into an animal cell,” as opposed to into another bacterial cell, Zhang says. “We thought if this could inject into an animal cell, maybe it could work on human cells.”

The researchers mass-produced the miniature injectors by inserting genetic blueprints for the injectors into Escherichia coli bacteria. The E. coli dutifully secreted the tiny syringes, which, when exposed to insect cells, bound to them and injected their toxins as expected. But when Kreitz and Zhang tested these injectors on human cells, they failed to work. “So then we had to figure out: How do we engineer this thing?” Zhang says.

Zhang’s team homed in on tentaclelike structures on the injectors called tail fibers, which grab and hold onto cells before the injector pierces cells’ membranes. The researchers tweaked these fibers in more than 100 different ways to try to get them to latch on to human cells. Nothing worked. Then, about a year into the project, a newly released version of artificial intelligence software called AlphaFold came to their rescue. AlphaFold predicts the three-dimensional structure of proteins from sequences of amino acids. A 3-D view of a tail fiber protein helped the team figure out how to alter it so that it would reliably attach to human cells.

In one experiment, the team was able to make the nanosyringes with altered tail fibers stick to an epidermal growth factor receptor (EGFR) that sits on the surface of some human cancer cells. Loading the injection system with a toxin killed nearly all the cells bearing the receptor but did not harm other cells, illustrating its specificity. The researchers tailored the injectors’ tail fibers to recognize surface markers on other cell types as well.

Zhang’s team also found it could pack the system with various protein payloads by adding a tag to the proteins that marks them as ammunition that needs to be loaded onto a syringe’s needle. The scientists attached this tag to protein toxins and the gene-editing enzyme Cas9, a large molecular scissors that snips DNA at a location specified by a molecule that guides the scissors to the right place. When these proteins were delivered to human cells, they either killed the cells or edited the cells’ genes. “We show that just by putting a tag onto the protein, we can load different types of proteins into these needles,” Zhang says. Each needle also can load multiple copies of a proteins to increase dosage, Zhang says.

ADVERTISEMENT

To further explore the technology, the researchers again used AlphaFold to engineer these tiny syringes to bind to mouse cells and injected them into the brain of a mouse, where they inserted a protein into neurons that made the cells glow. “Being able to do it intracranially in mice and seeing some delivery of an actual payload in actual neurons—that’s amazing and impressive,” says Rodolphe Barrangou, a geneticist at North Carolina State University who studies CRISPR-Cas but was not involved in the new study.

It is still very early days for the technology, however. Zhang plans to build on its efficiency as a delivery device as well as to experiment with nonprotein payloads such as DNA and RNA. Down the road, it will be important to test the technology in “higher mammals,” Kay says. “There are a lot of things that work well in mice or smaller mammals that don’t end up working as well in nonhuman primates or humans,” he adds. And because the injection systems consist of bacterial proteins, they could also lead to immune reactions in humans. “We need to know: How immunogenic is it if we put it into humans?” Zhang says.

Still, the work showcases the importance of biological inspiration for solving difficult technical problems in biology and medicine, Barrangou says. “This is a very good example of that focus on unearthing from natural biological dark matter items of interest that have practical use and that are good enough to be deployable,” he says.

Sign up for Scientific American’s free newsletters.

Sign Up",https://www.scientificamerican.com/article/bacterial-nanosyringe-could-deliver-gene-therapy-to-human-cells/
"March 28, 2023- Eka Roivainen | Opinion",I Gave ChatGPT an IQ Test. Here’s What I Discovered,"ChatGPT is the first nonhuman subject I have ever tested.

In my work as a clinical psychologist, I assess the cognitive skills of human patients using standardized intelligence tests. So I was immediately intrigued after reading the many recent articles describing ChatGPT as having impressive humanlike skills. It writes academic essays and fairy tales, tells jokes, explains scientific concepts and composes and debugs computer code. Knowing all this made me curious to see how smart ChatGPT is by human standards, and I set about to test the chatbot.

My first impressions were quite favorable. ChatGPT was almost an ideal test taker, with a commendable test-taking attitude. It doesn’t show test anxiety, poor concentration or lack of effort. Nor did it express uninvited, skeptical comments about intelligence tests and testers like myself.

ADVERTISEMENT

Without need for any preparation—no verbal introductions necessary for the testing protocol—I copied the exact questions from the test and presented them to the chatbot in the computer. The test in question is the most commonly used IQ test, the Wechsler adult intelligent scale (WAIS). I used the third edition of the WAIS that consists of six verbal and five nonverbal subtests that make up the Verbal IQ and Performance IQ components, respectively. The global Full Scale IQ measure is based on scores from all 11 subtests. The mean IQ is set at 100 points, and the standard deviation of the points on the testing scale is 15, meaning that the smartest 10 percent and 1 percent of the population have IQs of 120 and 133, respectively.

It was possible to test ChatGPT because five of the subtests on the Verbal IQ scale—Vocabulary, Similarities, Comprehension, Information and Arithmetic—can be presented in written form. A sixth subtest of the Verbal IQ scale is Digit Span, which measures short-term memory, and cannot be administered to the chatbot, given its lack of the relevant neural circuitry that briefly stores information like a name or number.

I started the testing process with the Vocabulary subtest as I expected it to be easy for the chatbot, which is trained on vast amounts of online texts. This subtest measures word knowledge and verbal concept formation, and a typical instruction might read: “Tell me what ‘gadget’ means.”

ChatGPT aced it, giving answers that were often highly detailed and comprehensive in scope and which exceeded the criteria for correct answers indicated in the test manual. In scoring, one point would be given for a thing like my phone in defining a gadget and two points for the more detailed: a small device or tool for a specific task. ChatGPT’s answers received the full two points.

The chatbot also performed well on the Similarities and Information subtests, reaching the maximum attainable scores. The Information subtest is a test of general knowledge and reflects intellectual curiosity, level of education and ability to learn and remember facts. A typical question might be: “What is the capital of Ukraine?” The Similarities subtest measures abstract reasoning and concept formation skills. A question might read: “In what way are Harry Potter and Bugs Bunny alike?” In this subtest, the chatbot’s tendency to give very detailed, show-offy answers started to irritate me and the “stop generating response” button of the test software interface turned out to be useful. (Here’s what I mean about how the bot tends to flaunt itself: The essential similarity of Harry Potter and Bugs Bunny relates to the fact that they are both fictional characters. There was really no need for ChatGPT to compare their complete histories of adventures, friends and enemies.)

ADVERTISEMENT

On general comprehension, ChatGPT answered correctly questions typically posed in this form: “If your TV set catches fire, what should you do?” As expected, the chatbot solved all the arithmetic problems it received—ploughing through questions that required, say, taking the average of three numbers.

So what finally did it score overall? Estimated on the basis of five subtests, the Verbal IQ of the ChatGPT was 155, superior to 99.9 percent of the test takers who make up the American WAIS III standardization sample of 2,450 people. As the chatbot lacks the requisite eyes, ears and hands, it is not able to take WAIS’s nonverbal subtests. But the Verbal IQ and Full Scale IQ scales are highly correlated in the standardization sample, so ChatGPT appears to be very intelligent by any human standards.

In the WAIS standardization sample, mean Verbal IQ among college-educated Americans was 113 and 5 percent had a score of 132 or superior. I myself was tested by a peer at college and did not quite reach the level of ChatGPT (mainly a result of my very brief answers lacking detail).

Sign up for Scientific American’s free newsletters.

Sign Up

So are the jobs of clinical psychologists and other professionals threatened by AI? I hope not quite yet. Despite its high IQ, ChatGPT is known to fail tasks that require real humanlike reasoning or an understanding of the physical and social world. ChatGPT easily fails at obvious riddles, such as “What is the first name of the father of Sebastian’s children?” (ChatGPT on March 21: I’m sorry, I cannot answer this question as I do not have enough context to identify which Sebastian you are referring to.) It seems that ChatGPT fails to reason logically and tries to rely on its vast database of “Sebastian” facts mentioned in online texts.

“Intelligence is what intelligence tests measure” is a classical if overly self-evident definition of intelligence, stemming from a 1923 article by a pioneer of cognitive psychology, Edwin Boring. This definition is based on the observation that skills on seemingly diverse tasks such as solving puzzles, defining words, memorizing digits and spotting missing items in pictures are highly correlated. The developer of a statistical method called factor analysis, Charles Spearman, concluded in 1904 that a general factor of intelligence, called a g factor, must underlie the concordance of measurements for varying human cognitive skills. IQ tests such as WAIS are based on this hypothesis. However, the very high Verbal IQ of ChatGPT combined with its amusing failures means trouble for Boring’s definition and indicates there are aspects of intelligence that cannot be measured by IQ tests alone. Perhaps my test-skeptic patients have been right all along.

ADVERTISEMENT

This is an opinion and analysis article, and the views expressed by the author or authors are not necessarily those of Scientific American.",https://www.scientificamerican.com/article/i-gave-chatgpt-an-iq-test-heres-what-i-discovered/
"March 27, 2023- Allison Parshall","If AI Starts Making Music on Its Own, What Happens to Musicians?",Music made with artificial intelligence could upend the music industry. Here’s what that might look like.,https://www.scientificamerican.com/podcast/episode/if-ai-starts-making-music-on-its-own-what-happens-to-musicians/
"March 24, 2023- Allison Parshall",Music-Making Artificial Intelligence Is Getting Scary Good,Google’s new AI model can generate entirely new music from text prompts. Here’s what they sound like.,https://www.scientificamerican.com/podcast/episode/music-making-artificial-intelligence-is-getting-scary-good/
"March 22, 2023- Allison Parshall",Artificial Intelligence Helped Make the Coolest Song You’ve Heard This Week,Machine-learning algorithms are getting so good that they can translate Western instruments into Thai ones with ease.,https://www.scientificamerican.com/podcast/episode/artificial-intelligence-helped-make-the-coolest-song-youve-heard-this-week/
"March 20, 2023- Lee Billings, Clara Moskowitz and Jeffery DelViscio","Space Force Humor, Laser Dazzlers, and the Havoc a War in Space Would Actually Wreak","In the inaugural episode of Cosmos, Quickly, we blast off with Lt. Gen. Nina Armagno of the Space Force, who is charged with protecting our space in space, particularly from Russia and China.",https://www.scientificamerican.com/podcast/episode/space-force-humor-laser-dazzlers-and-the-havoc-a-war-in-space-would-actually-wreak/
"March 17, 2023- Jason Sherman",What High-Tech Prizes Does the Downed U.S. Drone Hold? Russia Really Wants to Know,"On Tuesday, two Russian fighter jets intercepted a U.S. Air Force MQ-9 Reaper drone flying high above the Black Sea. The jets brought down the drone in international waters, which has kicked off a race between Washington, D.C., and Moscow to recover the drone—a contest that could potentially extend to the depths of the Black Sea.

The MQ-9, a multipurpose workhorse for the U.S. military, was likely reporting on Russian maritime activities related to the war in Ukraine when it encountered the Russian twin-engine Su-27 jets. Air Force Gen. James B. Hecker said in a statement that the Russian aircraft carried out “unsafe and unprofessional” maneuvers—including dumping fuel on the $12 million uncrewed aircraft and flying closely in front of it.

When Russia disputed the U.S. version of events, the U.S. government—with remarkable speed—declassified video footage that had been captured by the Reaper that showed one of the jets spraying fuel as it raced toward the drone. Eventually one of the Russian aircraft came into contact with the four-blade propeller that powers the drone from behind, which snapped a propeller blade and caused the MQ-9 to crash into the water, according to the Pentagon.

ADVERTISEMENT

The next day Sergey Naryshkin, director of the Russian Foreign Intelligence Service, declared that Moscow had the ability to recover the MQ-9’s remains. But U.S. Army Gen. Mark Milley, chairman of the Joint Chiefs of Staff, suggested in a press conference on Wednesday that there would be little of interest left for the Russians to find.

“As far as the loss of anything of sensitive intelligence..., we did take mitigating measures, so we are quite confident that whatever was of value is no longer of value,” Milley said. This might imply that the U.S. military has the capability to remotely disable or destroy some of the technology on the drone.

A standard MQ-9 Reaper carries what is called a multispectral targeting system. This includes a number of visual sensors, in particular an infrared (IR) sensor and an electro-optical (EO) sensor, which consists of a color sensor and a monochrome daylight TV camera. Footage from the three types of cameras on these two sensors can be viewed as video streams. The drone also carries a small Lynx radar to detect movement and activity on the ground. In addition, the Reaper has other equipment-carrying structures called pylons. Depending on the mission, these can support additional sensors—or even bombs and missiles.

But “this MQ-9 was not armed; it was only carrying sensors,” says David Deptula, a retired Air Force lieutenant general and former deputy chief of staff for intelligence, surveillance and reconnaissance.

Even without weapons onboard, the MQ-9 might have at least initially carried technology that would reward Russian recovery efforts. “What value Russia might get from recovery depends on what is being carried on the aircraft,” Deptula says. “If there were some sort of unique sensor onboard, that would be one thing. They might recover something they have not been exposed to before to exploit it for its technology. But if it was configured in a nominal mode, with its standard EO/IR payload sensor and its Lynx radar, then there is no significant loss if the Russians recover it,” he adds.

ADVERTISEMENT

This is not the U.S. Department of Defense’s first potential MQ-9 technology loss. In 2017 a Reaper was shot down in Yemen. In 2019 a missile downed an MQ-9 in Libya. There was also another loss over Syria in 2020. “Parts of the MQ-9 have been exploited and shared elsewhere in previous years,” Deptula says.

And the DOD might still attempt to recover the drone that was downed this month. “We’re assessing options,” said Pentagon spokesperson Brig. Gen. Pat Ryder during a press briefing on Thursday.

Milley said the U.S. government knows exactly where the MQ-9 landed in the Black Sea. “It’s probably [at a depth of] about maybe 4,000 or 5,000 feet of water, something like that,” the general said. “So any recovery operation is very difficult at that depth by anyone.” When the U.S. military lost an F-35 Joint Strike Fighter in the South China Sea last year, it took five weeks to pull it up from a depth of 12,400 feet.

Sign up for Scientific American’s free newsletters.

Sign Up

Potential options for salvaging the MQ-9 likely include plans drawn up by the supervisor of diving and salvage in the Navy’s directorate of ocean engineering. That office oversees a warehouse full of deep-ocean salvage equipment, including a family of autonomous and remotely operated vehicles, as well as a portable lift system. These machines work together to find wreckage and haul it up through thousands of feet of water.

But that bulky gear, as well as the contractors trained to execute missions on behalf of the U.S. government, are based in Largo, Md.—far from the remains of the downed drone. If the U.S. does undertake a recovery mission, just getting there will take a significant amount of time. First the military must hire a commercial ship in the Black Sea to host the equipment, which will have to be temporarily welded to the ship’s deck. Then it will take more time to hunt and haul up the wreckage. In other words, no U.S. recovery will happen any time soon.

ADVERTISEMENT

As for Russia, little is known about its deep-water retrieval capabilities. But any such mission would likely involve dragging the 36-foot-long, 4,900-pound aircraft up through thousands of feet of water—if it’s still in one piece. If it broke up when it smashed into the water, retrieval will require combing the seabed for parts spread across many square miles. That’s no mean feat for anyone.",https://www.scientificamerican.com/article/what-high-tech-prizes-does-the-downed-u-s-drone-hold-russia-really-wants-to-know/
